{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "od2YkWY8pSOC",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# NLP 2025\n",
    "# Lab 2: Word Vectors and Information Retrieval\n",
    "\n",
    "During the first few weeks, we discussed various ways to represent text ðŸ“. One key question was: What should be the basic unit of representation? Words are the fundamental building blocks ðŸ§±.\n",
    "\n",
    "In this lab, we will explore different text representation models, such as Bag-of-Words (BoW), TF-IDF and word embeddings ðŸ”¤âž¡ï¸ðŸ”¢. Among these, word embeddings are the most effective in terms of performance. They represent each word as a vector of numbers, where each vector captures the meaning of the word ðŸ§ ðŸ“Š.\n",
    "\n",
    "These numerical representations (or weights) are learned using machine learning models ðŸ¤–. Weâ€™ll dive deeper into how these vectors are learned in the next lecture ðŸ“š.\n",
    "\n",
    "For now, weâ€™ll focus on how different representation methods affect performance in an information retrieval task ðŸ”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "s93LS5bspSOD",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "By the end of this lab, you should be able to:\n",
    "\n",
    "+ ðŸ§¼ðŸ” Implement and/or use built-in functions to preprocess your data (once again!)\n",
    "+ ðŸ§±ðŸ‘œ Build a Bag-of-Words representation of the dataset\n",
    "+ ðŸ“Šâœ¨ Implement TF-IDF\n",
    "+ ðŸ“¥ðŸ”¤ Load pre-trained word embeddings\n",
    "+ ðŸ”ðŸ§  Inspect and test word embedding properties\n",
    "+ ðŸ—£ï¸âž¡ï¸ðŸ“ Use word embeddings to get sentence representations (aka sentence embeddings)\n",
    "+ ðŸ§©ðŸ”Ž Use sentence embeddings to solve more complex tasks like information retrieval\n",
    "+ ðŸ§ªðŸ“ Design evaluation frameworks for specific NLP tasks and assess their difficulty\n",
    "\n",
    "### Score breakdown\n",
    "\n",
    "| Exercise            | Points |\n",
    "|---------------------|--------|\n",
    "| [Exercise 1](#e1)   | 1      |\n",
    "| [Exercise 2](#e2)   | 1      |\n",
    "| [Exercise 3](#e3)   | 1      |\n",
    "| [Exercise 4](#e4)   | 1      |\n",
    "| [Exercise 5](#e5)   | 1      |\n",
    "| [Exercise 6](#e6)   | 2      |\n",
    "| [Exercise 7](#e7)   | 10     |\n",
    "| [Exercise 8](#e8)   | 5      |\n",
    "| [Exercise 9](#e9)   | 15     |\n",
    "| [Exercise 10](#e10) | 10     |\n",
    "| [Exercise 11](#e11) | 10     |\n",
    "| [Exercise 12](#e12) | 5      |\n",
    "| [Exercise 13](#e13) | 15     |\n",
    "| [Exercise 14](#e14) | 3      |\n",
    "| [Exercise 15](#e15) | 10     |\n",
    "| [Exercise 16](#e16) | 10     |\n",
    "| Total               | 100    |\n",
    "\n",
    "This score will be scaled down to 1 and that will be your final lab score.\n",
    "\n",
    "### ðŸ“Œ **Instructions for Delivery** (ðŸ“… **Deadline: 18/Apr 18:00**, ðŸŽ­ *wildcards possible*)\n",
    "\n",
    "âœ… **Submission Requirements**\n",
    "+ ðŸ“„ You need to submit a **PDF of your report** (use the templates provided in **LaTeX** ðŸ–‹ï¸ (*preferred*) or **Word** ðŸ“‘) and a **copy of your notebook** ðŸ““ with the code.\n",
    "+ âš¡ Make sure that **all cells are executed properly** âš™ï¸ and that **all figures/results/plots** ðŸ“Š you include in the report are also visible in your **executed notebook**.\n",
    "\n",
    "âœ… **Collaboration & Integrity**\n",
    "+ ðŸ—£ï¸ While you may **discuss** the lab with others, you must **write your solutions with your group only**. If you **discuss specific tasks** with others, please **include their names** in the appendix of the report.\n",
    "+ ðŸ“œ **Honor Code applies** to this lab. For more details, check **Syllabus Â§7.2** âš–ï¸.\n",
    "+ ðŸ“¢ **Mandatory Disclosure**:\n",
    "   - Any **websites** ðŸŒ (e.g., **Stack Overflow** ðŸ’¡) or **other resources** used must be **listed and disclosed**.\n",
    "   - Any **GenAI tools** ðŸ¤– (e.g., **ChatGPT**) used must be **explicitly mentioned**.\n",
    "   - ðŸš¨ **Failure to disclose these resources is a violation of academic integrity**. See **Syllabus Â§7.3** for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "aHYGq5RUpSOD",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 0. Setup\n",
    "\n",
    "As in the last lab, we will be using huggingface datasets library ([https://huggingface.co/datasets](https://huggingface.co/datasets)). You can find the detailed documentation and tutorials here: [https://huggingface.co/docs/datasets/en/index](https://huggingface.co/docs/datasets/en/index)\n",
    "\n",
    "If you don't have it installed you can run the code below or install it via `pip` in your terminal. If you are using Google Colab, you can uncomment and run the code below in a code cell. Restarting of the runtime may be required after installation (Runtime/Restart session)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rhEG8hKrpSOE",
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:46:16.100708Z",
     "start_time": "2025-04-20T22:46:16.097873Z"
    }
   },
   "source": [
    "#! pip install -U datasets~=3.5.0\n",
    "#! pip install -U gensim\n",
    "#! python -m pip install -U matplotlib\n",
    "#! pip install nltk\n",
    "#! pip install -U scikit-learn"
   ],
   "outputs": [],
   "execution_count": 89
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Previously installed datasets library version of 3.2.0 had an error when combined with numpy version >2. If you encounter an error at some point it might require to update the datasets library to the newer version. You can do that by running the code below. If you are using Google Colab, you can run the code below in a code cell. If you are using Jupyter Notebook, you can run the code below in a code cell or in a terminal."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:46:16.294957Z",
     "start_time": "2025-04-20T22:46:16.291932Z"
    }
   },
   "source": [
    "# ! pip install --upgrade --force-reinstall datasets\n",
    "# ! pip install --upgrade bottleneck // pandas requires bottleneck v1,3,6 or newer"
   ],
   "outputs": [],
   "execution_count": 90
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "5CCI1TPJpSOF",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As usual, we start by importing some essential Python libraries and we will be using. Apart from `gensim` (which is going to be used for word embeddings), we have already seen the others."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CRe8W4hKpSOF",
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:46:16.322050Z",
     "start_time": "2025-04-20T22:46:16.315063Z"
    }
   },
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datasets\n",
    "import nltk\n",
    "import tqdm\n",
    "import gensim\n",
    "from nltk.corpus import stopwords\n",
    "#\n",
    "# nltk.download('punkt_tab')punkt_tab\n",
    "nltk.download('stopwords')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/apple/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 91
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "NXy-1KiCpSOF",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Load and Preprocess Data\n",
    "\n",
    "*Sentence compression* involves rephrasing sentences to make them shorter while still retaining the original meaning. A reliable compression system would be valuable for mobile devices and could also serve as a component in an extractive summarization system.\n",
    "\n",
    "The dataset we are going to use can be found on [Huggingface](https://huggingface.co/datasets/embedding-data/sentence-compression). It concerns a set of 180,000 pairs of sentences, aka it is a parallel corpus of sentences and their equivalent compressions. It has been collected by harvesting news articles from the Internet where the headline appears to be similar to the first sentence and that property is used to find an \"extractive\" compression of the sentence.\n",
    "\n",
    "For example, for the sentence\n",
    "\n",
    "`\"Regulators Friday shut down a small Florida bank, bringing to 119 the number of US bank failures this year amid mounting loan defaults\"`\n",
    "\n",
    "the compressed equivalent (based on the dataset) is:\n",
    "\n",
    "`\"Regulators shut down small Florida bank\"`.\n",
    "\n",
    "\n",
    "For more information you can read the original paper (from Google) [here](https://aclanthology.org/D13-1155.pdf). We strongly recommend going over the paper to gain further insights. Notice that the paper is from 2013, therefore word embeddings have not been widely introduced yet in NLP tasks, meaning that the methods applied were based on the traditional NLP pipeline (feature extraction + ML)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "ztJX2GRVpSOF",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.1 Loading the Dataset\n",
    "\n",
    "The dataset will be loaded as a Pandas DataFrame. This may take a few minutes because of the large size of the data.\n",
    "\n",
    "Make sure to inspect the dataset and make sure it is imported properly."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tay2NXPTpSOG",
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:46:18.639357Z",
     "start_time": "2025-04-20T22:46:16.700938Z"
    }
   },
   "source": [
    "import nltk.corpus\n",
    "\n",
    "ds = datasets.load_dataset('embedding-data/sentence-compression')\n",
    "print(ds)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['set'],\n",
      "        num_rows: 180000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 92
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bUud3eZVpSOH",
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:46:18.825221Z",
     "start_time": "2025-04-20T22:46:18.820141Z"
    }
   },
   "source": [
    "for i in range(10):\n",
    "    print(ds['train'][i])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'set': [\"The USHL completed an expansion draft on Monday as 10 players who were on the rosters of USHL teams during the 2009-10 season were selected by the League's two newest entries, the Muskegon Lumberjacks and Dubuque Fighting Saints.\", 'USHL completes expansion draft']}\n",
      "{'set': ['Major League Baseball Commissioner Bud Selig will be speaking at St. Norbert College next month.', 'Bud Selig to speak at St. Norbert College']}\n",
      "{'set': [\"It's fresh cherry time in Michigan and the best time to enjoy this delicious and nutritious fruit.\", \"It's cherry time\"]}\n",
      "{'set': ['An Evesham man is facing charges in Pennsylvania after he allegedly dragged his girlfriend from the side of his pickup truck on the campus of Kutztown University in the early morning hours of Dec. 5, police said.', 'Evesham man faces charges for Pa.']}\n",
      "{'set': [\"NRT LLC, one of the nation's largest residential real estate brokerage companies, announced several executive appointments within its Coldwell Banker Residential Brokerage operations in Southern California.\", 'NRT announces executive appointments at its Coldwell Banker operations in Southern California']}\n",
      "{'set': ['THE JSE kept toying with an all time high by midday today as resources continued to fuel the bourse.', 'JSE keeps toying with all time high']}\n",
      "{'set': ['The government is defending the latest police crime statistics despite a worrying rise in the recorded amount of violent offending.', 'Government defends crime statistics']}\n",
      "{'set': ['The renovated Marappalam bridge, which had been opened for two-wheelers last week, was opened for other vehicles also on Friday.', 'Marappalam bridge opened']}\n",
      "{'set': ['A new survey shows 30 percent of Californians use Twitter, and more and more of us are using our smart phones to go online.', 'Survey: 30 percent of Californians use Twitter']}\n",
      "{'set': ['Brightpoint ,a provider of logistic services to the mobile industry, has started operations in the Turkish market.', 'Brightpoint starts operations on Turkish market']}\n"
     ]
    }
   ],
   "execution_count": 93
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "HfJSiWxrpSOH",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The dataset comes with only the `train` split so we will have to split it ourselves."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tATL53MWpSOH",
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:46:18.940385Z",
     "start_time": "2025-04-20T22:46:18.869901Z"
    }
   },
   "source": [
    "split_ds = ds['train'].train_test_split(test_size=0.2)\n",
    "print(split_ds)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['set'],\n",
      "        num_rows: 144000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['set'],\n",
      "        num_rows: 36000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 94
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "L133t3CqpSOH",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.2 Preprocessing the dataset\n",
    "In this section we will prepare the dataset, aka clean the sentences and tokenize.\n",
    "\n",
    "First, let's write the function to clean the text. It can be similar to the one from the previous lab (Lab1) but make sure that it makes sense for this dataset and task.\n",
    "\n",
    "More specifically, think about lower-casing, punctuation, stop-words and lemmatization/stemming and the impact it might have on the dataset. Also reflect on the fact that with word embeddings we want to uncover semantic relationships between words, whereas with bag-of-words we were trying to capture different morphological variations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "mQszN6GNpSOH",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a name='e1'></a>\n",
    "### Exercise 1: Clean function\n",
    "(1p) Fill in the following function ot clean the dataset. Implement at least 3 different steps."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TxjfLQj6pSOH",
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:46:19.115724Z",
     "start_time": "2025-04-20T22:46:19.110522Z"
    }
   },
   "source": [
    "def clean(text):\n",
    "    \"\"\"\n",
    "    Cleans the given text\n",
    "    Args:\n",
    "        text: a str with the text to clean\n",
    "\n",
    "    Returns: a str with the cleaned text\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Empty text\n",
    "    if text == '':\n",
    "        return text\n",
    "\n",
    "    # 'text' from the example can be of type numpy.str_, let's convert it to a python str\n",
    "    text = str(text)\n",
    "\n",
    "    #you might need more\n",
    "    #add them here\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "#those functions delete all uppercase letters but without multiple Capital letters like CNN US.\n",
    "\n",
    "    text = re.sub(r'\\b([A-Z][a-z]+)\\b', lambda m: m.group(1).lower(), text)\n",
    "    text = re.sub(r'\\b([A-Z])(?![A-Z])\\b', lambda m: m.group(1).lower(), text)\n",
    "\n",
    "    #keeps only letters and numbers BUT keeps ' if its between two letters like in the word don't\n",
    "    text = re.sub(r\"(?<!\\w)'|'(?!\\w)\", \"\", text)\n",
    "\n",
    "    #gets rid of all special characters but numbers letters and apostrophes\n",
    "    text = re.sub(r\"[^\\w\\s']\", \"\", text)\n",
    "\n",
    "    #Question to a friend: How did you do the stopping words part? (Caetano Allesie)\n",
    "    #written with help of copilot\n",
    "    stop_words =  set(nltk.corpus.stopwords.words('english'))\n",
    "    words = text.split()\n",
    "    stop_words_words = []\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            stop_words_words.append(word)\n",
    "    text =\" \".join(stop_words_words)\n",
    "    ### YOUR CODE ENDS HERE\n",
    "\n",
    "    text = text.strip()\n",
    "\n",
    "    # Update the example with the cleaned text\n",
    "    return text"
   ],
   "outputs": [],
   "execution_count": 95
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "gAqf1AoupSOJ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The following function will apply the function (sic) you just wrote to the whole dataset. More specifically, it takes the first entry (`sentence`) from the set of uncompressed/compressed pairs, applies the `clean` function and saves the processed sentence in the field `clean_sentence`. The same is dome for the compressed version of the sentence (saved as `clean_compressed`)."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T22:46:19.472488Z",
     "start_time": "2025-04-20T22:46:19.466194Z"
    }
   },
   "cell_type": "code",
   "source": "print(clean(\"'Hers' amunition don't 'aint yay!!!$%# and a \"))",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amunition aint yay\n"
     ]
    }
   ],
   "execution_count": 96
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WZn-M4_vpSOJ",
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:46:19.511575Z",
     "start_time": "2025-04-20T22:46:19.505887Z"
    }
   },
   "source": [
    "def clean_dataset(example):\n",
    "    \"\"\"\n",
    "    Cleans the sentence and compressed sentence in the example from the Dataset\n",
    "    Args:\n",
    "        example: an example from the Dataset\n",
    "\n",
    "    Returns: updated example with 'clean_sentence' and 'clean_compressed' cleaned\n",
    "\n",
    "    \"\"\"\n",
    "    sentence, compressed = example['set']\n",
    "    clean_sentence = clean(sentence)\n",
    "    clean_compressed = clean(compressed)\n",
    "    example['clean_sentence'] = clean_sentence\n",
    "    example['clean_compressed'] = clean_compressed\n",
    "    return example"
   ],
   "outputs": [],
   "execution_count": 97
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "_KVujosKpSOJ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Below we apply the function to the whole dataset (using `map`) and we can also inspect the result."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NBS1JbISpSOJ",
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:47:44.037499Z",
     "start_time": "2025-04-20T22:46:19.872956Z"
    }
   },
   "source": [
    "split_ds = split_ds.map(clean_dataset)\n",
    "print(split_ds)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/144000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1b9f573930bb4af5bd14a27822f85b98"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/36000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8a21ec3b339b4c22b4c9ea51ee6d9511"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['set', 'clean_sentence', 'clean_compressed'],\n",
      "        num_rows: 144000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['set', 'clean_sentence', 'clean_compressed'],\n",
      "        num_rows: 36000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 98
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "X_ThE9H-pSOJ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's examine some examples from the dataset and make sure that we got the results we wanted. At this step, it might be necessary to revisit some pre-processing steps if you are not happy with the results."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hP-qOPijpSOJ",
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:47:44.225677Z",
     "start_time": "2025-04-20T22:47:44.219998Z"
    }
   },
   "source": [
    "for i in range(10):\n",
    "    print(split_ds['train'][i])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'set': ['LONDON - Drugmaker AstraZeneca PLC says it is abandoning plans to develop a new anti-ovarian cancer drug and also says a planned antidepressant has underperformed in tests.', 'AstraZeneca abandoning anti-ovarian cancer drug'], 'clean_sentence': 'LONDON drugmaker AstraZeneca PLC says abandoning plans develop new antiovarian cancer drug also says planned antidepressant underperformed tests', 'clean_compressed': 'AstraZeneca abandoning antiovarian cancer drug'}\n",
      "{'set': ['Chennai, Aug 1 Tata Motors logged 15 percent sales growth in July over the corresponding month in 2011.', 'Tata Motors logs 15 percent sales growth'], 'clean_sentence': 'chennai aug 1 tata motors logged 15 percent sales growth july corresponding month 2011', 'clean_compressed': 'tata motors logs 15 percent sales growth'}\n",
      "{'set': [\"The three-day long Monthly Urmi Inter-District Women's Badminton Competition begins tomorrow at the gymnasium of Dhanmondi Women's Sports Complex.\", \"Inter-District Women's badminton begins tomorrow\"], 'clean_sentence': \"threeday long monthly urmi interdistrict women's badminton competition begins tomorrow gymnasium dhanmondi women's sports complex\", 'clean_compressed': \"interdistrict women's badminton begins tomorrow\"}\n",
      "{'set': ['Australian businesses are still keen to go green, despite the current downturn and the costs involved, according to a survey conducted by Grant Thornton.', 'Aussie Business keen to go green'], 'clean_sentence': 'australian businesses still keen go green despite current downturn costs involved according survey conducted grant thornton', 'clean_compressed': 'aussie business keen go green'}\n",
      "{'set': ['A triathlon will be held at Gustavus Adolphus College Saturday, April 25th to benefit juvenile diabetes through Triabetes, a project of Insulindependence.', 'Triathlon to benefit juvenile diabetes'], 'clean_sentence': 'triathlon held gustavus adolphus college saturday april 25th benefit juvenile diabetes triabetes project insulindependence', 'clean_compressed': 'triathlon benefit juvenile diabetes'}\n",
      "{'set': ['Unlike his predecesors Kiro Gligorov, Boris Trajkovski and Branko Crvenkovski, he will begin the 5-year mandate at the newly-built premises in Skopje Gjorge Ivanov will be inaugurated as President of the Former Republic of Macedonia on Tuesday.', 'Gjorge Ivanov to be inaugurated as President on Tuesday'], 'clean_sentence': 'unlike predecesors kiro gligorov boris trajkovski branko crvenkovski begin 5year mandate newlybuilt premises skopje gjorge ivanov inaugurated president former republic macedonia tuesday', 'clean_compressed': 'gjorge ivanov inaugurated president tuesday'}\n",
      "{'set': ['While Wisconsin was trying to balance a $3.6 billion deficit in 2011, the State Patrol spent about $54,000 on an aerial patrol program aimed at catching speeders.', 'State Patrol aerial program is catching speeders'], 'clean_sentence': 'wisconsin trying balance 36 billion deficit 2011 state patrol spent 54000 aerial patrol program aimed catching speeders', 'clean_compressed': 'state patrol aerial program catching speeders'}\n",
      "{'set': [\"The former chief investigator for the state medical examiner's office was charged Thursday with four counts of sexual battery for allegedly groping and propositioning two female co-workers.\", 'Former chief investigator for me charged'], 'clean_sentence': \"former chief investigator state medical examiner's office charged thursday four counts sexual battery allegedly groping propositioning two female coworkers\", 'clean_compressed': 'former chief investigator charged'}\n",
      "{'set': ['Azerbaijan will continue measures to protect ozone layer of the stratosphere in line with commitments taken before the world community.', 'Azerbaijan to continue measures to protect ozone layer'], 'clean_sentence': 'azerbaijan continue measures protect ozone layer stratosphere line commitments taken world community', 'clean_compressed': 'azerbaijan continue measures protect ozone layer'}\n",
      "{'set': ['Techno music is not dead in Berlin, music journalist Tobias Rapp argues.', \"Techno's not dead:\"], 'clean_sentence': 'techno music dead berlin music journalist tobias rapp argues', 'clean_compressed': \"techno's dead\"}\n"
     ]
    }
   ],
   "execution_count": 99
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "7LI2KlfypSOJ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a name='e2'></a>\n",
    "### Exercise 2: Tokenize function\n",
    "\n",
    "(1p) As always, we will need to tokenize the dataset in order to create bat-of-words and TF-IDF representations in the next sections. We will use the [Natural Language Toolkit (NLTK) library]([https://www.nltk.org/]) (https://www.nltk.org/). Complete the following function to split the text into tokens using the `word_tokenize()` function. Check the [documentation](https://www.nltk.org/api/nltk.tokenize.word_tokenize.html?highlight=word_tokenize) first.\n",
    "Note that there are different tokenizers e.g. `RegexpTokenizer` where you can enter your own regexp, `WhitespaceTokenizer` (similar to Python's string.split()) and `BlanklineTokenizer`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sb-M3V6ApSOK",
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:47:44.276863Z",
     "start_time": "2025-04-20T22:47:44.273411Z"
    }
   },
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Tokenizes the `text` parameter using nltk library\n",
    "    Args:\n",
    "        text: a string representing a sentence to be tokenized\n",
    "\n",
    "    Returns: a list of tokens (strings)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    ### YOUR CODE ENDS HERE\n",
    "    return tokens"
   ],
   "outputs": [],
   "execution_count": 100
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "gwsHqZc9pSOK",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next, the function will be applied to the whole dataset (as we did with the pre-processing) and `sentence_tokens` field will be created to store the result."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6sTX-AcTpSOK",
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:47:44.590620Z",
     "start_time": "2025-04-20T22:47:44.586883Z"
    }
   },
   "source": [
    "def tokenize_dataset(example):\n",
    "    \"\"\"\n",
    "    Tokenizes 'clean_sentence' columns in the example from the Dataset\n",
    "    Args:\n",
    "        example: an example from the Dataset\n",
    "\n",
    "    Returns: updated example with 'sentence_tokens' columns\n",
    "\n",
    "    \"\"\"\n",
    "    example['sentence_tokens'] = tokenize(example['clean_sentence'])\n",
    "    example['compressed_tokens'] = tokenize(example['clean_compressed'])\n",
    "    return example"
   ],
   "outputs": [],
   "execution_count": 101
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jvwmXLj2pSOK",
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:48:27.128769Z",
     "start_time": "2025-04-20T22:47:44.770883Z"
    }
   },
   "source": [
    "split_ds = split_ds.map(tokenize_dataset)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/144000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "849d42235e2149d1a05e3a617f0b46ea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/36000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5af15f0df4214a108fe2460b590167c6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 102
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yXnje31SpSOK",
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:48:27.300940Z",
     "start_time": "2025-04-20T22:48:27.291834Z"
    }
   },
   "source": [
    "for i in range(10):\n",
    "    print(split_ds['train'][i])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'set': ['LONDON - Drugmaker AstraZeneca PLC says it is abandoning plans to develop a new anti-ovarian cancer drug and also says a planned antidepressant has underperformed in tests.', 'AstraZeneca abandoning anti-ovarian cancer drug'], 'clean_sentence': 'LONDON drugmaker AstraZeneca PLC says abandoning plans develop new antiovarian cancer drug also says planned antidepressant underperformed tests', 'clean_compressed': 'AstraZeneca abandoning antiovarian cancer drug', 'sentence_tokens': ['LONDON', 'drugmaker', 'AstraZeneca', 'PLC', 'says', 'abandoning', 'plans', 'develop', 'new', 'antiovarian', 'cancer', 'drug', 'also', 'says', 'planned', 'antidepressant', 'underperformed', 'tests'], 'compressed_tokens': ['AstraZeneca', 'abandoning', 'antiovarian', 'cancer', 'drug']}\n",
      "{'set': ['Chennai, Aug 1 Tata Motors logged 15 percent sales growth in July over the corresponding month in 2011.', 'Tata Motors logs 15 percent sales growth'], 'clean_sentence': 'chennai aug 1 tata motors logged 15 percent sales growth july corresponding month 2011', 'clean_compressed': 'tata motors logs 15 percent sales growth', 'sentence_tokens': ['chennai', 'aug', '1', 'tata', 'motors', 'logged', '15', 'percent', 'sales', 'growth', 'july', 'corresponding', 'month', '2011'], 'compressed_tokens': ['tata', 'motors', 'logs', '15', 'percent', 'sales', 'growth']}\n",
      "{'set': [\"The three-day long Monthly Urmi Inter-District Women's Badminton Competition begins tomorrow at the gymnasium of Dhanmondi Women's Sports Complex.\", \"Inter-District Women's badminton begins tomorrow\"], 'clean_sentence': \"threeday long monthly urmi interdistrict women's badminton competition begins tomorrow gymnasium dhanmondi women's sports complex\", 'clean_compressed': \"interdistrict women's badminton begins tomorrow\", 'sentence_tokens': ['threeday', 'long', 'monthly', 'urmi', 'interdistrict', 'women', \"'s\", 'badminton', 'competition', 'begins', 'tomorrow', 'gymnasium', 'dhanmondi', 'women', \"'s\", 'sports', 'complex'], 'compressed_tokens': ['interdistrict', 'women', \"'s\", 'badminton', 'begins', 'tomorrow']}\n",
      "{'set': ['Australian businesses are still keen to go green, despite the current downturn and the costs involved, according to a survey conducted by Grant Thornton.', 'Aussie Business keen to go green'], 'clean_sentence': 'australian businesses still keen go green despite current downturn costs involved according survey conducted grant thornton', 'clean_compressed': 'aussie business keen go green', 'sentence_tokens': ['australian', 'businesses', 'still', 'keen', 'go', 'green', 'despite', 'current', 'downturn', 'costs', 'involved', 'according', 'survey', 'conducted', 'grant', 'thornton'], 'compressed_tokens': ['aussie', 'business', 'keen', 'go', 'green']}\n",
      "{'set': ['A triathlon will be held at Gustavus Adolphus College Saturday, April 25th to benefit juvenile diabetes through Triabetes, a project of Insulindependence.', 'Triathlon to benefit juvenile diabetes'], 'clean_sentence': 'triathlon held gustavus adolphus college saturday april 25th benefit juvenile diabetes triabetes project insulindependence', 'clean_compressed': 'triathlon benefit juvenile diabetes', 'sentence_tokens': ['triathlon', 'held', 'gustavus', 'adolphus', 'college', 'saturday', 'april', '25th', 'benefit', 'juvenile', 'diabetes', 'triabetes', 'project', 'insulindependence'], 'compressed_tokens': ['triathlon', 'benefit', 'juvenile', 'diabetes']}\n",
      "{'set': ['Unlike his predecesors Kiro Gligorov, Boris Trajkovski and Branko Crvenkovski, he will begin the 5-year mandate at the newly-built premises in Skopje Gjorge Ivanov will be inaugurated as President of the Former Republic of Macedonia on Tuesday.', 'Gjorge Ivanov to be inaugurated as President on Tuesday'], 'clean_sentence': 'unlike predecesors kiro gligorov boris trajkovski branko crvenkovski begin 5year mandate newlybuilt premises skopje gjorge ivanov inaugurated president former republic macedonia tuesday', 'clean_compressed': 'gjorge ivanov inaugurated president tuesday', 'sentence_tokens': ['unlike', 'predecesors', 'kiro', 'gligorov', 'boris', 'trajkovski', 'branko', 'crvenkovski', 'begin', '5year', 'mandate', 'newlybuilt', 'premises', 'skopje', 'gjorge', 'ivanov', 'inaugurated', 'president', 'former', 'republic', 'macedonia', 'tuesday'], 'compressed_tokens': ['gjorge', 'ivanov', 'inaugurated', 'president', 'tuesday']}\n",
      "{'set': ['While Wisconsin was trying to balance a $3.6 billion deficit in 2011, the State Patrol spent about $54,000 on an aerial patrol program aimed at catching speeders.', 'State Patrol aerial program is catching speeders'], 'clean_sentence': 'wisconsin trying balance 36 billion deficit 2011 state patrol spent 54000 aerial patrol program aimed catching speeders', 'clean_compressed': 'state patrol aerial program catching speeders', 'sentence_tokens': ['wisconsin', 'trying', 'balance', '36', 'billion', 'deficit', '2011', 'state', 'patrol', 'spent', '54000', 'aerial', 'patrol', 'program', 'aimed', 'catching', 'speeders'], 'compressed_tokens': ['state', 'patrol', 'aerial', 'program', 'catching', 'speeders']}\n",
      "{'set': [\"The former chief investigator for the state medical examiner's office was charged Thursday with four counts of sexual battery for allegedly groping and propositioning two female co-workers.\", 'Former chief investigator for me charged'], 'clean_sentence': \"former chief investigator state medical examiner's office charged thursday four counts sexual battery allegedly groping propositioning two female coworkers\", 'clean_compressed': 'former chief investigator charged', 'sentence_tokens': ['former', 'chief', 'investigator', 'state', 'medical', 'examiner', \"'s\", 'office', 'charged', 'thursday', 'four', 'counts', 'sexual', 'battery', 'allegedly', 'groping', 'propositioning', 'two', 'female', 'coworkers'], 'compressed_tokens': ['former', 'chief', 'investigator', 'charged']}\n",
      "{'set': ['Azerbaijan will continue measures to protect ozone layer of the stratosphere in line with commitments taken before the world community.', 'Azerbaijan to continue measures to protect ozone layer'], 'clean_sentence': 'azerbaijan continue measures protect ozone layer stratosphere line commitments taken world community', 'clean_compressed': 'azerbaijan continue measures protect ozone layer', 'sentence_tokens': ['azerbaijan', 'continue', 'measures', 'protect', 'ozone', 'layer', 'stratosphere', 'line', 'commitments', 'taken', 'world', 'community'], 'compressed_tokens': ['azerbaijan', 'continue', 'measures', 'protect', 'ozone', 'layer']}\n",
      "{'set': ['Techno music is not dead in Berlin, music journalist Tobias Rapp argues.', \"Techno's not dead:\"], 'clean_sentence': 'techno music dead berlin music journalist tobias rapp argues', 'clean_compressed': \"techno's dead\", 'sentence_tokens': ['techno', 'music', 'dead', 'berlin', 'music', 'journalist', 'tobias', 'rapp', 'argues'], 'compressed_tokens': ['techno', \"'s\", 'dead']}\n"
     ]
    }
   ],
   "execution_count": 103
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "FeF0wFd0pSOL",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Since we will need the tokenized sentences, we can use the following statement to extract them from the `train` split of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qYKfXFxQpSOL",
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:48:30.433995Z",
     "start_time": "2025-04-20T22:48:27.312068Z"
    }
   },
   "source": [
    "tokenized_sentences = split_ds['train']['sentence_tokens']\n",
    "print(len(tokenized_sentences))\n",
    "print(tokenized_sentences[:10])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144000\n",
      "[['LONDON', 'drugmaker', 'AstraZeneca', 'PLC', 'says', 'abandoning', 'plans', 'develop', 'new', 'antiovarian', 'cancer', 'drug', 'also', 'says', 'planned', 'antidepressant', 'underperformed', 'tests'], ['chennai', 'aug', '1', 'tata', 'motors', 'logged', '15', 'percent', 'sales', 'growth', 'july', 'corresponding', 'month', '2011'], ['threeday', 'long', 'monthly', 'urmi', 'interdistrict', 'women', \"'s\", 'badminton', 'competition', 'begins', 'tomorrow', 'gymnasium', 'dhanmondi', 'women', \"'s\", 'sports', 'complex'], ['australian', 'businesses', 'still', 'keen', 'go', 'green', 'despite', 'current', 'downturn', 'costs', 'involved', 'according', 'survey', 'conducted', 'grant', 'thornton'], ['triathlon', 'held', 'gustavus', 'adolphus', 'college', 'saturday', 'april', '25th', 'benefit', 'juvenile', 'diabetes', 'triabetes', 'project', 'insulindependence'], ['unlike', 'predecesors', 'kiro', 'gligorov', 'boris', 'trajkovski', 'branko', 'crvenkovski', 'begin', '5year', 'mandate', 'newlybuilt', 'premises', 'skopje', 'gjorge', 'ivanov', 'inaugurated', 'president', 'former', 'republic', 'macedonia', 'tuesday'], ['wisconsin', 'trying', 'balance', '36', 'billion', 'deficit', '2011', 'state', 'patrol', 'spent', '54000', 'aerial', 'patrol', 'program', 'aimed', 'catching', 'speeders'], ['former', 'chief', 'investigator', 'state', 'medical', 'examiner', \"'s\", 'office', 'charged', 'thursday', 'four', 'counts', 'sexual', 'battery', 'allegedly', 'groping', 'propositioning', 'two', 'female', 'coworkers'], ['azerbaijan', 'continue', 'measures', 'protect', 'ozone', 'layer', 'stratosphere', 'line', 'commitments', 'taken', 'world', 'community'], ['techno', 'music', 'dead', 'berlin', 'music', 'journalist', 'tobias', 'rapp', 'argues']]\n"
     ]
    }
   ],
   "execution_count": 104
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:48:31.840940Z",
     "start_time": "2025-04-20T22:48:30.593498Z"
    }
   },
   "source": [
    "tokenized_compressed = split_ds['train']['compressed_tokens']\n",
    "print(len(tokenized_compressed))\n",
    "print(tokenized_compressed[:10])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144000\n",
      "[['AstraZeneca', 'abandoning', 'antiovarian', 'cancer', 'drug'], ['tata', 'motors', 'logs', '15', 'percent', 'sales', 'growth'], ['interdistrict', 'women', \"'s\", 'badminton', 'begins', 'tomorrow'], ['aussie', 'business', 'keen', 'go', 'green'], ['triathlon', 'benefit', 'juvenile', 'diabetes'], ['gjorge', 'ivanov', 'inaugurated', 'president', 'tuesday'], ['state', 'patrol', 'aerial', 'program', 'catching', 'speeders'], ['former', 'chief', 'investigator', 'charged'], ['azerbaijan', 'continue', 'measures', 'protect', 'ozone', 'layer'], ['techno', \"'s\", 'dead']]\n"
     ]
    }
   ],
   "execution_count": 105
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDGwEiZeCA5U",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Notice the difference in the types of the different structures we use. Run the following cell to check the types. Do they make sense to you?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wKrkFmcZCtOd",
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:48:36.763575Z",
     "start_time": "2025-04-20T22:48:32.007054Z"
    }
   },
   "source": [
    "#type of original dataset\n",
    "print(type(split_ds))\n",
    "print(\"--\")\n",
    "#type of original sentence\n",
    "print(split_ds['train'][1])\n",
    "print(type(split_ds['train'][1]))\n",
    "print(\"--\")\n",
    "#type of pre-proceesed sentence\n",
    "print(split_ds['train']['clean_sentence'][1])\n",
    "print(type(split_ds['train']['clean_sentence'][1]))\n",
    "print(\"--\")\n",
    "#type of tokenized sentence\n",
    "print(split_ds['train']['sentence_tokens'][1])\n",
    "print(type(split_ds['train']['sentence_tokens'][1]))\n",
    "print(\"--\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.dataset_dict.DatasetDict'>\n",
      "--\n",
      "{'set': ['Chennai, Aug 1 Tata Motors logged 15 percent sales growth in July over the corresponding month in 2011.', 'Tata Motors logs 15 percent sales growth'], 'clean_sentence': 'chennai aug 1 tata motors logged 15 percent sales growth july corresponding month 2011', 'clean_compressed': 'tata motors logs 15 percent sales growth', 'sentence_tokens': ['chennai', 'aug', '1', 'tata', 'motors', 'logged', '15', 'percent', 'sales', 'growth', 'july', 'corresponding', 'month', '2011'], 'compressed_tokens': ['tata', 'motors', 'logs', '15', 'percent', 'sales', 'growth']}\n",
      "<class 'dict'>\n",
      "--\n",
      "chennai aug 1 tata motors logged 15 percent sales growth july corresponding month 2011\n",
      "<class 'str'>\n",
      "--\n",
      "['chennai', 'aug', '1', 'tata', 'motors', 'logged', '15', 'percent', 'sales', 'growth', 'july', 'corresponding', 'month', '2011']\n",
      "<class 'list'>\n",
      "--\n"
     ]
    }
   ],
   "execution_count": 106
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Bag of Words\n",
    "In this section you will built a bag-of-words representation of the dataset. We will use numpy arrays to store the results. The bag-of-words representation is a simple and effective way to represent text data. It involves creating a vocabulary of unique words from the dataset and representing each sentence as a vector of word counts. We first need the vocabulary, which we will build from both the full sentences and the compressed sentences. Similar to the first lab, the vocabulary will be a list of unique words from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a name='e3'></a>\n",
    "### Exercise 3: Extracting vocabulary counts\n",
    "\n",
    "(1p) In the following cell, you will implement a function that takes a list of tokenized sentences and returns a dictionary with the counts of each word in the vocabulary. The dictionary should be of the form {word: count}. As in previous lab, you will use the `Counter` class from the `collections` module to do this."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:48:36.918176Z",
     "start_time": "2025-04-20T22:48:36.914817Z"
    }
   },
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "def extract_vocabulary_counts(tokenized_sentences):\n",
    "    \"\"\"\n",
    "    Extracts the vocabulary from the tokenized sentences\n",
    "    Args:\n",
    "        tokenized_sentences: a list of lists of tokens\n",
    "\n",
    "    Returns: a Counter object with the counts of each word in the vocabulary\n",
    "    \"\"\"\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    # copilot used when writing the code\n",
    "    counter = Counter()\n",
    "    for sentence in tokenized_sentences:\n",
    "        counter.update(sentence)\n",
    "    return counter\n",
    "    ### YOUR CODE ENDS HERE"
   ],
   "outputs": [],
   "execution_count": 107
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:48:38.239859Z",
     "start_time": "2025-04-20T22:48:37.247372Z"
    }
   },
   "source": [
    "vocab_counter = extract_vocabulary_counts(tokenized_sentences + tokenized_compressed)\n",
    "print(len(vocab_counter))\n",
    "print(vocab_counter.most_common(10))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122544\n",
      "[(\"'s\", 28972), ('new', 19918), ('said', 19904), ('man', 11964), ('US', 10596), ('today', 10081), ('police', 9724), ('two', 9276), ('first', 8057), ('announced', 7725)]\n"
     ]
    }
   ],
   "execution_count": 108
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As you can see the size of the vocabulary is quite large. Like the last time, we will limit the vocabulary to the most frequent words. The next cell will create a dictionary that maps each word to an index in the vocabulary. This will be used to create the bag-of-words representation of the sentences."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:48:38.666394Z",
     "start_time": "2025-04-20T22:48:38.251464Z"
    }
   },
   "source": [
    "vocab_size = 10_000\n",
    "vocab = vocab_counter.most_common(vocab_size)\n",
    "token_to_id = {word: i for i, (word, _) in enumerate(vocab)}\n",
    "print(token_to_id)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"'s\": 0, 'new': 1, 'said': 2, 'man': 3, 'US': 4, 'today': 5, 'police': 6, 'two': 7, 'first': 8, 'announced': 9, 'tuesday': 10, 'year': 11, 'monday': 12, 'wednesday': 13, 'thursday': 14, 'state': 15, 'friday': 16, 'president': 17, 'says': 18, 'former': 19, 'world': 20, 'one': 21, 'million': 22, 'city': 23, 'county': 24, 'last': 25, 'according': 26, 'may': 27, 'woman': 28, 'saturday': 29, 'week': 30, 'sunday': 31, 'minister': 32, 'government': 33, 'company': 34, 'years': 35, 'three': 36, 'people': 37, 'home': 38, 'india': 39, 'night': 40, 'time': 41, 'killed': 42, 'bank': 43, 'national': 44, 'south': 45, 'day': 46, 'next': 47, 'arrested': 48, 'court': 49, 'morning': 50, 'found': 51, 'charged': 52, 'died': 53, 'country': 54, 'set': 55, 'school': 56, 'obama': 57, 'would': 58, 'could': 59, 'second': 60, 'back': 61, 'group': 62, 'reported': 63, 'market': 64, 'fire': 65, 'china': 66, 'international': 67, 'team': 68, 'open': 69, 'season': 70, 'business': 71, 'house': 72, 'oil': 73, 'service': 74, 'charges': 75, 'car': 76, 'early': 77, 'prices': 78, 'north': 79, 'reports': 80, 'news': 81, 'star': 82, 'united': 83, 'inc': 84, 'high': 85, 'officials': 86, 'month': 87, 'global': 88, 'dies': 89, 'report': 90, 'public': 91, 'death': 92, 'following': 93, 'plans': 94, 'guilty': 95, 'four': 96, 'hospital': 97, 'billion': 98, 'yesterday': 99, 'services': 100, 'released': 101, 'health': 102, 'federal': 103, 'league': 104, 'american': 105, 'near': 106, 'chief': 107, 'office': 108, 'say': 109, 'pakistan': 110, 'york': 111, 'hit': 112, 'end': 113, 'help': 114, 'show': 115, 'west': 116, 'financial': 117, 'made': 118, '2012': 119, 'security': 120, 'game': 121, 'percent': 122, 'months': 123, 'accused': 124, '10': 125, 'make': 126, 'take': 127, 'indian': 128, 'five': 129, 'coach': 130, 'another': 131, 'economic': 132, 'per': 133, 'local': 134, 'top': 135, 'john': 136, 'play': 137, 'launched': 138, 'announces': 139, 'british': 140, 'power': 141, 'expected': 142, 'official': 143, 'life': 144, 'women': 145, 'center': 146, 'part': 147, 'dead': 148, 'third': 149, 'jobs': 150, 'work': 151, 'european': 152, 'launches': 153, 'university': 154, 'major': 155, 'trade': 156, 'party': 157, 'leader': 158, 'deal': 159, 'general': 160, 'held': 161, 'record': 162, 'crash': 163, '1': 164, 'energy': 165, 'cup': 166, 'march': 167, 'told': 168, 'left': 169, 'win': 170, 'cut': 171, 'media': 172, 'men': 173, 'return': 174, 'get': 175, 'UK': 176, 'stocks': 177, 'shot': 178, 'close': 179, 'officer': 180, 'support': 181, 'days': 182, 'due': 183, 'states': 184, 'gas': 185, '2010': 186, 'online': 187, 'street': 188, 'air': 189, 'child': 190, 'club': 191, 'bill': 192, 'free': 193, 'since': 194, 'department': 195, 'economy': 196, 'children': 197, 'area': 198, 'weekend': 199, 'central': 200, 'launch': 201, '2011': 202, 'head': 203, 'six': 204, 'district': 205, 'drug': 206, 'sales': 207, 'foreign': 208, 'family': 209, 'capital': 210, 'still': 211, 'injured': 212, 'prime': 213, 'release': 214, 'series': 215, 'london': 216, 'start': 217, 'visit': 218, 'mobile': 219, 'road': 220, 'shares': 221, 'military': 222, 'face': 223, 'including': 224, '2': 225, 'called': 226, 'afternoon': 227, 'tour': 228, 'quarter': 229, 'dollar': 230, 'australia': 231, '20': 232, 'st': 233, 'development': 234, 'park': 235, 'tax': 236, 'june': 237, 'attack': 238, 'board': 239, 'campaign': 240, 'fall': 241, 'students': 242, 'iran': 243, 'best': 244, 'industry': 245, 'david': 246, 'system': 247, 'despite': 248, 'stock': 249, 'april': 250, 'fell': 251, 'like': 252, 'football': 253, 'signed': 254, 'wins': 255, 'film': 256, 'final': 257, 'australian': 258, 'across': 259, 'east': 260, 'water': 261, 'data': 262, 'barack': 263, 'corp': 264, 'way': 265, 'go': 266, 'sentenced': 267, 'cancer': 268, 'plan': 269, 'markets': 270, 'council': 271, '11': 272, 'growth': 273, 'meeting': 274, '2009': 275, 'pay': 276, 'manager': 277, 'management': 278, 'talks': 279, 'big': 280, 'actor': 281, 'around': 282, '2013': 283, 'money': 284, 'washington': 285, 'afghanistan': 286, 'research': 287, 'revealed': 288, 'price': 289, 'run': 290, 'england': 291, 'buy': 292, 'authorities': 293, 'leading': 294, 'program': 295, 'late': 296, '30': 297, 'contract': 298, 'food': 299, 'law': 300, 'move': 301, 'gold': 302, 'allegedly': 303, 'chinese': 304, 'case': 305, 'host': 306, 'largest': 307, 'conference': 308, 'director': 309, 'number': 310, 'games': 311, 'agency': 312, 'prison': 313, 'san': 314, 'political': 315, 'agreement': 316, '15': 317, '3': 318, 'confirmed': 319, 'white': 320, 'rate': 321, 'wants': 322, 'test': 323, 'community': 324, 'annual': 325, 'hold': 326, 'girl': 327, 'several': 328, 'network': 329, 'union': 330, 'music': 331, 'increase': 332, 'crisis': 333, '12': 334, 'july': 335, 'closed': 336, 'recent': 337, 'russia': 338, 'firm': 339, 'michael': 340, 'murder': 341, 'town': 342, 'america': 343, 'medical': 344, 'budget': 345, 'saying': 346, 'higher': 347, 'surgery': 348, 'good': 349, 'technology': 350, 'TV': 351, 'press': 352, 'private': 353, 'investment': 354, 'workers': 355, 'companies': 356, 'lead': 357, 'recently': 358, 'young': 359, 'red': 360, 'right': 361, 'secretary': 362, 'rise': 363, 'making': 364, 'college': 365, 'continue': 366, 'japan': 367, 'special': 368, 'canada': 369, 'actress': 370, 'well': 371, 'use': 372, 'age': 373, 'nearly': 374, 'latest': 375, 'wife': 376, 'provider': 377, 'away': 378, 'share': 379, 'demand': 380, 'study': 381, 'opened': 382, 'shooting': 383, 'rose': 384, 'korea': 385, '5': 386, 'french': 387, 'senior': 388, 'become': 389, 'taking': 390, 'cent': 391, 'place': 392, 'offer': 393, 'sex': 394, 'many': 395, 'fight': 396, 'texas': 397, 'congress': 398, 'store': 399, 'body': 400, 'election': 401, 'going': 402, 'production': 403, 'care': 404, 'line': 405, 'accident': 406, 'assault': 407, 'southern': 408, 'trial': 409, 'january': 410, 'live': 411, 'action': 412, 'senate': 413, 'likely': 414, 'rights': 415, 'credit': 416, 'meet': 417, 'region': 418, 'rates': 419, 'israel': 420, 'named': 421, 'lower': 422, 'weeks': 423, 'opens': 424, 'judge': 425, 'social': 426, 'updated': 427, 'baby': 428, 'war': 429, 'signs': 430, 'presidential': 431, 'investors': 432, 'emergency': 433, 'sign': 434, 'also': 435, 'forces': 436, 'mark': 437, 'video': 438, 'los': 439, 'rs': 440, 'facing': 441, 'long': 442, 'singer': 443, 'centre': 444, 'governor': 445, 'debt': 446, 'apple': 447, 'coast': 448, 'trading': 449, 'faces': 450, 'ahead': 451, 'charge': 452, 'africa': 453, 'hours': 454, '100': 455, 'loss': 456, 'filed': 457, 'title': 458, 'strong': 459, 'even': 460, 'times': 461, 'members': 462, '2008': 463, 'google': 464, 'information': 465, 'premier': 466, 'russian': 467, 'player': 468, 'points': 469, 'europe': 470, 'february': 471, 'grand': 472, 'profit': 473, 'products': 474, 'small': 475, 'building': 476, 'fund': 477, 'past': 478, 'plant': 479, 'working': 480, 'paul': 481, 'leaders': 482, 'ministry': 483, 'pleaded': 484, 'driver': 485, 'executive': 486, 'nation': 487, 'california': 488, 'pleads': 489, 'ago': 490, 'side': 491, 'angeles': 492, 'without': 493, 'bus': 494, 'real': 495, 'calls': 496, 'nuclear': 497, 'amid': 498, 'summer': 499, 'leave': 500, 'issued': 501, 'boy': 502, 'results': 503, 'interest': 504, 'german': 505, 'race': 506, 'players': 507, 'future': 508, 'project': 509, 'chairman': 510, 'september': 511, 'force': 512, 'call': 513, '4': 514, 'pm': 515, 'fourth': 516, 'order': 517, 'heart': 518, 'france': 519, 'agreed': 520, 'least': 521, 'banks': 522, '25': 523, 'delhi': 524, 'student': 525, 'took': 526, 'beat': 527, 'seven': 528, 'software': 529, 'falls': 530, 'old': 531, 'florida': 532, 'residents': 533, 'army': 534, 'role': 535, 'asian': 536, 'traffic': 537, 'northern': 538, 'reportedly': 539, 'lost': 540, 'exchange': 541, 'site': 542, 'opening': 543, 'taken': 544, 'makes': 545, 'november': 546, 'human': 547, 'sell': 548, 'cuts': 549, 'returns': 550, 'coming': 551, 'earlier': 552, 'education': 553, 'victory': 554, 'cash': 555, 'stop': 556, 'james': 557, 'bid': 558, 'canadian': 559, 'corporation': 560, 'claims': 561, 'come': 562, 'operations': 563, 'change': 564, 'us': 565, 'injury': 566, 'schools': 567, 'need': 568, 'republican': 569, 'control': 570, 'october': 571, 'half': 572, 'airlines': 573, 'policy': 574, 'round': 575, 'fans': 576, '13': 577, 'river': 578, 'sector': 579, 'forward': 580, 'planning': 581, 'brown': 582, 'website': 583, 'looking': 584, '14': 585, '21': 586, 'august': 587, 'internet': 588, 'match': 589, 'great': 590, 'continues': 591, 'gov': 592, 'suspended': 593, 'airport': 594, 'station': 595, '16': 596, 'jail': 597, 'strike': 598, 'co': 599, 'issues': 600, 'evening': 601, 'arrest': 602, 'issue': 603, 'association': 604, 'domestic': 605, '18': 606, 'offering': 607, 'killing': 608, 'missing': 609, 'keep': 610, 'chris': 611, 'running': 612, 'training': 613, '50': 614, 'much': 615, 'december': 616, 'lake': 617, 'job': 618, 'israeli': 619, 'black': 620, 'train': 621, 'countries': 622, 'parliament': 623, 'key': 624, 'george': 625, 'hall': 626, 'biggest': 627, 'raise': 628, 'consumer': 629, 'driving': 630, 'must': 631, 'remain': 632, 'guard': 633, 'used': 634, 'insurance': 635, 'construction': 636, 'album': 637, 'commission': 638, 'remains': 639, 'island': 640, 'britain': 641, 'got': 642, 'green': 643, 'better': 644, 'property': 645, 'vote': 646, 'giant': 647, 'son': 648, 'manchester': 649, 'session': 650, 'african': 651, 'soon': 652, 'sale': 653, 'led': 654, '6': 655, 'ended': 656, 'ready': 657, 'weather': 658, 'customers': 659, 'event': 660, 'vehicle': 661, 'current': 662, 'shows': 663, '7': 664, 'join': 665, 'takes': 666, 'getting': 667, 'sports': 668, 'sexual': 669, 'safety': 670, 'mother': 671, 'chicago': 672, 'western': 673, 'eight': 674, 'full': 675, 'put': 676, 'post': 677, 'investigating': 678, 'received': 679, 'trying': 680, 'statement': 681, 'member': 682, 'officers': 683, 'low': 684, 'sold': 685, 'bankruptcy': 686, 'sen': 687, 'see': 688, 'brand': 689, 'singh': 690, 'little': 691, 'facebook': 692, 'troops': 693, 'announce': 694, 'level': 695, 'want': 696, 'committee': 697, 'euro': 698, 'awards': 699, 'sri': 700, 'cricket': 701, 'tonight': 702, '17': 703, 'turkey': 704, '8': 705, 'field': 706, 'search': 707, 'among': 708, 'champion': 709, '22': 710, 'target': 711, 'give': 712, 'robert': 713, 'finance': 714, 'debut': 715, 'fuel': 716, 'iraq': 717, 'warned': 718, 'stage': 719, 'within': 720, 'ban': 721, 'regional': 722, 'career': 723, 'movie': 724, 'elections': 725, 'border': 726, 'needs': 727, 'rock': 728, 'retail': 729, 'opposition': 730, 'outside': 731, '24': 732, 'storm': 733, 'justice': 734, 'practice': 735, 'selling': 736, 'hollywood': 737, 'solutions': 738, 'along': 739, 'gains': 740, 'love': 741, 'couple': 742, 'behind': 743, 'admitted': 744, 'wall': 745, 'maker': 746, 'mayor': 747, 'upcoming': 748, 'valley': 749, 'staff': 750, 'jackson': 751, 'bay': 752, 'award': 753, 'suicide': 754, 'space': 755, 'later': 756, 'violence': 757, 'systems': 758, 'anniversary': 759, 'miss': 760, 'flu': 761, 'history': 762, 'mortgage': 763, 'thousands': 764, 'zealand': 765, 'candidate': 766, 'germany': 767, 'church': 768, 'championship': 769, 'recovery': 770, 'phone': 771, 'raised': 772, 'based': 773, 'decision': 774, 'using': 775, 'olympic': 776, 'attacks': 777, 'struck': 778, 'growing': 779, 'middle': 780, 'performance': 781, 'mumbai': 782, 'cost': 783, 'spending': 784, 'microsoft': 785, 'offers': 786, 'officially': 787, 'name': 788, 'risk': 789, 'claimed': 790, 'protest': 791, 'mexico': 792, 'sent': 793, 'festival': 794, 'employees': 795, 'housing': 796, 'list': 797, 'beach': 798, 'build': 799, 'provide': 800, 'positive': 801, 'protection': 802, 'given': 803, 'losses': 804, 'ltd': 805, 'leaving': 806, 'captain': 807, 'japanese': 808, 'owner': 809, 'peace': 810, 'pressure': 811, 'rally': 812, 'break': 813, 'hotel': 814, 'husband': 815, 'democratic': 816, 'worth': 817, 'act': 818, 'ever': 819, 'loan': 820, 'father': 821, 'travel': 822, 'battle': 823, 'eastern': 824, 'fraud': 825, 'almost': 826, 'robbery': 827, 'asia': 828, 'confidence': 829, 'showed': 830, 'acquire': 831, 'possible': 832, 'files': 833, 'continued': 834, 'alleged': 835, 'legal': 836, 'daily': 837, 'UN': 838, 'survey': 839, 'sheriff': 840, 'joint': 841, 'step': 842, 'truck': 843, 'stay': 844, 'defense': 845, 'funds': 846, 'television': 847, 'plane': 848, 'veteran': 849, 'less': 850, 'known': 851, 'johnson': 852, 'joe': 853, 'georgia': 854, '31': 855, 'lady': 856, 'basketball': 857, 'costs': 858, 'approved': 859, '19': 860, 'administration': 861, 'girls': 862, 'soldiers': 863, 'businesses': 864, 'never': 865, 'deputy': 866, 'changes': 867, 'single': 868, 'starting': 869, 'main': 870, 'radio': 871, 'returned': 872, 'smith': 873, 'daughter': 874, 'williams': 875, '40': 876, 'rep': 877, 'bush': 878, 'interview': 879, '23': 880, 'declared': 881, 'heavy': 882, 'warning': 883, 'sources': 884, 'gay': 885, 'division': 886, 'asked': 887, 'fired': 888, 'natural': 889, 'inflation': 890, 'nine': 891, 'soldier': 892, 'falling': 893, 'reserve': 894, 'might': 895, 'supply': 896, 'serious': 897, 'dr': 898, 'stadium': 899, '9': 900, 'mike': 901, 'facility': 902, 'de': 903, 'carolina': 904, 'seen': 905, 'increased': 906, 'gun': 907, 'begin': 908, 'land': 909, 'point': 910, 'met': 911, 'areas': 912, 'drop': 913, 'defence': 914, 'web': 915, 'king': 916, 'highway': 917, 'baseball': 918, 'whose': 919, 'champions': 920, 'jailed': 921, 'popular': 922, 'boost': 923, 'book': 924, 'aid': 925, 'hopes': 926, 'boston': 927, 'drive': 928, 'dropped': 929, 'christmas': 930, 'look': 931, 'fiscal': 932, 'vice': 933, 'stores': 934, 'italian': 935, 'futures': 936, 'calif': 937, 'armed': 938, 'projects': 939, 'straight': 940, 'passed': 941, 'acquired': 942, 'failed': 943, 'tom': 944, 'flights': 945, 'gets': 946, 'khan': 947, 'convicted': 948, 'appointed': 949, 'turned': 950, 'teacher': 951, 'striker': 952, '26': 953, 'partnership': 954, 'justin': 955, 'winter': 956, 'ground': 957, 'homes': 958, 'went': 959, 'every': 960, 'drugs': 961, 'injuries': 962, 'bond': 963, 'concerns': 964, 'bomb': 965, 'hits': 966, 'recession': 967, 'earnings': 968, 'know': 969, 'joined': 970, 'digital': 971, 'attorney': 972, 'find': 973, 'playing': 974, 'total': 975, 'palestinian': 976, 'paid': 977, 'connection': 978, 'front': 979, 'expand': 980, 'common': 981, 'person': 982, 'stars': 983, 'nations': 984, 'winning': 985, 'supreme': 986, 'large': 987, 'pakistani': 988, 'begins': 989, 'martin': 990, 'published': 991, 'conditions': 992, 'moving': 993, 'watch': 994, 'dog': 995, 'super': 996, 'lanka': 997, 'suspected': 998, 'spring': 999, 'light': 1000, 'prince': 1001, 'raises': 1002, 'reached': 1003, 'NFL': 1004, 'started': 1005, 'ohio': 1006, 'commercial': 1007, 'syria': 1008, 'decided': 1009, 'investigation': 1010, 'unit': 1011, 'term': 1012, 'marriage': 1013, '27': 1014, 'steve': 1015, 'operation': 1016, 'al': 1017, 'jones': 1018, 'yet': 1019, 'seeking': 1020, 'boss': 1021, 'completed': 1022, 'bring': 1023, 'suffered': 1024, 'together': 1025, 'flight': 1026, 'finally': 1027, 'already': 1028, 'levels': 1029, 'scheduled': 1030, 'criminal': 1031, 'twitter': 1032, 'efforts': 1033, 'sydney': 1034, 'michigan': 1035, 'spokesman': 1036, 'create': 1037, 'revenue': 1038, 'suspect': 1039, 'houston': 1040, 'giving': 1041, 'kim': 1042, 'forced': 1043, 'CEO': 1044, 'partner': 1045, 'kill': 1046, 'lawsuit': 1047, 'attacked': 1048, 'access': 1049, 'holding': 1050, 'spain': 1051, 'civil': 1052, 'parts': 1053, 'turkish': 1054, 'birth': 1055, 'banned': 1056, 'goes': 1057, 'caught': 1058, 'problems': 1059, 'double': 1060, 'ryan': 1061, 'stake': 1062, 'added': 1063, 'celebrate': 1064, 'whether': 1065, '28': 1066, 'cooperation': 1067, 'funding': 1068, 'THE': 1069, 'robbed': 1070, 'process': 1071, 'steel': 1072, 'releases': 1073, 'band': 1074, 'reach': 1075, 'treatment': 1076, 'abuse': 1077, 'leaves': 1078, 'arrived': 1079, 'unemployment': 1080, 'crashed': 1081, 'joins': 1082, 'hundreds': 1083, 'platform': 1084, 'camp': 1085, 'involved': 1086, 'assembly': 1087, 'communications': 1088, 'ireland': 1089, 'retirement': 1090, 'taylor': 1091, 'sea': 1092, 'range': 1093, 'base': 1094, '500': 1095, 'corporate': 1096, 'track': 1097, 'senator': 1098, 'tomorrow': 1099, 'peter': 1100, 'index': 1101, 'available': 1102, 'romney': 1103, 'improve': 1104, 'banking': 1105, 'perform': 1106, 'net': 1107, 'ambassador': 1108, 'ruled': 1109, 'living': 1110, 'jury': 1111, 'stabbed': 1112, 'earthquake': 1113, 'crime': 1114, 'unveiled': 1115, 'saudi': 1116, 'toronto': 1117, 'stolen': 1118, 'assets': 1119, 'iranian': 1120, 'liverpool': 1121, 'midfielder': 1122, 'condition': 1123, 'caused': 1124, 'province': 1125, 'reduce': 1126, 'period': 1127, 'cars': 1128, 'EU': 1129, 'channel': 1130, 'independent': 1131, 'iPhone': 1132, 'incident': 1133, 'afghan': 1134, 'posted': 1135, 'equity': 1136, 'village': 1137, 'magazine': 1138, 'class': 1139, 'egypt': 1140, 'holiday': 1141, 'lee': 1142, 'wanted': 1143, 'rape': 1144, 'save': 1145, 'industrial': 1146, 'scott': 1147, 'divorce': 1148, 'personal': 1149, 'stand': 1150, 'birthday': 1151, 'dubai': 1152, 'ordered': 1153, 'illegal': 1154, 'admits': 1155, 'crude': 1156, 'soccer': 1157, 'entertainment': 1158, 'kevin': 1159, 'blue': 1160, 'urged': 1161, 'jennifer': 1162, 'marketing': 1163, 'jan': 1164, 'inside': 1165, 'tony': 1166, 'gulf': 1167, 'producer': 1168, 'seek': 1169, 'tournament': 1170, 'split': 1171, 'relations': 1172, 'ceremony': 1173, 'cases': 1174, 'taliban': 1175, 'worldwide': 1176, 'patients': 1177, 'figures': 1178, 'rules': 1179, 'youth': 1180, 'italy': 1181, 'chelsea': 1182, 'royal': 1183, 'celebrates': 1184, 'solar': 1185, 'jersey': 1186, 'concert': 1187, 'rising': 1188, 'americans': 1189, 'taiwan': 1190, 'review': 1191, 'newspaper': 1192, 'dollars': 1193, 'fashion': 1194, 'auto': 1195, 'competition': 1196, 'comes': 1197, 'ship': 1198, 'proposed': 1199, 'minor': 1200, 'direct': 1201, 'clinton': 1202, 'corruption': 1203, 'buying': 1204, 'cabinet': 1205, 'girlfriend': 1206, 'suffering': 1207, 'fifth': 1208, 'brazil': 1209, 'researchers': 1210, 'agent': 1211, 'damage': 1212, 'massive': 1213, 'manufacturing': 1214, 'stealing': 1215, '29': 1216, 'primary': 1217, 'syrian': 1218, 'think': 1219, 'spanish': 1220, 'records': 1221, 'receive': 1222, 'technologies': 1223, 'resources': 1224, 'returning': 1225, 'appeal': 1226, 'minnesota': 1227, 'ties': 1228, 'fort': 1229, 'potential': 1230, 'discuss': 1231, 'apartment': 1232, 'model': 1233, 'singapore': 1234, 'extended': 1235, 'card': 1236, 'acquisition': 1237, 'expects': 1238, 'far': 1239, 'NBA': 1240, 'came': 1241, 'turn': 1242, 'challenge': 1243, 'ali': 1244, 'institute': 1245, 'operator': 1246, 'disease': 1247, 'greece': 1248, 'calling': 1249, 'rest': 1250, 'began': 1251, 'scientists': 1252, 'kansas': 1253, 'threat': 1254, 'rises': 1255, 'airline': 1256, 'korean': 1257, 'source': 1258, 'affairs': 1259, 'strategic': 1260, 'adding': 1261, 'fresh': 1262, 'female': 1263, 'room': 1264, 'users': 1265, 'pregnant': 1266, 'others': 1267, 'brother': 1268, 'highest': 1269, 'pop': 1270, 'felony': 1271, 'morgan': 1272, 'planned': 1273, 'broke': 1274, 'partners': 1275, 'militants': 1276, 'deficit': 1277, 'louis': 1278, 'parents': 1279, 'virginia': 1280, 'form': 1281, 'previous': 1282, 'hard': 1283, 'aircraft': 1284, 'short': 1285, 'moved': 1286, 'friends': 1287, 'gives': 1288, 'overnight': 1289, 'vehicles': 1290, 'downtown': 1291, 'voted': 1292, 'groups': 1293, 'orders': 1294, 'address': 1295, 'controversial': 1296, 'charity': 1297, 'mining': 1298, 'leads': 1299, 'situation': 1300, 'fair': 1301, 'programme': 1302, 'offered': 1303, 'appear': 1304, 'talk': 1305, 'product': 1306, 'tiger': 1307, 'helped': 1308, 'iowa': 1309, 'las': 1310, '200': 1311, 'bad': 1312, 'cause': 1313, 'bridge': 1314, 'played': 1315, 'quarterly': 1316, 'focus': 1317, 'firefighters': 1318, 'coal': 1319, 'jim': 1320, 'denied': 1321, 'compared': 1322, 'detroit': 1323, 'barrel': 1324, 'income': 1325, 'queen': 1326, 'colorado': 1327, 'quality': 1328, 'paris': 1329, 'losing': 1330, 'worker': 1331, 'society': 1332, 'draft': 1333, 'perry': 1334, 'view': 1335, 'winner': 1336, 'starts': 1337, 'average': 1338, 'miami': 1339, 'fox': 1340, 'teachers': 1341, 'closing': 1342, 'writer': 1343, 'NATO': 1344, 'doctors': 1345, 'defender': 1346, 'indicted': 1347, 'snow': 1348, '60': 1349, 'operating': 1350, 'wedding': 1351, 'boat': 1352, 'teen': 1353, 'limited': 1354, 'legend': 1355, 'blood': 1356, 'estate': 1357, 'beating': 1358, 'victims': 1359, 'scheme': 1360, 'tried': 1361, 'terms': 1362, 'cutting': 1363, 'acquires': 1364, 'dividend': 1365, 'receives': 1366, 'gave': 1367, 'illinois': 1368, 'gaza': 1369, 'response': 1370, 'swine': 1371, 'weak': 1372, 'hill': 1373, 'date': 1374, 'claim': 1375, 'restaurant': 1376, 'authority': 1377, 'effort': 1378, 'farm': 1379, 'draw': 1380, 'vegas': 1381, 'arizona': 1382, 'airways': 1383, 'port': 1384, 'fatal': 1385, 'poor': 1386, 'alex': 1387, 'andrew': 1388, 'measures': 1389, 'enough': 1390, 'exports': 1391, 'academy': 1392, 'friend': 1393, 'hurricane': 1394, 'republic': 1395, 'labor': 1396, 'McCain': 1397, 'reform': 1398, 'defeat': 1399, 'lot': 1400, 'feb': 1401, 'malaysia': 1402, 'kelly': 1403, 'introduced': 1404, 'committed': 1405, 'rain': 1406, 'heard': 1407, 'looks': 1408, 'allow': 1409, 'libya': 1410, 'separate': 1411, 'teams': 1412, 'organization': 1413, 'protect': 1414, 'madrid': 1415, 'memorial': 1416, 'hand': 1417, 'bail': 1418, 'fighting': 1419, 'course': 1420, 'towards': 1421, 'though': 1422, 'bills': 1423, 'investigate': 1424, 'engaged': 1425, 'irish': 1426, 'sells': 1427, 'rangers': 1428, 'theft': 1429, 'benefits': 1430, 'azerbaijan': 1431, 'wireless': 1432, 'climate': 1433, 'hearing': 1434, 'developer': 1435, 'celebrity': 1436, 'elderly': 1437, 'rival': 1438, 'fined': 1439, 'protesters': 1440, 'contest': 1441, 'grant': 1442, 'MP': 1443, 'lose': 1444, 'dispute': 1445, 'hockey': 1446, 'retire': 1447, 'diego': 1448, 'beijing': 1449, 'effective': 1450, 'millions': 1451, 'flood': 1452, 'dec': 1453, 'squad': 1454, 'indonesia': 1455, 'hospitalized': 1456, 'fame': 1457, 'tennis': 1458, 'rescued': 1459, 'environment': 1460, 'critical': 1461, 'hong': 1462, 'moves': 1463, 'aug': 1464, 'decline': 1465, 'block': 1466, 'rating': 1467, 'farmers': 1468, 'wind': 1469, 'forecast': 1470, 'atlanta': 1471, 'motor': 1472, 'rescue': 1473, 'currently': 1474, 'william': 1475, 'cloud': 1476, 'mission': 1477, 'arrives': 1478, 'beginning': 1479, 'victim': 1480, 'completes': 1481, 'present': 1482, 'package': 1483, 'knee': 1484, 'custody': 1485, 'holds': 1486, 'meets': 1487, 'boyfriend': 1488, 'voters': 1489, 'successful': 1490, 'tim': 1491, 'pirates': 1492, 'considering': 1493, 'x': 1494, 'attempt': 1495, 'kate': 1496, 'equipment': 1497, 'chase': 1498, 'families': 1499, 'navy': 1500, 'la': 1501, 'lawmakers': 1502, 'van': 1503, 'rugby': 1504, 'develop': 1505, 'reporting': 1506, 'different': 1507, \"n't\": 1508, 'hope': 1509, 'kashmir': 1510, 'ford': 1511, 'events': 1512, 'resigned': 1513, 'position': 1514, 'flat': 1515, 'worst': 1516, 'kong': 1517, 'boys': 1518, 'replace': 1519, 'elected': 1520, 'slightly': 1521, 'pacific': 1522, 'drivers': 1523, 'currency': 1524, 'woods': 1525, 'greek': 1526, 'summit': 1527, 'additional': 1528, 'matt': 1529, 'conduct': 1530, 'richard': 1531, 'shut': 1532, 'cell': 1533, 'mr': 1534, 'severe': 1535, 'cities': 1536, 'ending': 1537, 'electric': 1538, 'becoming': 1539, 'avoid': 1540, 'kardashian': 1541, 'threatened': 1542, 'spot': 1543, 'turns': 1544, 'headed': 1545, 'transfer': 1546, 'headquarters': 1547, 'resume': 1548, 'visits': 1549, 'weapons': 1550, 'important': 1551, 'nov': 1552, 'rebels': 1553, 'retailer': 1554, 'ends': 1555, 'ben': 1556, 'oct': 1557, 'securities': 1558, 'wayne': 1559, 'andy': 1560, 'francisco': 1561, 'mixed': 1562, 'bonds': 1563, 'believes': 1564, 'lindsay': 1565, 'lohan': 1566, 'computer': 1567, 'quarterback': 1568, 'kills': 1569, 'doctor': 1570, 'motors': 1571, 'harry': 1572, 'seeks': 1573, 'charlie': 1574, 'ca': 1575, 'solution': 1576, 'venture': 1577, 'celebrated': 1578, 'relationship': 1579, 'complex': 1580, 'hot': 1581, 'chance': 1582, 'professional': 1583, 'believe': 1584, 'fears': 1585, 'samsung': 1586, 'commissioner': 1587, 'saw': 1588, 'reality': 1589, 'runs': 1590, 'cross': 1591, 'problem': 1592, 'dallas': 1593, 'awarded': 1594, 'tree': 1595, 'owners': 1596, 'sets': 1597, 'loans': 1598, 'brain': 1599, 'leadership': 1600, 'tourism': 1601, 'involving': 1602, 'effect': 1603, 'golf': 1604, 'township': 1605, 'pulled': 1606, 'passes': 1607, 'progress': 1608, 'milan': 1609, 'song': 1610, 'industries': 1611, 'landing': 1612, 'broken': 1613, 'invest': 1614, 'chain': 1615, 'carrier': 1616, 'multiple': 1617, 'telecom': 1618, 'labour': 1619, 'safe': 1620, 'distribution': 1621, 'value': 1622, 'alliance': 1623, 'account': 1624, 'result': 1625, 'protests': 1626, 'huge': 1627, 'trip': 1628, 'citizens': 1629, 'ice': 1630, 'shop': 1631, 'became': 1632, 'tests': 1633, 'profits': 1634, 'films': 1635, 'indiana': 1636, 'aimed': 1637, 'bangladesh': 1638, 'minutes': 1639, 'raising': 1640, 'seriously': 1641, 'sir': 1642, 'arts': 1643, 'signing': 1644, 'row': 1645, 'happy': 1646, 'clear': 1647, 'brian': 1648, 'transport': 1649, 'activity': 1650, 'disaster': 1651, 'english': 1652, 'impact': 1653, 'brought': 1654, 'charles': 1655, 'various': 1656, 'bringing': 1657, 'sony': 1658, 'citing': 1659, 'trust': 1660, 'bollywood': 1661, 'wisconsin': 1662, 'toyota': 1663, 'science': 1664, '2007': 1665, 'strategy': 1666, 'poll': 1667, 'employee': 1668, 'missouri': 1669, 'bob': 1670, 'showing': 1671, 'design': 1672, 'via': 1673, 'marijuana': 1674, 'reelection': 1675, 'sox': 1676, 'cameron': 1677, 'simon': 1678, 'remained': 1679, 'outlook': 1680, 'resign': 1681, 'cleared': 1682, 'scored': 1683, 'ministers': 1684, 'debate': 1685, 'gone': 1686, 'advanced': 1687, 'jack': 1688, 'recall': 1689, 'benefit': 1690, 'launching': 1691, 'recovering': 1692, 'zone': 1693, 'kids': 1694, 'consumers': 1695, 'terror': 1696, 'crimes': 1697, 'mountain': 1698, 'application': 1699, 'rick': 1700, 'expecting': 1701, 'associated': 1702, 'strikes': 1703, 'sexually': 1704, 'causing': 1705, 'art': 1706, 'die': 1707, 'allen': 1708, 'ratings': 1709, 'increases': 1710, 'rupee': 1711, 'assistant': 1712, 'classic': 1713, 'heat': 1714, 'directors': 1715, 'parties': 1716, 'fan': 1717, 'steps': 1718, 'closes': 1719, 'version': 1720, 'infrastructure': 1721, 'animal': 1722, 'capacity': 1723, 'journal': 1724, 'swiss': 1725, 'quit': 1726, 'entered': 1727, 'expansion': 1728, 'relief': 1729, 'foundation': 1730, 'things': 1731, 'lines': 1732, 'struggling': 1733, 'moscow': 1734, 'expectations': 1735, 'mass': 1736, 'motorcycle': 1737, 'manufacturer': 1738, 'investor': 1739, 'giants': 1740, 'cleveland': 1741, 'crashes': 1742, 'tribute': 1743, 'feels': 1744, 'content': 1745, 'helping': 1746, 'environmental': 1747, 'app': 1748, 'attend': 1749, 'married': 1750, 'BBC': 1751, 'customer': 1752, 'ukraine': 1753, 'grow': 1754, 'needed': 1755, 'related': 1756, 'brad': 1757, 'stewart': 1758, 'arsenal': 1759, 'forest': 1760, 'attempted': 1761, 'metal': 1762, 'politics': 1763, 'wide': 1764, 'story': 1765, 'offices': 1766, 'increasing': 1767, 'delivery': 1768, 'bowl': 1769, 'santa': 1770, 'cast': 1771, 'express': 1772, 'lawyer': 1773, 'IT': 1774, 'seized': 1775, '1000': 1776, 'historic': 1777, 'cruise': 1778, 'denies': 1779, 'complete': 1780, 'hamilton': 1781, 'holdings': 1782, 'gordon': 1783, 'jose': 1784, 'always': 1785, 'activities': 1786, 'II': 1787, 'disabled': 1788, 'tech': 1789, 'prevent': 1790, 'bar': 1791, 'stabbing': 1792, 'unveils': 1793, 'failing': 1794, 'BJP': 1795, 'lives': 1796, 'gaga': 1797, 'rule': 1798, 'jets': 1799, 'plants': 1800, 'philadelphia': 1801, 'leg': 1802, 'punjab': 1803, 'really': 1804, 'spend': 1805, 'square': 1806, 'olympics': 1807, 'auction': 1808, 'thomas': 1809, 'jason': 1810, 'warns': 1811, 'carrying': 1812, 'joining': 1813, 'USA': 1814, 'sarah': 1815, 'analysts': 1816, 'crore': 1817, 'offensive': 1818, 'tackle': 1819, 'kentucky': 1820, 'battery': 1821, 'toward': 1822, 'scotland': 1823, 'jessica': 1824, '32': 1825, 'jet': 1826, 'ongoing': 1827, 'windows': 1828, 'sanctions': 1829, 'appoints': 1830, 'purchase': 1831, 'iron': 1832, 'sharply': 1833, 'anthony': 1834, 'brazilian': 1835, 'majority': 1836, 'stephen': 1837, 'seattle': 1838, 'networks': 1839, '75': 1840, 'metro': 1841, 'significant': 1842, 'allegations': 1843, 'pick': 1844, 'burglary': 1845, 'avenue': 1846, 'posts': 1847, 'failure': 1848, 'discovered': 1849, 'candidates': 1850, 'apparently': 1851, 'helicopter': 1852, 'developed': 1853, 'placed': 1854, 'box': 1855, 'fast': 1856, 'defensive': 1857, 'file': 1858, 'barcelona': 1859, 'pilot': 1860, 'send': 1861, 'receiver': 1862, 'deadly': 1863, 'gain': 1864, 'assaulting': 1865, 'arab': 1866, 'goal': 1867, 'possession': 1868, 'mitt': 1869, 'factor': 1870, 'nationwide': 1871, 'islamic': 1872, 'experts': 1873, 'extend': 1874, 'wake': 1875, 'ten': 1876, 'electronic': 1877, 'campus': 1878, 'commerce': 1879, 'immigration': 1880, 'able': 1881, 'throughout': 1882, 'healthcare': 1883, 'terrorism': 1884, 'comments': 1885, 'closer': 1886, 'weekly': 1887, 'visited': 1888, 'loses': 1889, 'bieber': 1890, 'stimulus': 1891, 'cole': 1892, 'applications': 1893, 'pradesh': 1894, 'firms': 1895, 'pass': 1896, 'breaks': 1897, 'approves': 1898, 'cents': 1899, 'sending': 1900, 'extension': 1901, 'advertising': 1902, 'embassy': 1903, 'rare': 1904, 'detained': 1905, 'homicide': 1906, 'designed': 1907, 'settlement': 1908, 'activists': 1909, 'voice': 1910, 'fires': 1911, 'polls': 1912, 'schedule': 1913, 'satellite': 1914, 'patrick': 1915, 'idol': 1916, 'comedy': 1917, 'success': 1918, 'author': 1919, 'victoria': 1920, 'taxes': 1921, 'democrats': 1922, 'works': 1923, 'southwest': 1924, 'enter': 1925, 'regular': 1926, 'developing': 1927, 'n': 1928, 'founder': 1929, 'golden': 1930, 'spent': 1931, 'identified': 1932, 'tennessee': 1933, 'promote': 1934, 'consider': 1935, 'standard': 1936, 'treasury': 1937, 'kennedy': 1938, 'done': 1939, 'zimbabwe': 1940, 'shopping': 1941, 'patrol': 1942, 'thought': 1943, 'destroyed': 1944, 'try': 1945, 'created': 1946, 'wild': 1947, '70': 1948, 'concern': 1949, 'supplies': 1950, 'adds': 1951, 'add': 1952, 'orleans': 1953, '35': 1954, 'sentence': 1955, 'pounds': 1956, 'providing': 1957, 'reveals': 1958, 'broadband': 1959, 'confirms': 1960, 'update': 1961, 'electronics': 1962, 'setting': 1963, 'technical': 1964, 'declares': 1965, 'seat': 1966, 'vs': 1967, 'activist': 1968, 'beckham': 1969, 'hills': 1970, 'engineering': 1971, 'agree': 1972, 'agencies': 1973, 'threatening': 1974, 'export': 1975, 'cover': 1976, 'nigeria': 1977, 'dating': 1978, 'consecutive': 1979, 'arabia': 1980, 'speed': 1981, 'introduces': 1982, 'parliamentary': 1983, 'violent': 1984, 'appears': 1985, 'let': 1986, 'rural': 1987, 'previously': 1988, 'speak': 1989, 'chapter': 1990, 'ring': 1991, 'russell': 1992, 'undergo': 1993, 'frank': 1994, 'speech': 1995, 'generation': 1996, 'melbourne': 1997, 'passenger': 1998, 'fine': 1999, 'patent': 2000, 'decade': 2001, 'counts': 2002, 'wales': 2003, 'passengers': 2004, 'racing': 2005, 'serve': 2006, 'changed': 2007, 'campbell': 2008, 'philippines': 2009, 'expands': 2010, 'palin': 2011, 'daniel': 2012, 'hurt': 2013, 'silver': 2014, 'dealers': 2015, 'jr': 2016, '80': 2017, 'vietnam': 2018, 'muslim': 2019, 'FC': 2020, 'terrorist': 2021, 'trend': 2022, 'gary': 2023, 'yahoo': 2024, '300': 2025, 'bin': 2026, 'longer': 2027, 'secret': 2028, 'granted': 2029, 'alcohol': 2030, 'panel': 2031, 'studio': 2032, 'tata': 2033, 'fees': 2034, 'scandal': 2035, 'beaten': 2036, 'electricity': 2037, 'refused': 2038, 'dutch': 2039, 'sept': 2040, 'hosting': 2041, 'prosecutors': 2042, 'allowed': 2043, 'forum': 2044, 'deliver': 2045, 'email': 2046, 'heading': 2047, 'overall': 2048, 'experience': 2049, 'DC': 2050, 'nick': 2051, 'selected': 2052, 'prize': 2053, 'subsidiary': 2054, 'threats': 2055, 'decades': 2056, 'cocaine': 2057, 'laws': 2058, 'claiming': 2059, 'recovered': 2060, 'elizabeth': 2061, 'honored': 2062, 'ruling': 2063, 'investments': 2064, 'streets': 2065, 'numbers': 2066, 'shareholders': 2067, 'nelson': 2068, 'advisory': 2069, 'freedom': 2070, 'christian': 2071, 'hands': 2072, 'enterprise': 2073, 'coalition': 2074, 'phoenix': 2075, 'hour': 2076, 'theatre': 2077, 'cuba': 2078, 'oklahoma': 2079, 'prix': 2080, 'rejected': 2081, 'alabama': 2082, 'pace': 2083, 'AP': 2084, 'expanding': 2085, 'mexican': 2086, 'el': 2087, 'ensure': 2088, 'adam': 2089, 'kyrgyzstan': 2090, 'pitcher': 2091, 'appearance': 2092, 'teenager': 2093, 'roads': 2094, 'northwest': 2095, 'chemical': 2096, 'wrong': 2097, 'android': 2098, 'units': 2099, 'hired': 2100, 'continuing': 2101, 'crew': 2102, 'finds': 2103, 'voting': 2104, 'crews': 2105, 'overseas': 2106, 'michelle': 2107, 'bought': 2108, 'cape': 2109, 'qatar': 2110, 'receiving': 2111, 'territory': 2112, 'pope': 2113, 'route': 2114, 'lewis': 2115, 'photo': 2116, 'davis': 2117, 'successfully': 2118, 'targets': 2119, 'linked': 2120, 'nokia': 2121, 'ghana': 2122, 'greater': 2123, 'elementary': 2124, 'feel': 2125, 'egyptian': 2126, 'devices': 2127, 'ocean': 2128, 'beats': 2129, 'analyst': 2130, 'evidence': 2131, 'improved': 2132, 'clean': 2133, 'cable': 2134, 'agriculture': 2135, 'question': 2136, 'push': 2137, 'marine': 2138, 'ill': 2139, 'sport': 2140, 'jordan': 2141, 'sun': 2142, 'stated': 2143, 'wells': 2144, 'sites': 2145, 'expanded': 2146, 'brothers': 2147, 'assaulted': 2148, 'portfolio': 2149, 'clash': 2150, 'keeping': 2151, 'dangerous': 2152, 'venezuela': 2153, 'announcement': 2154, 'artist': 2155, 'resigns': 2156, 'parking': 2157, 'democracy': 2158, 'letter': 2159, 'jon': 2160, 'negative': 2161, 'indians': 2162, 'walk': 2163, 'engine': 2164, 'friendly': 2165, 'wounded': 2166, 'breaking': 2167, 'interior': 2168, 'statistics': 2169, 'homeless': 2170, 'b': 2171, 'yen': 2172, 'hosts': 2173, 'NEW': 2174, 'lowest': 2175, 'surprise': 2176, 'sixth': 2177, 'strip': 2178, 'wilson': 2179, 'facilities': 2180, 'amy': 2181, 'alert': 2182, '90': 2183, 'serving': 2184, 'lack': 2185, 'amount': 2186, 'bulgaria': 2187, 'fargo': 2188, 'mine': 2189, 'options': 2190, 'twins': 2191, 'visiting': 2192, 'treated': 2193, 'shoot': 2194, 'urges': 2195, 'proposal': 2196, 'harris': 2197, 'tamil': 2198, 'branch': 2199, 'toll': 2200, 'cold': 2201, 'diagnosed': 2202, 'reaches': 2203, 'reuters': 2204, 'garden': 2205, 'thanks': 2206, 'rapper': 2207, 'representative': 2208, 'approval': 2209, 'supporters': 2210, 'hillary': 2211, 'catholic': 2212, 'speculation': 2213, 'carbon': 2214, 'eye': 2215, 'extends': 2216, 'journalist': 2217, 'note': 2218, 'believed': 2219, 'bear': 2220, 'true': 2221, 'provides': 2222, 'bodies': 2223, 'tough': 2224, 'moore': 2225, 'appeared': 2226, 'iraqi': 2227, 'rail': 2228, 'contracts': 2229, 'oscar': 2230, 'anna': 2231, 'nifty': 2232, 'milwaukee': 2233, 'questions': 2234, 'tropical': 2235, 'buys': 2236, 'CBS': 2237, 'can': 2238, 'not': 2239, 'foot': 2240, '2014': 2241, 'medal': 2242, 'stone': 2243, 'enforcement': 2244, 'miller': 2245, 'message': 2246, 'recover': 2247, 'goods': 2248, 'programs': 2249, 'tokyo': 2250, 'arms': 2251, 'produce': 2252, 'rihanna': 2253, 'murray': 2254, 'agents': 2255, 'massachusetts': 2256, 'immediate': 2257, 'collection': 2258, 'residential': 2259, 'aged': 2260, 'diplomatic': 2261, 'lending': 2262, 'owned': 2263, 'phones': 2264, 'begun': 2265, 'tickets': 2266, 'fellow': 2267, 'scottish': 2268, 'libyan': 2269, 'myanmar': 2270, 'kept': 2271, 'votes': 2272, 'religious': 2273, 'sheen': 2274, 'longtime': 2275, 'hoping': 2276, 'foods': 2277, 'bailout': 2278, 'sees': 2279, 'museum': 2280, 'deals': 2281, 'traders': 2282, 'famous': 2283, 'stronger': 2284, 'ontario': 2285, 'weight': 2286, 'iPad': 2287, 'supports': 2288, 'yankees': 2289, 'status': 2290, 'details': 2291, 'legislation': 2292, '45': 2293, 'device': 2294, 'storage': 2295, 'testing': 2296, 'movement': 2297, 'ATt': 2298, 'gandhi': 2299, 'laid': 2300, 'dozens': 2301, 'although': 2302, 'rehab': 2303, 'sued': 2304, 'spears': 2305, 'hire': 2306, 'paper': 2307, 'miles': 2308, 'teenage': 2309, 'jerry': 2310, '400': 2311, 'lebanon': 2312, 'sharp': 2313, 'austin': 2314, 'palm': 2315, 'spread': 2316, 'congressional': 2317, 'yemen': 2318, 'oregon': 2319, 'denver': 2320, 'abu': 2321, 'pro': 2322, 'sam': 2323, 'apparent': 2324, 'orange': 2325, 'galaxy': 2326, 'plea': 2327, 'shoulder': 2328, 'factory': 2329, 'drama': 2330, 'drops': 2331, 'library': 2332, 'suspicion': 2333, 'built': 2334, 'powerful': 2335, 'cards': 2336, 'strength': 2337, 'kicked': 2338, 'musical': 2339, 'alive': 2340, 'zardari': 2341, 'twice': 2342, 'collision': 2343, 'challenges': 2344, 'rice': 2345, 'prisoners': 2346, 'chiefs': 2347, 'journalists': 2348, 'mail': 2349, 'include': 2350, 'located': 2351, 'lifted': 2352, 'formula': 2353, 'tigers': 2354, 'duty': 2355, 'affected': 2356, 'championships': 2357, 'waste': 2358, 'presence': 2359, 'independence': 2360, 'preparing': 2361, 'assistance': 2362, 'strengthen': 2363, 'feature': 2364, 'basis': 2365, 'invited': 2366, '150': 2367, 'rivals': 2368, 'secure': 2369, 'becomes': 2370, 'putting': 2371, 'roger': 2372, 'certain': 2373, 'healthy': 2374, 'ABC': 2375, 'funeral': 2376, 'initial': 2377, 'britney': 2378, 'causes': 2379, 'howard': 2380, 'veterans': 2381, 'plays': 2382, 'doors': 2383, 'welcome': 2384, 'pittsburgh': 2385, 'recalled': 2386, 'UAE': 2387, 'license': 2388, 'acting': 2389, 'eric': 2390, 'offender': 2391, 'hitting': 2392, 'monetary': 2393, 'notes': 2394, 'formally': 2395, 'presented': 2396, 'stable': 2397, 'atlantic': 2398, 'arena': 2399, 'conservative': 2400, 'franchise': 2401, 'repair': 2402, 'kumar': 2403, 'fully': 2404, 'regarding': 2405, 'finish': 2406, 'nationals': 2407, 'patient': 2408, 'resort': 2409, 'exercise': 2410, 'copper': 2411, 'instead': 2412, 'creating': 2413, 'goals': 2414, 'pattinson': 2415, '10000': 2416, 'payment': 2417, 'sensex': 2418, 'delegation': 2419, 'stroke': 2420, 'cheryl': 2421, 'bureau': 2422, 'newly': 2423, 'rather': 2424, 'dogs': 2425, 'missed': 2426, 'explosion': 2427, 'that': 2428, 'filing': 2429, 'stanley': 2430, 'talent': 2431, 'combat': 2432, 'dance': 2433, 'approximately': 2434, 'breast': 2435, 'expert': 2436, 'ways': 2437, 'alaska': 2438, 'stopped': 2439, 'option': 2440, 'terrorists': 2441, 'utah': 2442, 'rio': 2443, 'fatally': 2444, 'extra': 2445, 'ticket': 2446, 'reduced': 2447, 'vowed': 2448, 'policies': 2449, 'jimmy': 2450, 'suffers': 2451, 'communities': 2452, 'smartphone': 2453, 'simpson': 2454, 'railway': 2455, 'tourists': 2456, 'brands': 2457, 'speaker': 2458, 'transportation': 2459, 'sabha': 2460, 'stations': 2461, 'monthly': 2462, 'argentina': 2463, 'reporters': 2464, 'superstar': 2465, 'eurozone': 2466, 'birmingham': 2467, 'nomination': 2468, 'earth': 2469, 'lions': 2470, 'honor': 2471, 'sprint': 2472, 'anderson': 2473, 'ball': 2474, 'winds': 2475, 'serbia': 2476, 'offshore': 2477, 'sudan': 2478, 'heads': 2479, 'hudson': 2480, 'output': 2481, 'shown': 2482, 'cancelled': 2483, 'pool': 2484, 'virus': 2485, 'existing': 2486, 'vancouver': 2487, 'standards': 2488, 'jolie': 2489, 'pair': 2490, 'designer': 2491, 'somali': 2492, 'check': 2493, 'intelligence': 2494, 'tells': 2495, 'mississippi': 2496, 'initiative': 2497, 'w': 2498, 'mall': 2499, 'circuit': 2500, 'jeff': 2501, 'invasion': 2502, 'legendary': 2503, 'carlos': 2504, 'deadline': 2505, 'buildings': 2506, 'newcastle': 2507, 'hero': 2508, 'negotiations': 2509, 'networking': 2510, 'southeast': 2511, 'touch': 2512, 'angelina': 2513, 'congressman': 2514, 'matches': 2515, 'pension': 2516, 'BP': 2517, 'felt': 2518, 'agrees': 2519, 'comeback': 2520, 'expect': 2521, 'window': 2522, 'resident': 2523, 'spotted': 2524, 'malaysian': 2525, 'commander': 2526, 'missile': 2527, 'aviation': 2528, 'edward': 2529, 'sought': 2530, 'katie': 2531, 'employment': 2532, 'welcomed': 2533, 'exclusive': 2534, 'active': 2535, 'advance': 2536, 'drunk': 2537, 'deaths': 2538, 'recalls': 2539, 'conducted': 2540, '65': 2541, 'kings': 2542, 'highly': 2543, 'madonna': 2544, 'broadway': 2545, 'collapsed': 2546, 'goldman': 2547, 'regime': 2548, 'slow': 2549, 'palestinians': 2550, 'USD': 2551, 'warren': 2552, 'tampa': 2553, 'payments': 2554, 'asks': 2555, 'financing': 2556, 'fish': 2557, 'penalty': 2558, 'emerging': 2559, 'busy': 2560, 'reporter': 2561, 'contact': 2562, 'baltimore': 2563, 'kazakhstan': 2564, 'ease': 2565, '41': 2566, 'places': 2567, 'NCAA': 2568, 'NY': 2569, 'pennsylvania': 2570, 'demi': 2571, 'waters': 2572, 'ron': 2573, 'thailand': 2574, 'floor': 2575, 'screen': 2576, 'native': 2577, '64': 2578, 'oakland': 2579, 'enters': 2580, 'mac': 2581, 'manslaughter': 2582, 'searching': 2583, 'jumped': 2584, 'dialogue': 2585, 'canceled': 2586, 'retired': 2587, 'entire': 2588, 'celebrating': 2589, 'killer': 2590, 'hospitals': 2591, 'illness': 2592, 'demands': 2593, 'pitt': 2594, 'scene': 2595, 'fact': 2596, 'j': 2597, 'removed': 2598, 'properties': 2599, 'boxing': 2600, 'discovery': 2601, 'coverage': 2602, 'culture': 2603, 'gang': 2604, 'counties': 2605, 'springs': 2606, 'positions': 2607, 'helps': 2608, 'especially': 2609, 'traded': 2610, 'movies': 2611, 'businessman': 2612, 'welcomes': 2613, 'performing': 2614, 'what': 2615, 'turning': 2616, 'steady': 2617, 'asking': 2618, 'page': 2619, 'dancing': 2620, 'horse': 2621, 'dream': 2622, 'fee': 2623, 'opportunities': 2624, 'perfect': 2625, 'lineup': 2626, 'sugar': 2627, 'tonnes': 2628, 'NBC': 2629, 'identity': 2630, 'arm': 2631, 'probation': 2632, 'clinic': 2633, 'fishermen': 2634, 'unions': 2635, 'declined': 2636, 'judges': 2637, 'fishing': 2638, 'northeast': 2639, 'biden': 2640, 'luxury': 2641, '600': 2642, 'cargo': 2643, 'supplier': 2644, 'edwards': 2645, 'phil': 2646, 'lift': 2647, 'orlando': 2648, 'fear': 2649, 'sachs': 2650, 'dedicated': 2651, 'false': 2652, 'utility': 2653, 'czech': 2654, 'penn': 2655, 'learned': 2656, 'introduce': 2657, 'dakota': 2658, 'manmohan': 2659, 'fit': 2660, 'edge': 2661, 'renewed': 2662, 'clients': 2663, 'troubled': 2664, 'sentiment': 2665, 'delayed': 2666, 'insists': 2667, 'confident': 2668, 'personnel': 2669, 'republicans': 2670, 'accounts': 2671, 'feet': 2672, 'worked': 2673, 'bears': 2674, 'male': 2675, 'swedish': 2676, 'population': 2677, 'democrat': 2678, 'waiting': 2679, 'smart': 2680, 'choice': 2681, 'beyond': 2682, 'complaint': 2683, 'exhibition': 2684, 'creek': 2685, 'shanghai': 2686, 'producers': 2687, 'suspends': 2688, 'residence': 2689, 'smoke': 2690, 'hamas': 2691, 'pornography': 2692, 'queensland': 2693, 'noon': 2694, 'buffalo': 2695, 'however': 2696, 'considered': 2697, 'responsible': 2698, 'representatives': 2699, 'specialist': 2700, 'columbia': 2701, 'e': 2702, 'tell': 2703, 'portland': 2704, 'mary': 2705, 'bilateral': 2706, 'alan': 2707, 'outstanding': 2708, 'henry': 2709, 'targeting': 2710, 'reforms': 2711, 'madison': 2712, 'awareness': 2713, 'often': 2714, 'columbus': 2715, 'GOP': 2716, 'diamond': 2717, 'tested': 2718, 'pain': 2719, 'carry': 2720, 'NSW': 2721, 'persons': 2722, 'modern': 2723, 'learn': 2724, 'cooper': 2725, 'medicine': 2726, 'incidents': 2727, 'wood': 2728, 'bell': 2729, 'connecticut': 2730, 'deep': 2731, 'sky': 2732, 'institutions': 2733, 'display': 2734, 'disney': 2735, 'bahrain': 2736, 'opener': 2737, 'born': 2738, 'josh': 2739, 'kenya': 2740, 'katy': 2741, 'fitness': 2742, 'postponed': 2743, 'preliminary': 2744, 'restructuring': 2745, 'asset': 2746, 'nothing': 2747, 'conflict': 2748, 'documents': 2749, 'deputies': 2750, 'temporary': 2751, 'items': 2752, 'professor': 2753, 'winehouse': 2754, 'evacuated': 2755, 'something': 2756, 'merger': 2757, 'guy': 2758, 'philippine': 2759, 'immediately': 2760, 'convention': 2761, 'rich': 2762, 'stole': 2763, 'matter': 2764, 'CNN': 2765, 'mutual': 2766, 'chavez': 2767, 'appeals': 2768, 'marry': 2769, 'phase': 2770, 'means': 2771, 'managed': 2772, 'defends': 2773, 'ask': 2774, 'ankle': 2775, 'pull': 2776, 'request': 2777, 'casino': 2778, 'threatens': 2779, 'escaped': 2780, 'promotion': 2781, 'hosted': 2782, 'sworn': 2783, 'fighter': 2784, 'normal': 2785, 'there': 2786, 'ad': 2787, 'antonio': 2788, 'finished': 2789, 'weaker': 2790, 'happened': 2791, 'suspicious': 2792, 'SA': 2793, 'dark': 2794, 'pipeline': 2795, '62': 2796, 'suspects': 2797, 'tied': 2798, '85': 2799, 'internal': 2800, 'informed': 2801, 'boeing': 2802, 'marks': 2803, 'pays': 2804, 'battling': 2805, 'shots': 2806, 'commitment': 2807, 'thing': 2808, 'neighborhood': 2809, 'imports': 2810, 'fake': 2811, 'jewish': 2812, 'NHL': 2813, 'participate': 2814, 'tourist': 2815, 'ray': 2816, 'spill': 2817, 'andre': 2818, 'rocket': 2819, 'tight': 2820, 'drinking': 2821, 'probe': 2822, 'dan': 2823, 'fallen': 2824, 'switzerland': 2825, 'reading': 2826, 'engagement': 2827, 'kingdom': 2828, 'expressed': 2829, 'interim': 2830, '42': 2831, 'everything': 2832, 'remove': 2833, 'estimates': 2834, 'premiere': 2835, 'defeated': 2836, 'image': 2837, 'scam': 2838, 'resolution': 2839, 'announcing': 2840, 'criticism': 2841, 'arrive': 2842, 'notice': 2843, 'compete': 2844, 'dhabi': 2845, 'hike': 2846, 'junior': 2847, 'integrated': 2848, 'LLC': 2849, 'pedestrian': 2850, 'recorded': 2851, 'indonesian': 2852, 'arkansas': 2853, 'import': 2854, '2000': 2855, 'swimming': 2856, 'c': 2857, 'franklin': 2858, 'sean': 2859, 'roll': 2860, 'virgin': 2861, 'bit': 2862, 'features': 2863, 'edition': 2864, '100000': 2865, 'aniston': 2866, 'scientific': 2867, 'wait': 2868, 'provided': 2869, 'tea': 2870, 'shortage': 2871, 'urban': 2872, 'damaged': 2873, 'lankan': 2874, 'wildlife': 2875, 'charlotte': 2876, 'improving': 2877, 'onto': 2878, 'blast': 2879, 'provincial': 2880, 'everyone': 2881, 'derby': 2882, 'paying': 2883, 'YouTube': 2884, 'coffee': 2885, 'decide': 2886, 'raid': 2887, 'blow': 2888, 'delay': 2889, 'difficult': 2890, 'suggested': 2891, 'rushed': 2892, 'jay': 2893, 'masters': 2894, 'benchmark': 2895, 'figure': 2896, 'jump': 2897, 'haiti': 2898, 'secured': 2899, 'seasons': 2900, 'nominated': 2901, 'direction': 2902, '76': 2903, 'naval': 2904, 'johnny': 2905, 'tons': 2906, 'settle': 2907, 'escape': 2908, 'warner': 2909, 'cowell': 2910, 'featuring': 2911, 'pitch': 2912, 'chrysler': 2913, 'defend': 2914, 'pound': 2915, 'allowing': 2916, 'sweden': 2917, 'louisiana': 2918, 'betting': 2919, 'terry': 2920, 'plc': 2921, 'islands': 2922, 'federation': 2923, 'maryland': 2924, 'brings': 2925, 'steven': 2926, 'managing': 2927, 'learning': 2928, 'flying': 2929, 'craig': 2930, 'century': 2931, 'wave': 2932, 'belarus': 2933, 'god': 2934, 'defended': 2935, 'sister': 2936, 'lawrence': 2937, 'constitution': 2938, 'broadcast': 2939, 'cited': 2940, 'tornado': 2941, 'mostly': 2942, 'kidnapped': 2943, 'euros': 2944, 'azerbaijani': 2945, 'gunpoint': 2946, 'lawyers': 2947, 'neil': 2948, 'cancels': 2949, 'ukrainian': 2950, 'alexander': 2951, 'knife': 2952, 'ride': 2953, 'robin': 2954, 'rookie': 2955, 'cardinals': 2956, 'ferguson': 2957, 'bull': 2958, '5000': 2959, 'adults': 2960, 'bulgarian': 2961, 'armenia': 2962, 'bulls': 2963, 'seems': 2964, 'nicole': 2965, 'gates': 2966, 'compensation': 2967, 'easy': 2968, 'style': 2969, 'AG': 2970, 'charter': 2971, 'assigned': 2972, 'eagles': 2973, 'verizon': 2974, 'names': 2975, 'mental': 2976, 'location': 2977, 'feeling': 2978, 'traditional': 2979, 'table': 2980, '63': 2981, 'follow': 2982, 'bristol': 2983, 'influence': 2984, 'transit': 2985, 'interstate': 2986, 'cincinnati': 2987, 'amazon': 2988, 'suspension': 2989, 'civilians': 2990, 'barbara': 2991, 'violations': 2992, 'alternative': 2993, 'investigators': 2994, 'kristen': 2995, 'balance': 2996, 'word': 2997, 'delays': 2998, 'prepare': 2999, 'whole': 3000, 'approach': 3001, 'parent': 3002, 'warrant': 3003, 'UFC': 3004, 'mount': 3005, 'nashville': 3006, 'lay': 3007, 'bengal': 3008, 'crossing': 3009, 'visa': 3010, 'carter': 3011, 'kolkata': 3012, 'meetings': 3013, 'ran': 3014, 'plastic': 3015, 'resistance': 3016, 'tender': 3017, 'sends': 3018, 'core': 3019, 'includes': 3020, 'cyrus': 3021, 'kicks': 3022, 'lopez': 3023, 'occurred': 3024, 'maintain': 3025, 'registered': 3026, 'picked': 3027, 'reopen': 3028, 'fail': 3029, 'opportunity': 3030, 'reliance': 3031, 'anything': 3032, 'registration': 3033, 'preseason': 3034, '33': 3035, 'medvedev': 3036, 'maintenance': 3037, 'eve': 3038, 'images': 3039, 'mandela': 3040, 'described': 3041, 'murdered': 3042, 'supporting': 3043, 'globe': 3044, 'savings': 3045, 'centers': 3046, 'murdering': 3047, 'drowned': 3048, 'shortly': 3049, 'seventh': 3050, 'vows': 3051, 'processing': 3052, 'cuban': 3053, 'regulatory': 3054, 'villa': 3055, 'halt': 3056, 'LA': 3057, 'bruce': 3058, 'remaining': 3059, '34': 3060, 'barclays': 3061, 'colombia': 3062, 'targeted': 3063, 'reopened': 3064, 'ed': 3065, 'slowdown': 3066, 'trillion': 3067, 'joseph': 3068, 'trophy': 3069, 'districts': 3070, 'playoff': 3071, 'upper': 3072, 'swift': 3073, 'softball': 3074, 'hires': 3075, '36': 3076, 'suing': 3077, 'petrol': 3078, 'del': 3079, 'nicolas': 3080, 'montreal': 3081, 'PM': 3082, 'nepal': 3083, 'crown': 3084, 'arrests': 3085, 'hiring': 3086, 'nevada': 3087, 'rafael': 3088, 'maria': 3089, 'jazz': 3090, 'marathon': 3091, 'dealer': 3092, 'pilots': 3093, 'books': 3094, 'armstrong': 3095, 'clashes': 3096, 'blamed': 3097, 'aims': 3098, 'kidnapping': 3099, 'shah': 3100, 'flooding': 3101, 'checks': 3102, 'tower': 3103, 'carried': 3104, 'dismissed': 3105, 'lane': 3106, 'legislature': 3107, 'walmart': 3108, 'fleet': 3109, 'tottenham': 3110, 'longterm': 3111, 'restore': 3112, 'cowboys': 3113, 'pole': 3114, 'flag': 3115, 'putin': 3116, 'watson': 3117, 'pictures': 3118, 'withdraws': 3119, 'diabetes': 3120, 'comedian': 3121, 'delivered': 3122, 'door': 3123, 'asif': 3124, 'threw': 3125, 'judicial': 3126, 'retailers': 3127, 'organisation': 3128, 'taxi': 3129, 'material': 3130, 'benedict': 3131, 'jammu': 3132, 'employers': 3133, 'handed': 3134, 'materials': 3135, 'netherlands': 3136, 'heritage': 3137, 'enhance': 3138, 'trafficking': 3139, 'drilling': 3140, 'drew': 3141, '43': 3142, 'cyprus': 3143, 'inmate': 3144, 'suit': 3145, 'adopted': 3146, 'lama': 3147, 'duke': 3148, 'accept': 3149, 'dodgers': 3150, 'gained': 3151, 'walking': 3152, 'temporarily': 3153, 'suggests': 3154, 'collaboration': 3155, 'legislative': 3156, 'considers': 3157, 'volunteers': 3158, 'dinner': 3159, 'recalling': 3160, 'rob': 3161, 'clubs': 3162, 'tehran': 3163, 'liberal': 3164, 'cultural': 3165, 'prosecutor': 3166, 'comprehensive': 3167, 'improvement': 3168, 'lincoln': 3169, 'bars': 3170, 'exploration': 3171, 'bobby': 3172, 'miley': 3173, 'liam': 3174, '10th': 3175, 'promised': 3176, 'language': 3177, 'pat': 3178, 'walker': 3179, 'MAN': 3180, 'establish': 3181, 'speaks': 3182, 'downturn': 3183, '37': 3184, 'undisclosed': 3185, 'billy': 3186, 'dates': 3187, 'zoo': 3188, 'competitive': 3189, 'temple': 3190, 'estimated': 3191, 'hilton': 3192, 'till': 3193, 'emirates': 3194, 'jesse': 3195, 'intel': 3196, 'clark': 3197, 'crowd': 3198, 'honda': 3199, 'smoking': 3200, 'idea': 3201, 'revenues': 3202, 'NASCAR': 3203, 'reasons': 3204, 'parker': 3205, 'talking': 3206, 'similar': 3207, 'nominee': 3208, '700': 3209, 'bradley': 3210, 'wearing': 3211, 'chennai': 3212, 'shuttle': 3213, 'arson': 3214, 'exit': 3215, 'roster': 3216, 'principal': 3217, 'organizations': 3218, 'camera': 3219, 'upgraded': 3220, 'pub': 3221, 'regulators': 3222, 'backed': 3223, 'quickly': 3224, 'withdraw': 3225, 'scores': 3226, 'captured': 3227, '2006': 3228, 'shoots': 3229, 'AC': 3230, 'deutsche': 3231, 'hotels': 3232, 'NASA': 3233, 'emerged': 3234, 'limit': 3235, 'advantage': 3236, 'unveil': 3237, 'risks': 3238, 'proud': 3239, 'sure': 3240, 'bird': 3241, 'forthcoming': 3242, 'trees': 3243, 'ricky': 3244, 'raped': 3245, 'rains': 3246, 'creative': 3247, 'auckland': 3248, 'burning': 3249, 'retiring': 3250, 'carl': 3251, 'armenian': 3252, 'machine': 3253, 'conviction': 3254, 'dalai': 3255, 'roof': 3256, 'written': 3257, 'grants': 3258, 'restored': 3259, 'marking': 3260, 'classes': 3261, 'actually': 3262, 'produced': 3263, 'brandon': 3264, 'recording': 3265, 'p': 3266, 'listed': 3267, 'YORK': 3268, 'fitch': 3269, 'kick': 3270, 'undergoing': 3271, 'petroleum': 3272, 'welfare': 3273, 'kapoor': 3274, 'tools': 3275, 'casey': 3276, 'quits': 3277, 'tie': 3278, 'prominent': 3279, 'older': 3280, 'hawaii': 3281, 'unexpectedly': 3282, 'celebration': 3283, 'reaching': 3284, 'aaron': 3285, 'barry': 3286, 'inquiry': 3287, 'gujarat': 3288, 'attention': 3289, 'focused': 3290, 'physical': 3291, 'faced': 3292, 'danny': 3293, 'reid': 3294, 'parks': 3295, 'municipal': 3296, 'dick': 3297, 'register': 3298, 'wealth': 3299, '61': 3300, 'restrictions': 3301, 'IBM': 3302, 'kind': 3303, 'stepping': 3304, 'jamie': 3305, 'linebacker': 3306, 'delta': 3307, 'condemned': 3308, 'automotive': 3309, 'icon': 3310, 'fiji': 3311, 'commodity': 3312, 'bike': 3313, 'triple': 3314, 'presents': 3315, 'takeover': 3316, 'roberts': 3317, 'episode': 3318, '911': 3319, 'hedge': 3320, 'executives': 3321, 'unlikely': 3322, 'trail': 3323, 'diesel': 3324, 'worries': 3325, 'sound': 3326, 'minority': 3327, 'pushed': 3328, 'kuwait': 3329, 'sparked': 3330, 'cook': 3331, 'musharraf': 3332, 'poland': 3333, 'dublin': 3334, 'rand': 3335, 'degree': 3336, 'grew': 3337, 'section': 3338, 'houses': 3339, 'accidentally': 3340, 'operators': 3341, 'knocked': 3342, 'cap': 3343, 'upon': 3344, 'toddler': 3345, 'beauty': 3346, '800': 3347, 'lakh': 3348, 'warriors': 3349, 'gaming': 3350, 'affect': 3351, 'inter': 3352, 'wear': 3353, 'violating': 3354, 'guide': 3355, 'colombian': 3356, 'streak': 3357, 'hampshire': 3358, 'larry': 3359, 'honoured': 3360, 'undergoes': 3361, 'changing': 3362, 'raiders': 3363, 'thai': 3364, 'powers': 3365, 'minimum': 3366, 'speaking': 3367, 'downgraded': 3368, 'mets': 3369, 'master': 3370, 'witnesses': 3371, 'motorola': 3372, 'landed': 3373, 'raping': 3374, 'sunderland': 3375, '3000': 3376, 'royals': 3377, '55': 3378, 'keith': 3379, 'FBI': 3380, 'ESPN': 3381, 'knowledge': 3382, 'saved': 3383, 'motion': 3384, 'tool': 3385, 'plead': 3386, 'code': 3387, 'roy': 3388, 'original': 3389, 'infection': 3390, 'customs': 3391, 'nigerian': 3392, 'AM': 3393, 'sterling': 3394, 'lord': 3395, 'defending': 3396, 'collins': 3397, 'mar': 3398, 'responsibility': 3399, 'depression': 3400, 'accuses': 3401, 'rejects': 3402, 'malik': 3403, 'coordinator': 3404, 'adult': 3405, 'MTV': 3406, 'regions': 3407, 'caribbean': 3408, 'rush': 3409, 'permanent': 3410, 'hugo': 3411, 'ottawa': 3412, 'maoists': 3413, 'virtual': 3414, 'matthew': 3415, 'fields': 3416, 'probably': 3417, 'bigger': 3418, 'lok': 3419, 'citizen': 3420, 'interested': 3421, 'ian': 3422, 'twin': 3423, 'McCartney': 3424, 'read': 3425, 'shore': 3426, 'lender': 3427, 'finals': 3428, 'currencies': 3429, 'plus': 3430, 'picture': 3431, 'thinks': 3432, 'athletic': 3433, 'fastest': 3434, 'fixed': 3435, 'rolling': 3436, 'kris': 3437, 'capitol': 3438, 'sides': 3439, 'guns': 3440, 'tribal': 3441, 'leak': 3442, 'prove': 3443, 'cells': 3444, 'billionaire': 3445, 'freed': 3446, 'illegally': 3447, 'highs': 3448, 'link': 3449, 'lightning': 3450, 'commonwealth': 3451, 'hunger': 3452, 'chile': 3453, 'patriots': 3454, 'milestone': 3455, 'category': 3456, 'PC': 3457, 'routes': 3458, 'nadal': 3459, 'tries': 3460, 'demanded': 3461, 'firefighter': 3462, 'liberty': 3463, 'performed': 3464, '46': 3465, 'hughes': 3466, 'hair': 3467, 'endorses': 3468, 'memory': 3469, 'article': 3470, 'intends': 3471, 'greg': 3472, 'opera': 3473, 'sciences': 3474, 'parade': 3475, 'practices': 3476, 'extending': 3477, 'ted': 3478, 'dealing': 3479, 'animals': 3480, 'gaddafi': 3481, 'prior': 3482, 'cat': 3483, 'label': 3484, 'mukherjee': 3485, 'edged': 3486, '51': 3487, 'dolphins': 3488, 'encounter': 3489, 'withdrawn': 3490, 'shane': 3491, 'crack': 3492, 'included': 3493, 'rome': 3494, 'monitoring': 3495, 'bihar': 3496, 'sarkozy': 3497, 'bat': 3498, 'earned': 3499, 'fla': 3500, 'asylum': 3501, 'drought': 3502, 'collapse': 3503, 'outfielder': 3504, 'wine': 3505, 'heavyweight': 3506, 'established': 3507, 'salman': 3508, 'fails': 3509, 'agreements': 3510, 'dry': 3511, 'standoff': 3512, 'knight': 3513, 'christina': 3514, 'wholesale': 3515, 'unchanged': 3516, 'dropping': 3517, 'praised': 3518, 'abroad': 3519, 'kerala': 3520, 'sustained': 3521, 'alone': 3522, 'struggle': 3523, 'accepted': 3524, 'ranked': 3525, 'perth': 3526, 'karnataka': 3527, 'seize': 3528, 'retires': 3529, 'score': 3530, 'dave': 3531, 'lakers': 3532, 'tanker': 3533, 'fewer': 3534, 'writes': 3535, '48': 3536, 'montana': 3537, 'storms': 3538, 'rogers': 3539, 'latin': 3540, 'pet': 3541, 'increasingly': 3542, 'measure': 3543, 'developers': 3544, 'entering': 3545, 'passing': 3546, 'urging': 3547, 'moment': 3548, 'cubs': 3549, 'kidney': 3550, 'bachchan': 3551, 'lebanese': 3552, '72': 3553, 'structure': 3554, 'maine': 3555, 'tracking': 3556, 'twoyear': 3557, 'managers': 3558, 'resignation': 3559, 'pleased': 3560, 'marshall': 3561, 'palace': 3562, 'keen': 3563, 'romania': 3564, 'kenny': 3565, 'murphy': 3566, 'poised': 3567, 'rallied': 3568, 'unique': 3569, 'islamabad': 3570, 'releasing': 3571, 'required': 3572, 'appointment': 3573, 'magic': 3574, 'remarks': 3575, 'controversy': 3576, 'goalkeeper': 3577, 'restaurants': 3578, 'ranks': 3579, 'reason': 3580, 'teens': 3581, 'drone': 3582, 'hear': 3583, 'tensions': 3584, 'guards': 3585, 'era': 3586, 'kerry': 3587, 'ore': 3588, 'burned': 3589, 'sacramento': 3590, 'governments': 3591, 'shipping': 3592, 'someone': 3593, 'pushing': 3594, 'innovative': 3595, 'respect': 3596, 'kanye': 3597, 'drink': 3598, 'gap': 3599, 'jerusalem': 3600, 'kyle': 3601, 'entry': 3602, 'providers': 3603, 'adviser': 3604, 'saints': 3605, 'communication': 3606, 'renewable': 3607, 'surge': 3608, 'significantly': 3609, 'innings': 3610, 'athletes': 3611, 'everton': 3612, 'trucks': 3613, 'lands': 3614, 'vladimir': 3615, 'publisher': 3616, 'buyers': 3617, 'neck': 3618, 'photos': 3619, 'holmes': 3620, 'pak': 3621, 'dramatic': 3622, 'possibility': 3623, 'weapon': 3624, 'upset': 3625, 'served': 3626, 'cameras': 3627, '250': 3628, 'anyone': 3629, 'determined': 3630, 'loves': 3631, 'forecasts': 3632, 'aston': 3633, 'muslims': 3634, 'size': 3635, 'militant': 3636, 'dow': 3637, 'BlackBerry': 3638, 'backs': 3639, 'sues': 3640, 'skipper': 3641, 'conspiracy': 3642, 'revolution': 3643, 'attacking': 3644, 'waivers': 3645, 'roman': 3646, 'terminal': 3647, 'crackdown': 3648, 'hunt': 3649, 'spokeswoman': 3650, 'refuses': 3651, 'thrown': 3652, 'thompson': 3653, 'reduction': 3654, 'hunting': 3655, 'membership': 3656, 'trailer': 3657, 'fun': 3658, 'potentially': 3659, 'crashing': 3660, 'salary': 3661, 'prospect': 3662, 'recycling': 3663, 'nebraska': 3664, 'accepting': 3665, 'HP': 3666, 'adams': 3667, 'sectors': 3668, 'indianapolis': 3669, 'baghdad': 3670, 'quite': 3671, 'tablet': 3672, 'resource': 3673, 'count': 3674, 'politicians': 3675, 'worse': 3676, 'PTI': 3677, 'delaware': 3678, 'endorsed': 3679, 'firing': 3680, 'transaction': 3681, 'sue': 3682, 'solo': 3683, 'foster': 3684, 'drunken': 3685, 'humanitarian': 3686, 'brisbane': 3687, 'proposes': 3688, 'tyler': 3689, 'selection': 3690, 'MPs': 3691, 'computers': 3692, 'motorcyclist': 3693, '44': 3694, 'graham': 3695, 'northwestern': 3696, 'smartphones': 3697, 'volleyball': 3698, 'allstar': 3699, 'lance': 3700, 'blame': 3701, 'acres': 3702, 'injuring': 3703, 'universal': 3704, 'metals': 3705, 'FIFA': 3706, 'fed': 3707, 'affordable': 3708, 'envoy': 3709, 'III': 3710, 'fisher': 3711, 'pulls': 3712, 'publicly': 3713, 'theater': 3714, 'puts': 3715, 'kosovo': 3716, 'reveal': 3717, 'ashley': 3718, 'burns': 3719, 'vatican': 3720, 'path': 3721, '52': 3722, '38': 3723, 'faster': 3724, 'stands': 3725, 'actions': 3726, 'zuma': 3727, 'rollover': 3728, 'pit': 3729, 'pledged': 3730, 'wreck': 3731, 'tracks': 3732, 'mario': 3733, 'eddie': 3734, 'skills': 3735, 'familiar': 3736, 'innovation': 3737, 'brief': 3738, 'trouble': 3739, 'guidance': 3740, 'gilani': 3741, 'formed': 3742, 'standing': 3743, 'complaints': 3744, 'adopt': 3745, 'picks': 3746, 'demanding': 3747, 'limits': 3748, 'rebound': 3749, 'rolled': 3750, 'evans': 3751, 'ross': 3752, 'mahmoud': 3753, 'citigroup': 3754, 'slipped': 3755, 'rooney': 3756, 'underwent': 3757, 'ahmadinejad': 3758, 'task': 3759, 'manage': 3760, 'sustainable': 3761, 'saint': 3762, 'insisted': 3763, 'raza': 3764, 'gift': 3765, 'attempting': 3766, 'DUI': 3767, 'jonathan': 3768, 'external': 3769, 'throws': 3770, 'boosted': 3771, 'songs': 3772, 'scale': 3773, 'misdemeanor': 3774, 'critically': 3775, 'slammed': 3776, 'imposed': 3777, 'buried': 3778, 'affair': 3779, 'rockets': 3780, 'streaming': 3781, 'vaccine': 3782, 'lenders': 3783, 'visitors': 3784, 'zero': 3785, 'workforce': 3786, 'shareholder': 3787, 'GM': 3788, 'georgian': 3789, 'qualifying': 3790, 'sovereign': 3791, 'Twenty20': 3792, 'brett': 3793, 'foreclosure': 3794, 'tsunami': 3795, 'commits': 3796, 'agricultural': 3797, 'guest': 3798, 'wrote': 3799, 'upgrade': 3800, 'mills': 3801, 'alongside': 3802, 'rachel': 3803, 'costa': 3804, 'maritime': 3805, 'wheat': 3806, 'featured': 3807, 'hip': 3808, 'prospects': 3809, 'sponsor': 3810, 'outbreak': 3811, 'blaze': 3812, 'seats': 3813, 'mill': 3814, 'prepares': 3815, 'wage': 3816, 'momentum': 3817, 'douglas': 3818, 'assignment': 3819, 'promises': 3820, '53': 3821, 'approve': 3822, 'stream': 3823, 'dean': 3824, 'heidi': 3825, 'reducing': 3826, 'jeremy': 3827, 'semifinal': 3828, 'starring': 3829, 'superior': 3830, 'editor': 3831, 'voluntary': 3832, 'slip': 3833, 'harper': 3834, 'munich': 3835, 'revised': 3836, 'fares': 3837, 'conservation': 3838, 'reserves': 3839, 'stress': 3840, 'pickup': 3841, 'corps': 3842, 'declines': 3843, 'hunter': 3844, 'maharashtra': 3845, 'variety': 3846, 'select': 3847, 'finding': 3848, 'NC': 3849, 'strongly': 3850, 'trains': 3851, 'julian': 3852, 'treat': 3853, 'analysis': 3854, 'senators': 3855, 'studies': 3856, 'interests': 3857, 'skin': 3858, 'character': 3859, 'prepared': 3860, 'blog': 3861, 'clothing': 3862, 'promoting': 3863, 'courts': 3864, 'greatest': 3865, 'weakened': 3866, 'resolve': 3867, 'poverty': 3868, 'forcing': 3869, 'AFP': 3870, 'bombing': 3871, 'modi': 3872, 'browns': 3873, 'pharmaceuticals': 3874, '3D': 3875, 'type': 3876, 'wright': 3877, 'kent': 3878, 'hub': 3879, 'models': 3880, 'vision': 3881, 'closure': 3882, 'writing': 3883, 'attempts': 3884, 'saving': 3885, 'berlusconi': 3886, 'directed': 3887, 'communist': 3888, 'midnight': 3889, 'beer': 3890, 'blues': 3891, 'ken': 3892, '120': 3893, 'interactive': 3894, 'promoted': 3895, 'ability': 3896, 'lung': 3897, 'suspend': 3898, 'watching': 3899, 'links': 3900, 'fly': 3901, 'shock': 3902, 'broncos': 3903, 'coaches': 3904, 'donald': 3905, 'apologizes': 3906, 'mind': 3907, 'replaced': 3908, 'dell': 3909, 'advice': 3910, 'temperatures': 3911, 'airbus': 3912, 'discharged': 3913, 'uses': 3914, 'effects': 3915, 'eighth': 3916, 'FA': 3917, 'jobless': 3918, 'cairo': 3919, 'enterprises': 3920, 'quick': 3921, 'qantas': 3922, '50000': 3923, 'stranded': 3924, 'catches': 3925, 'abusing': 3926, 'plunged': 3927, 'neutral': 3928, 'holidays': 3929, 'angry': 3930, 'argument': 3931, 'laden': 3932, 'supported': 3933, 'apologized': 3934, 'celtic': 3935, 'pending': 3936, 'trials': 3937, 'contractor': 3938, 'sep': 3939, 'rochester': 3940, 'write': 3941, 'springfield': 3942, 'venezuelan': 3943, 'braves': 3944, 'julia': 3945, 'sporting': 3946, 'baseman': 3947, 'raw': 3948, 'bans': 3949, 'redskins': 3950, '82': 3951, 'prescription': 3952, 'walked': 3953, 'oneyear': 3954, 'middleton': 3955, 'WikiLeaks': 3956, 'assange': 3957, 'vodafone': 3958, 'stability': 3959, 'user': 3960, 'trapped': 3961, 'chamber': 3962, '2015': 3963, '95': 3964, 'coaching': 3965, 'telecommunications': 3966, 'phillies': 3967, 'telling': 3968, 'chancellor': 3969, 'susan': 3970, 'fighters': 3971, 'cyclist': 3972, 'musician': 3973, 'sons': 3974, 'locations': 3975, 'vessel': 3976, 'marked': 3977, 'bangalore': 3978, 'crystal': 3979, 'motorists': 3980, 'semifinals': 3981, 'haryana': 3982, 'wellington': 3983, 'chosen': 3984, 'mom': 3985, 'peak': 3986, 'corner': 3987, 'burn': 3988, 'sharks': 3989, 'BC': 3990, 'pete': 3991, 'jefferson': 3992, 'individual': 3993, 'defenseman': 3994, '67': 3995, 'studios': 3996, 'mason': 3997, 'accusing': 3998, 'switch': 3999, 'crucial': 4000, 'photographer': 4001, 'premium': 4002, 'pharmaceutical': 4003, 'attract': 4004, 'workshop': 4005, 'documentary': 4006, 'v': 4007, 'apply': 4008, 'tank': 4009, 'heights': 4010, 'stops': 4011, 'abdullah': 4012, 'misses': 4013, 'resumed': 4014, 'r': 4015, 'pizza': 4016, 'supermarket': 4017, 'wire': 4018, 'AN': 4019, 'answer': 4020, 'addition': 4021, 'ronaldo': 4022, 'uranium': 4023, 'requirements': 4024, 'liquor': 4025, 'randy': 4026, 'surplus': 4027, 'feared': 4028, 'donated': 4029, 'allows': 4030, 'favorite': 4031, 'stepped': 4032, 'bishop': 4033, 'idaho': 4034, 'spencer': 4035, 'lying': 4036, 'throwing': 4037, 'faith': 4038, 'chidambaram': 4039, 'computing': 4040, 'cliff': 4041, 'unknown': 4042, 'mean': 4043, 'immigrants': 4044, 'ANC': 4045, 'danger': 4046, 'settled': 4047, 'sandy': 4048, 'BMW': 4049, 'priority': 4050, 'jacob': 4051, 'bomber': 4052, 'involvement': 4053, 'sleep': 4054, 'nobel': 4055, 'beef': 4056, 'pregnancy': 4057, 'glass': 4058, 'eased': 4059, 'quoted': 4060, 'string': 4061, 'IMF': 4062, 'grove': 4063, 'refinance': 4064, 'amendment': 4065, 'gene': 4066, 'eagle': 4067, 'uncertainty': 4068, 'earn': 4069, 'resumes': 4070, 'montgomery': 4071, 'rajasthan': 4072, 'drove': 4073, 'efficiency': 4074, 'wing': 4075, 'remote': 4076, 'berlin': 4077, 'lawmaker': 4078, 'possibly': 4079, 'babies': 4080, 'hole': 4081, 'celebrations': 4082, 'equities': 4083, 'unable': 4084, 'spokesperson': 4085, 'monitor': 4086, 'sonia': 4087, 'either': 4088, 'volume': 4089, 'norway': 4090, 'attending': 4091, 'winger': 4092, 'universities': 4093, 'opinion': 4094, 'implement': 4095, 'spirit': 4096, 'lil': 4097, 'anne': 4098, 'garage': 4099, 'indies': 4100, 'gunmen': 4101, 'gomez': 4102, 'clinical': 4103, 'HTC': 4104, 'austerity': 4105, 'forms': 4106, 'subject': 4107, 'adelaide': 4108, 'sessions': 4109, 'bottom': 4110, 'favourite': 4111, '11th': 4112, 'robinson': 4113, 'ravens': 4114, 'leeds': 4115, 'prostate': 4116, 'dad': 4117, 'presidency': 4118, 'websites': 4119, 'porn': 4120, 'ham': 4121, 'lucky': 4122, 'jacksonville': 4123, 'karzai': 4124, 'flash': 4125, 'grocery': 4126, 'seeing': 4127, 'rahul': 4128, 'mubarak': 4129, 'memphis': 4130, 'potter': 4131, 'inducted': 4132, 'comment': 4133, 'expenses': 4134, 'floods': 4135, 'followed': 4136, 'auburn': 4137, 'solid': 4138, 'widespread': 4139, 'nursing': 4140, 'syed': 4141, 'shelter': 4142, 'refusing': 4143, 'dmitry': 4144, 'broad': 4145, 'brussels': 4146, 'ward': 4147, 'ski': 4148, 'petition': 4149, 'commissioners': 4150, '71': 4151, 'carey': 4152, 'blasts': 4153, 'refinery': 4154, 'cancel': 4155, 'economies': 4156, 'ambulance': 4157, 'moss': 4158, 'mahindra': 4159, 'counterpart': 4160, 'cinema': 4161, 'bags': 4162, 'watchdog': 4163, 'automaker': 4164, 'piece': 4165, 'prevention': 4166, 'consumption': 4167, 'abandoned': 4168, 'cotton': 4169, 'confirm': 4170, 'secondary': 4171, 'aggravated': 4172, 'witness': 4173, 'lily': 4174, 'catch': 4175, 'hopeful': 4176, 'prostitution': 4177, 'discussed': 4178, 'disappointing': 4179, 'parish': 4180, 'somalia': 4181, '54': 4182, 'abortion': 4183, 'warn': 4184, 'portsmouth': 4185, 'muhammad': 4186, 'producing': 4187, 'chef': 4188, '900': 4189, 'moon': 4190, 'makers': 4191, 'thieves': 4192, 'polish': 4193, 'grade': 4194, 'serial': 4195, 'papers': 4196, 'salt': 4197, 'winners': 4198, 'naked': 4199, 'juan': 4200, 'fernando': 4201, 'amanda': 4202, 'overhaul': 4203, 'landmark': 4204, 'NHS': 4205, 'proposals': 4206, 'recognition': 4207, 'rental': 4208, 'regulator': 4209, 'creation': 4210, '66': 4211, 'diplomat': 4212, 'abbas': 4213, '39': 4214, 'messages': 4215, 'sharing': 4216, 'tops': 4217, 'completely': 4218, 'staterun': 4219, 'licence': 4220, 'sing': 4221, 'coroner': 4222, 'lovato': 4223, 'sacked': 4224, 'reds': 4225, 'quinn': 4226, 'pink': 4227, 'tommy': 4228, 'performs': 4229, 'vikings': 4230, 'baldwin': 4231, 'privacy': 4232, 'accidents': 4233, 'PGA': 4234, 'newest': 4235, 'spoke': 4236, 'louisville': 4237, 'tibetan': 4238, 'suggesting': 4239, 'mugabe': 4240, 'particularly': 4241, 'hanging': 4242, '20th': 4243, 'todd': 4244, 'words': 4245, 'hu': 4246, 'investigated': 4247, 'trades': 4248, 'praises': 4249, 'shops': 4250, 'absence': 4251, 'obesity': 4252, 'wimbledon': 4253, 'convenience': 4254, 'cruelty': 4255, 'aim': 4256, 'eating': 4257, 'fiveyear': 4258, '68': 4259, 'nightclub': 4260, 'bayern': 4261, 'emma': 4262, 'gasoline': 4263, 'roles': 4264, 'keeps': 4265, 'initiatives': 4266, 'command': 4267, 'lifetime': 4268, 'underway': 4269, 'costar': 4270, 'bryant': 4271, 'AFL': 4272, 'vital': 4273, 'richmond': 4274, 'nancy': 4275, 'species': 4276, 'ferrari': 4277, 'rapid': 4278, 'publishing': 4279, 'transition': 4280, 'chest': 4281, 'concerned': 4282, 'nintendo': 4283, 'milk': 4284, 'centres': 4285, 'viewers': 4286, 'concluded': 4287, 'consulting': 4288, 'overcome': 4289, 'driven': 4290, 'max': 4291, 'upgrades': 4292, 'warming': 4293, 'slashed': 4294, 'exposure': 4295, 'actors': 4296, 'filmmaker': 4297, '50th': 4298, 'ericsson': 4299, 'grid': 4300, 'audience': 4301, 'pentagon': 4302, 'scrap': 4303, 'gathered': 4304, 'crowned': 4305, 'robbie': 4306, 'HIV': 4307, 'seoul': 4308, 'assist': 4309, 'arnold': 4310, 'offences': 4311, 'robbing': 4312, 'integration': 4313, 'DJ': 4314, 'sheikh': 4315, 'emissions': 4316, 'mitchell': 4317, 'surrounding': 4318, 'staying': 4319, 'broadcasting': 4320, 'purchases': 4321, 'frozen': 4322, 'colleges': 4323, 'riding': 4324, 'shed': 4325, 'xinhua': 4326, 'heroin': 4327, 'identify': 4328, 'brooklyn': 4329, 'achieved': 4330, 'eat': 4331, 'defeats': 4332, 'arctic': 4333, 'bag': 4334, 'athens': 4335, 'yemeni': 4336, 'hungary': 4337, 'aide': 4338, 'jesus': 4339, 'uttar': 4340, '49': 4341, 'honorary': 4342, 'threeyear': 4343, 'respond': 4344, 'rodriguez': 4345, '83': 4346, 'tendulkar': 4347, 'diplomats': 4348, 'extreme': 4349, 'christie': 4350, 'tape': 4351, 'qaeda': 4352, 'titans': 4353, 'flames': 4354, 'unity': 4355, 'rapids': 4356, 'planes': 4357, 'acts': 4358, 'constitutional': 4359, 'jake': 4360, 'pranab': 4361, 'unidentified': 4362, 'manhattan': 4363, 'discrimination': 4364, \"'\": 4365, 'miners': 4366, 'gibson': 4367, 'branches': 4368, 'vacant': 4369, 'concussion': 4370, 'oldest': 4371, 'lows': 4372, 'refugees': 4373, 'sick': 4374, 'stakes': 4375, 'client': 4376, 'sisters': 4377, 'predicted': 4378, 'mines': 4379, 'swept': 4380, 'scare': 4381, 'survive': 4382, 'finger': 4383, 'bone': 4384, 'advised': 4385, 'professionals': 4386, 'determine': 4387, 'slash': 4388, 'drowns': 4389, 'seed': 4390, 'edmonton': 4391, 'buses': 4392, 'kitchen': 4393, 'recognized': 4394, 'titles': 4395, 'critics': 4396, 'holy': 4397, 'missiles': 4398, 'specialty': 4399, '12th': 4400, '125': 4401, 'versus': 4402, 'hostage': 4403, 'schwarzenegger': 4404, 'childhood': 4405, 'suffer': 4406, 'pricing': 4407, 'sitting': 4408, 'baku': 4409, 'elton': 4410, 'youths': 4411, 'hate': 4412, 'netanyahu': 4413, 'rolls': 4414, 'steelers': 4415, 'torch': 4416, 'improves': 4417, 'roberto': 4418, 'directly': 4419, 'importance': 4420, 'spectrum': 4421, 'branded': 4422, 'alberta': 4423, 'ownership': 4424, 'airports': 4425, 'channels': 4426, 'athletics': 4427, 'chip': 4428, 'tributes': 4429, 'nature': 4430, 'ninth': 4431, 'leon': 4432, 'outdoor': 4433, 'skip': 4434, 'peaceful': 4435, 'furniture': 4436, 'deposit': 4437, 'suzuki': 4438, 'clothes': 4439, 'differences': 4440, 'wenger': 4441, 'gross': 4442, 'peru': 4443, 'lt': 4444, 'northeastern': 4445, 'tobacco': 4446, 'hyderabad': 4447, 'seahawks': 4448, 'slams': 4449, 'beverly': 4450, 'chicken': 4451, 'destroys': 4452, '1st': 4453, 'advances': 4454, 'iconic': 4455, 'basic': 4456, 'affiliate': 4457, 'audio': 4458, 'brady': 4459, 'mars': 4460, 'unrest': 4461, 'lion': 4462, 'text': 4463, 'default': 4464, 'signal': 4465, 'easter': 4466, 'exploded': 4467, 'drawing': 4468, 'shift': 4469, 'clerk': 4470, 'jays': 4471, 'ecuador': 4472, '20yearold': 4473, '1500': 4474, 'estranged': 4475, 'looked': 4476, 'rupert': 4477, 'murdoch': 4478, 'orioles': 4479, 'occupy': 4480, 'wages': 4481, 'gunman': 4482, 'bed': 4483, 'condemns': 4484, 'PLC': 4485, 'shell': 4486, 'inspired': 4487, 'surveillance': 4488, 'federer': 4489, 'luke': 4490, 'offset': 4491, 'prisoner': 4492, 'hamid': 4493, 'download': 4494, 'anticipated': 4495, 'guitarist': 4496, 'minute': 4497, 'nearby': 4498, '47': 4499, 'sharif': 4500, 'ships': 4501, 'bounce': 4502, '57': 4503, 'crop': 4504, 'unless': 4505, 'billions': 4506, 'deer': 4507, 'timberlake': 4508, 'bids': 4509, 'ashton': 4510, 'swim': 4511, 'stuck': 4512, 'topped': 4513, 'educational': 4514, 'discussion': 4515, 'locked': 4516, 'regulations': 4517, 'surged': 4518, 'ace': 4519, 'WASHINGTON': 4520, 'grain': 4521, 'suburban': 4522, 'francis': 4523, 'celtics': 4524, '74': 4525, 'operate': 4526, 'canadians': 4527, 'nissan': 4528, 'easing': 4529, 'inaugural': 4530, 'bolton': 4531, 'fill': 4532, 'easily': 4533, 'electrical': 4534, 'owen': 4535, '2005': 4536, 'declining': 4537, 'APA': 4538, 'installed': 4539, 'doubled': 4540, 'shared': 4541, 'judiciary': 4542, 'barnes': 4543, 'marc': 4544, '73': 4545, 'rebel': 4546, 'strengthened': 4547, 'commodities': 4548, 'artists': 4549, 'dozen': 4550, 'slowed': 4551, 'yields': 4552, 'household': 4553, 'roadside': 4554, 'pacquiao': 4555, 'elephant': 4556, 'races': 4557, 'rivers': 4558, 'robber': 4559, 'diseases': 4560, 'cheating': 4561, 'promising': 4562, 'ballot': 4563, 'osbourne': 4564, 'broadcaster': 4565, 'optimism': 4566, 'finland': 4567, 'bloomberg': 4568, 'ultimate': 4569, 'reopens': 4570, 'attended': 4571, 'southeastern': 4572, 'argentine': 4573, 'elbow': 4574, '77': 4575, 'evasion': 4576, 'sweep': 4577, '56': 4578, 'telephone': 4579, 'acquitted': 4580, 'castro': 4581, 'cisco': 4582, 'behaviour': 4583, 'hailed': 4584, 'oracle': 4585, 'rod': 4586, 'administrative': 4587, 'observed': 4588, 'investing': 4589, 'mystery': 4590, 'evacuation': 4591, 'occupied': 4592, 'referendum': 4593, 'contain': 4594, 'lottery': 4595, 'pastor': 4596, 'inning': 4597, 'rumors': 4598, 'cycling': 4599, 'novel': 4600, 'engineers': 4601, 'guru': 4602, 'pioneer': 4603, 'slump': 4604, 'stripped': 4605, 'transplant': 4606, 'academic': 4607, 'warm': 4608, 'pilgrims': 4609, 'smaller': 4610, 'multiyear': 4611, 'heath': 4612, 'slowing': 4613, 'nominations': 4614, 'martinez': 4615, 'penguins': 4616, 'spy': 4617, 'insider': 4618, 'norwich': 4619, 'capable': 4620, 'screening': 4621, '88': 4622, 'posting': 4623, 'nadu': 4624, 'blind': 4625, 'younger': 4626, 'completion': 4627, 'disputed': 4628, 'eva': 4629, 'happen': 4630, 'manufacturers': 4631, 'amnesty': 4632, 'violation': 4633, 'fireworks': 4634, 'wolves': 4635, 'warehouse': 4636, 'sachin': 4637, 'bernard': 4638, 'detention': 4639, 'inmates': 4640, 'combined': 4641, 'priest': 4642, 'enjoy': 4643, 'WWE': 4644, 'robberies': 4645, 'postal': 4646, 'unpaid': 4647, 'honour': 4648, 'grave': 4649, 'simple': 4650, 'ethnic': 4651, 'census': 4652, 'aggressive': 4653, 'dennis': 4654, 'teaching': 4655, 'doubles': 4656, 'permits': 4657, 'enable': 4658, 'scoring': 4659, 'dumped': 4660, 'crunch': 4661, 'maximum': 4662, 'emotional': 4663, 'jumps': 4664, 'freddie': 4665, 'sense': 4666, 'pervez': 4667, 'whitney': 4668, 'chances': 4669, 'decisions': 4670, 'print': 4671, 'newspapers': 4672, 'pride': 4673, 'delivers': 4674, 'twoday': 4675, 'operational': 4676, 'gather': 4677, 'yard': 4678, 'runway': 4679, 'colin': 4680, 'slide': 4681, 'jewelry': 4682, 'individuals': 4683, '21yearold': 4684, 'collided': 4685, 'boycott': 4686, 'clarke': 4687, 'values': 4688, 'cheney': 4689, 'disclosed': 4690, 'ann': 4691, 'marcus': 4692, 'XVI': 4693, 'serbian': 4694, 'farmer': 4695, 'frontman': 4696, 'blocked': 4697, 'donations': 4698, '69': 4699, 'PlayStation': 4700, 'smuggling': 4701, 'yes': 4702, 'chart': 4703, 'collapses': 4704, 'packaging': 4705, 'dress': 4706, 'donates': 4707, 'threeday': 4708, 'continental': 4709, 'ridge': 4710, 'aberdeen': 4711, 'guarantee': 4712, 'hybrid': 4713, 'breakfast': 4714, 'stem': 4715, 'abdul': 4716, 'sensation': 4717, 'deposits': 4718, 'beyonce': 4719, 'reverse': 4720, 'brewers': 4721, 'unbeaten': 4722, 'borrowing': 4723, 'teenagers': 4724, 'diet': 4725, 'originally': 4726, 'achieve': 4727, 'applied': 4728, 'cambridge': 4729, 'weakness': 4730, 'jonas': 4731, 'NJ': 4732, 'thanksgiving': 4733, 'bombs': 4734, '86': 4735, 'SUV': 4736, '200000': 4737, 'selena': 4738, 'cope': 4739, 'gen': 4740, 'pact': 4741, 'bernanke': 4742, 'racist': 4743, 'survived': 4744, 'pulling': 4745, 'bowling': 4746, 'necessary': 4747, 'xbox': 4748, '81': 4749, 'fled': 4750, 'agenda': 4751, 'suu': 4752, 'kyi': 4753, 'trainer': 4754, 'princess': 4755, 'damages': 4756, 'berry': 4757, 'dame': 4758, 'ceasefire': 4759, 'atomic': 4760, '130': 4761, 'grammy': 4762, 'electoral': 4763, 'sandra': 4764, 'floyd': 4765, 'apology': 4766, 'ashes': 4767, 'designated': 4768, 'lynch': 4769, 'rumours': 4770, 'seminar': 4771, 'syracuse': 4772, 'departments': 4773, 'eyes': 4774, 'wings': 4775, 'aboard': 4776, 'steal': 4777, 'easier': 4778, 'advisor': 4779, 'striking': 4780, 'pharmacy': 4781, 'cyber': 4782, 'soul': 4783, 'letters': 4784, '78': 4785, 'wildfire': 4786, 'lived': 4787, 'johannesburg': 4788, 'quoting': 4789, 'throw': 4790, 'inquest': 4791, 'who': 4792, 'horror': 4793, 'endorse': 4794, 'amitabh': 4795, 'monroe': 4796, 'feed': 4797, 'plot': 4798, 'understand': 4799, 'pleading': 4800, 'beautiful': 4801, 'cofounder': 4802, 'oneday': 4803, 'rehabilitation': 4804, 'angels': 4805, 'meat': 4806, 'permission': 4807, 'DNA': 4808, 'gillard': 4809, 'prompting': 4810, 'briefly': 4811, 'mel': 4812, 'ancient': 4813, 'lakes': 4814, 'pledge': 4815, 'staged': 4816, 'poker': 4817, 'amber': 4818, 'burglaries': 4819, 'eliminate': 4820, 'escapes': 4821, 'sebastian': 4822, 'tribune': 4823, 'freight': 4824, 'obtained': 4825, 'verdict': 4826, 'angel': 4827, 'playoffs': 4828, 'watched': 4829, 'machines': 4830, 'definitely': 4831, 'coastal': 4832, 'apart': 4833, 'albert': 4834, 'capture': 4835, 'crushed': 4836, 'presidentelect': 4837, 'righthander': 4838, 'odds': 4839, 'statewide': 4840, 'preparation': 4841, 'ICC': 4842, 'hometown': 4843, 'exwife': 4844, 'portugal': 4845, 'UBS': 4846, 'graduate': 4847, 'restraining': 4848, 'duties': 4849, 'remembered': 4850, 'merkel': 4851, 'rocker': 4852, 'NRL': 4853, 'lunch': 4854, 'volunteer': 4855, 'creator': 4856, 'titled': 4857, 'framework': 4858, 'oscars': 4859, 'levy': 4860, 'belgian': 4861, 'climbed': 4862, 'formal': 4863, 'regulation': 4864, 'recruiting': 4865, 'coleman': 4866, '2004': 4867, 'christopher': 4868, 'retained': 4869, 'valued': 4870, 'theme': 4871, 'placement': 4872, 'gallagher': 4873, 'alqaeda': 4874, 'drinks': 4875, 'karachi': 4876, 'juventus': 4877, 'shark': 4878, 'audit': 4879, 'definitive': 4880, 'suite': 4881, 'responded': 4882, 'cautious': 4883, 'worried': 4884, 'fundraising': 4885, '100th': 4886, 'belgium': 4887, 'qualify': 4888, 'unprecedented': 4889, 'discount': 4890, 'datuk': 4891, 'abducted': 4892, 'mentally': 4893, 'oak': 4894, 'treaty': 4895, 'institution': 4896, 'bronze': 4897, 'delivering': 4898, 'larger': 4899, 'harrison': 4900, 'punishment': 4901, 'awardwinning': 4902, 'manny': 4903, 'tablets': 4904, 'representing': 4905, 'indefinite': 4906, '20000': 4907, '91': 4908, 'swap': 4909, 'lab': 4910, 'rallies': 4911, 'tag': 4912, 'denmark': 4913, '101': 4914, 'empire': 4915, 'challenging': 4916, 'tentative': 4917, 'nurse': 4918, 'bosses': 4919, 'quarterfinals': 4920, 'ferry': 4921, '84': 4922, 'blocks': 4923, 'drill': 4924, 'commit': 4925, 'apologised': 4926, 'warnings': 4927, 'norman': 4928, 'aside': 4929, 'liver': 4930, 'dam': 4931, 'wars': 4932, 'magnitude': 4933, 'midwest': 4934, 'pneumonia': 4935, 'wish': 4936, 'moody': 4937, 'andhra': 4938, 'marion': 4939, 'islam': 4940, 'lloyd': 4941, 'cardiac': 4942, 'unanimously': 4943, 'mohammed': 4944, 'civilian': 4945, 'remember': 4946, 'opponents': 4947, 'lifts': 4948, 'stages': 4949, 'extremely': 4950, 'severely': 4951, 'reviews': 4952, 'shoppers': 4953, 'phillips': 4954, 'seconds': 4955, 'desert': 4956, 'replacement': 4957, 'submitted': 4958, 'responding': 4959, 'dairy': 4960, 'assam': 4961, 'HSBC': 4962, 'borders': 4963, 'views': 4964, 'IST': 4965, 'towns': 4966, 'knew': 4967, 'intervention': 4968, 'moderate': 4969, 'closely': 4970, 'bashar': 4971, 'CBI': 4972, 'shootout': 4973, 'soft': 4974, 'entitled': 4975, 'lineman': 4976, 'shape': 4977, 'boyle': 4978, 'composer': 4979, 'austria': 4980, 'replacing': 4981, 'governance': 4982, 'abbott': 4983, '500000': 4984, 'batsman': 4985, '79': 4986, 'widely': 4987, 'omaha': 4988, 'pump': 4989, 'corn': 4990, 'LP': 4991, 'arbitration': 4992, 'homeowners': 4993, 'substantial': 4994, 'lights': 4995, 'gear': 4996, 'keys': 4997, 'compliance': 4998, 'yuan': 4999, 'promise': 5000, 'parole': 5001, 'demonstration': 5002, 'stones': 5003, 'emerge': 5004, 'lease': 5005, 'osama': 5006, 'blackburn': 5007, 'semiconductor': 5008, 'newman': 5009, 'pollution': 5010, 'romanian': 5011, 'spurs': 5012, 'harassment': 5013, 'flagship': 5014, 'southwestern': 5015, 'hull': 5016, 'pattern': 5017, 'norwegian': 5018, 'butler': 5019, 'infant': 5020, 'distributor': 5021, '2nd': 5022, 'exposed': 5023, 'gambling': 5024, 'rebounds': 5025, 'ethics': 5026, 'leaked': 5027, 'declare': 5028, 'invitation': 5029, 'wichita': 5030, 'dental': 5031, 'climb': 5032, 'appointments': 5033, 'outfit': 5034, 'blake': 5035, 'capabilities': 5036, 'giffords': 5037, 'thousand': 5038, 'shoes': 5039, 'questioned': 5040, 'detective': 5041, 'darren': 5042, 'cardiff': 5043, 'freeze': 5044, 'covering': 5045, 'organized': 5046, 'loved': 5047, 'appealing': 5048, 'mild': 5049, 'destination': 5050, 'cool': 5051, 'glee': 5052, 'knot': 5053, 'scenes': 5054, 'cruz': 5055, 'disciplinary': 5056, 'filming': 5057, 'footballer': 5058, 'recommended': 5059, 'damascus': 5060, 'pretty': 5061, 'mayer': 5062, 'politician': 5063, 'sp': 5064, 'rudd': 5065, 'decrease': 5066, 'recruit': 5067, 'seniors': 5068, 'newton': 5069, 'splits': 5070, 'quiet': 5071, 'serena': 5072, 'migrants': 5073, 'defeating': 5074, 'calm': 5075, 'ahmed': 5076, 'proceedings': 5077, 'mainly': 5078, 'ads': 5079, 'triplea': 5080, 'insurer': 5081, 'hardware': 5082, 'admitting': 5083, 'fugitive': 5084, 'trooper': 5085, 'hugh': 5086, 'reed': 5087, 'bankers': 5088, 'glasgow': 5089, 'H1N1': 5090, 'readers': 5091, 'exporters': 5092, 'charging': 5093, 'lifestyle': 5094, 'chad': 5095, 'outlets': 5096, 'philip': 5097, 'singing': 5098, '2020': 5099, 'relay': 5100, 'glenn': 5101, 'indecent': 5102, 'scientist': 5103, 'UEFA': 5104, 'baker': 5105, 'minneapolis': 5106, 'accepts': 5107, 'michele': 5108, 'farms': 5109, 'expensive': 5110, 'crossed': 5111, 'quebec': 5112, 'therapy': 5113, 'lesbian': 5114, 'rb': 5115, 'spell': 5116, '92': 5117, 'calgary': 5118, 'packers': 5119, 'implementation': 5120, 'understanding': 5121, 'gaining': 5122, 'ally': 5123, 'le': 5124, 'McLaren': 5125, 'orissa': 5126, 'booked': 5127, 'kicking': 5128, 'teammate': 5129, 'catcher': 5130, 'salem': 5131, 'tibet': 5132, 'FORMER': 5133, 'controls': 5134, 'aiming': 5135, 'chargers': 5136, 'deported': 5137, 'blacks': 5138, 'numerous': 5139, 'slam': 5140, 'rider': 5141, 'winnipeg': 5142, 'brush': 5143, 'enhanced': 5144, 'bros': 5145, 'voter': 5146, 'trends': 5147, 'bryan': 5148, 'fundraiser': 5149, 'layoffs': 5150, 'lexington': 5151, 'joel': 5152, 'supermodel': 5153, 'chair': 5154, 'document': 5155, 'encouraged': 5156, 'breach': 5157, 'buffett': 5158, 'declaration': 5159, 'raj': 5160, '24yearold': 5161, 'OPEC': 5162, 'bath': 5163, 'preferred': 5164, 'ones': 5165, 'favour': 5166, 'spiritual': 5167, 'discussions': 5168, 'shootings': 5169, 'excessive': 5170, 'renew': 5171, 'tips': 5172, 'mile': 5173, 'bullock': 5174, 'certification': 5175, 'volatile': 5176, 'hazare': 5177, 'turkmenistan': 5178, 'appoint': 5179, 'transferred': 5180, 'civic': 5181, 'reward': 5182, 'statements': 5183, 'indicated': 5184, 'sharma': 5185, 'pensions': 5186, 'siemens': 5187, 'thackeray': 5188, 'downgrades': 5189, 'challenged': 5190, '110': 5191, 'vulnerable': 5192, 'apps': 5193, 'backing': 5194, 'disorder': 5195, 'SAP': 5196, 'valentine': 5197, 'blair': 5198, 'TMZ': 5199, 'silicon': 5200, 'apr': 5201, 'peninsula': 5202, 'oprah': 5203, 'mad': 5204, 'molestation': 5205, 'swansea': 5206, 'traveling': 5207, 'trump': 5208, 'emmy': 5209, 'narrowly': 5210, 'navigation': 5211, 'grounds': 5212, 'survival': 5213, 'nathan': 5214, 'refugee': 5215, 'accounting': 5216, 'curb': 5217, 'birds': 5218, 'cedar': 5219, 'speedway': 5220, 'gray': 5221, 'throat': 5222, 'selects': 5223, 'execution': 5224, '25th': 5225, \"o'brien\": 5226, 'touched': 5227, 'mortgages': 5228, 'guidelines': 5229, 'miner': 5230, '30000': 5231, 'bound': 5232, 'strain': 5233, 'taipei': 5234, 'protesting': 5235, 'doping': 5236, 'policeman': 5237, 'manuel': 5238, 'engineer': 5239, 'tens': 5240, 'participation': 5241, 'kabul': 5242, '14th': 5243, 'pupils': 5244, 'lambert': 5245, 'thomson': 5246, 'wounds': 5247, 'employer': 5248, 'santorum': 5249, 'extensive': 5250, 'gate': 5251, 'boxer': 5252, 'hearts': 5253, 'merge': 5254, 'insurgents': 5255, 'lahore': 5256, 'christians': 5257, 'k': 5258, 'lisa': 5259, 'medals': 5260, 'overdose': 5261, 'sanchez': 5262, 'autism': 5263, 'edinburgh': 5264, 'austrian': 5265, '25000': 5266, 'pledges': 5267, 'teammates': 5268, 'kutcher': 5269, 'assured': 5270, 'thunder': 5271, 'conrad': 5272, 'prestigious': 5273, 'wigan': 5274, 'mariners': 5275, 'stemming': 5276, 'comic': 5277, 'silvio': 5278, 'urge': 5279, 'LG': 5280, 'mercury': 5281, 'g': 5282, 'underground': 5283, 'withdrew': 5284, 'executed': 5285, 'parked': 5286, 'writers': 5287, 'flow': 5288, 'naomi': 5289, 'fat': 5290, 'confessed': 5291, '05': 5292, 'fix': 5293, 'twilight': 5294, 'misconduct': 5295, 'pursue': 5296, 'socalled': 5297, 'substance': 5298, 'FOCUS': 5299, '22yearold': 5300, 'morris': 5301, 'recovers': 5302, 'cooperate': 5303, 'turmoil': 5304, 'answers': 5305, 'clearing': 5306, 'herald': 5307, 'sioux': 5308, '4000': 5309, 'mega': 5310, 'inaugurated': 5311, 'tragedy': 5312, 'rankings': 5313, 'mohammad': 5314, 'economist': 5315, 'vendor': 5316, 'tribunal': 5317, 'likes': 5318, 'bullet': 5319, 'harbor': 5320, 'citizenship': 5321, 'licensing': 5322, 'cornerback': 5323, 'rockies': 5324, 'affecting': 5325, 'maruti': 5326, 'finances': 5327, 'bust': 5328, 'mamata': 5329, 'oath': 5330, 'tulsa': 5331, 'intersection': 5332, 'superintendent': 5333, 'cuomo': 5334, 'simply': 5335, '23yearold': 5336, 'largely': 5337, 'medicare': 5338, 'ram': 5339, 'rams': 5340, 'nonprofit': 5341, 'finnish': 5342, 'reiterated': 5343, 'indefinitely': 5344, 'rehman': 5345, 'vincent': 5346, '13th': 5347, 'rocky': 5348, '350': 5349, 'rubber': 5350, '17th': 5351, 'install': 5352, 'appearing': 5353, 'muammar': 5354, 'betty': 5355, 'fred': 5356, 'sensitive': 5357, 'experienced': 5358, 'expo': 5359, 'broker': 5360, 'goa': 5361, 'desperate': 5362, 'aguilera': 5363, 'norfolk': 5364, 'depot': 5365, 'mosque': 5366, 'raja': 5367, 'spreading': 5368, 'EUR': 5369, 'drives': 5370, 'l': 5371, 'impressive': 5372, 'pose': 5373, 'sentencing': 5374, 'jewellery': 5375, 'clooney': 5376, 'chemicals': 5377, 'albany': 5378, 'organised': 5379, 'renowned': 5380, 'patil': 5381, 'anchor': 5382, 'triggered': 5383, 'controlled': 5384, 'tours': 5385, 'AIDS': 5386, 'renews': 5387, 'intent': 5388, 'correspondent': 5389, 'wyoming': 5390, '360': 5391, '89': 5392, 'luis': 5393, 'janata': 5394, 'f': 5395, 'wade': 5396, 'exactly': 5397, 'thriller': 5398, 'wishes': 5399, 'relatives': 5400, 'horses': 5401, 'jean': 5402, 'jintao': 5403, 'destroy': 5404, 'contribute': 5405, 'ash': 5406, 'mounting': 5407, 'ethiopia': 5408, 'monsoon': 5409, 'swing': 5410, 'risen': 5411, 'fever': 5412, 'licenses': 5413, 'carpet': 5414, 'bonuses': 5415, 'mohamed': 5416, 'torn': 5417, 'essential': 5418, 'portal': 5419, 'overturned': 5420, 'server': 5421, '3G': 5422, 'longest': 5423, 'fines': 5424, 'sierra': 5425, 'UCLA': 5426, 'updates': 5427, 'carriers': 5428, 'rapidly': 5429, '87': 5430, 'paso': 5431, 'regrets': 5432, 'blockbuster': 5433, 'brook': 5434, 'mogul': 5435, 'reliever': 5436, 'dhoni': 5437, 'absolutely': 5438, 'walsh': 5439, 'cox': 5440, 'infringement': 5441, 'promotions': 5442, 'conn': 5443, 'celebrities': 5444, 'button': 5445, 'allies': 5446, 'McDonald': 5447, 'athlete': 5448, 'struggles': 5449, 'expelled': 5450, 'inspection': 5451, 'invites': 5452, '19yearold': 5453, 'extraordinary': 5454, 'cemetery': 5455, 'arrival': 5456, 'silence': 5457, 'bench': 5458, 'cream': 5459, 'colombo': 5460, 'danish': 5461, 'USbased': 5462, 'exgirlfriend': 5463, 'chronic': 5464, 'surface': 5465, 'ivory': 5466, 'hathaway': 5467, 'developments': 5468, 'represent': 5469, 'statue': 5470, 'boats': 5471, 'whale': 5472, 'maintained': 5473, 'ventures': 5474, 'offenders': 5475, 'insisting': 5476, 'zambia': 5477, 'oman': 5478, 'jane': 5479, 'contractors': 5480, 'focusing': 5481, 'OS': 5482, 'prosecution': 5483, 'iTunes': 5484, 'badly': 5485, '25yearold': 5486, 'riot': 5487, 'mini': 5488, 'heroes': 5489, 'fought': 5490, 'doubt': 5491, 'willing': 5492, 'vicepresident': 5493, 'starbucks': 5494, 'investigations': 5495, 'tension': 5496, '4th': 5497, 'innocent': 5498, 'timothy': 5499, 'sustainability': 5500, 'wrestling': 5501, 'cats': 5502, 'disappointed': 5503, 'cannabis': 5504, 'gallery': 5505, 'ailing': 5506, 'recruitment': 5507, 'owns': 5508, 'canal': 5509, 'bradford': 5510, 'jamaica': 5511, 'gathering': 5512, 'extradition': 5513, 'michaels': 5514, 'laura': 5515, 'airtel': 5516, 'difference': 5517, 'genetic': 5518, 'frontier': 5519, 'shield': 5520, 'archbishop': 5521, 'choose': 5522, 'gardens': 5523, 'maple': 5524, 'doubleheader': 5525, 'BHP': 5526, 'favor': 5527, 'neighbours': 5528, 'discover': 5529, 'apologises': 5530, 'secures': 5531, 'tucson': 5532, 'railways': 5533, 'cricketer': 5534, 'circle': 5535, 'connect': 5536, 'billboard': 5537, 'PPP': 5538, 'strengthening': 5539, 'influential': 5540, '1200': 5541, 'meant': 5542, 'dirty': 5543, 'explore': 5544, 'depp': 5545, 'yellow': 5546, 'availability': 5547, 'pune': 5548, 'tmobile': 5549, 'derek': 5550, 'newborn': 5551, 'grace': 5552, 'punched': 5553, 'sheffield': 5554, 'SC': 5555, 'cement': 5556, 'threaten': 5557, 'behalf': 5558, 'cycle': 5559, 'imran': 5560, 'historical': 5561, 'malta': 5562, 'effectively': 5563, 'boulevard': 5564, 'backup': 5565, 'mainland': 5566, 'leicester': 5567, 'yorkshire': 5568, 'honors': 5569, 'buzz': 5570, 'mourinho': 5571, 'planet': 5572, 'weighed': 5573, 'sharapova': 5574, 'satyam': 5575, 'narendra': 5576, 'grows': 5577, 'diaz': 5578, 'develops': 5579, 'brent': 5580, 'SEC': 5581, 'prompted': 5582, 'vanessa': 5583, '18yearold': 5584, 'elite': 5585, 'beta': 5586, 'collective': 5587, 'duo': 5588, 'praise': 5589, 'portion': 5590, 'covered': 5591, 'suggest': 5592, 'chopra': 5593, 'suburb': 5594, 'bang': 5595, 'newport': 5596, 'subscribers': 5597, 'prepaid': 5598, 'qualified': 5599, 'canyon': 5600, 'possessing': 5601, 'bolt': 5602, 'logistics': 5603, 'modest': 5604, 'ranch': 5605, 'arsene': 5606, 'routine': 5607, 'torture': 5608, 'nicki': 5609, 'minaj': 5610, 'nile': 5611, 'stoke': 5612, 'explosive': 5613, 'bennett': 5614, 'donate': 5615, 'adrian': 5616, 'container': 5617, 'roma': 5618, 'ecommerce': 5619, 'mansion': 5620, 'benjamin': 5621, 'tunisia': 5622, '15000': 5623, 'eliminated': 5624, 'bancorp': 5625, 'kid': 5626, 'travis': 5627, 'boosting': 5628, 'swan': 5629, 'tesco': 5630, 'nude': 5631, 'racial': 5632, 'wickets': 5633, 'fights': 5634, 'bruins': 5635, 'dawn': 5636, 'molesting': 5637, 'europa': 5638, 'handling': 5639, 'certificate': 5640, 'knows': 5641, 'witherspoon': 5642, 'resulted': 5643, 'IPL': 5644, 'arthur': 5645, 'jharkhand': 5646, 'myers': 5647, 'crush': 5648, 'romantic': 5649, 'handle': 5650, 'vietnamese': 5651, 'housewives': 5652, 'midday': 5653, 'turbine': 5654, 'reconciliation': 5655, 'waived': 5656, 'cues': 5657, 'windsor': 5658, 'carroll': 5659, 'courses': 5660, 'tractor': 5661, 'christchurch': 5662, 'sweet': 5663, 'couples': 5664, 'rovers': 5665, 'organisers': 5666, 'concept': 5667, 'privately': 5668, 'stories': 5669, 'romance': 5670, 'fouryear': 5671, 'harvest': 5672, 'laundering': 5673, 'du': 5674, 'heavily': 5675, 'manila': 5676, 'hamburg': 5677, 'referee': 5678, 'amtrak': 5679, 'rajya': 5680, 'contribution': 5681, 'glen': 5682, 'defamation': 5683, 'camps': 5684, 'blagojevich': 5685, 'analytics': 5686, 'platinum': 5687, '58': 5688, 'maiden': 5689, 'optimistic': 5690, 'des': 5691, 'boom': 5692, 'issuing': 5693, 'thinking': 5694, 'omar': 5695, 'attractive': 5696, 'pratt': 5697, 'strategies': 5698, 'tinto': 5699, 'tire': 5700, 'picking': 5701, 'quest': 5702, 'retain': 5703, 'vince': 5704, 'minogue': 5705, 'mae': 5706, 'fierce': 5707, 'elect': 5708, 'compromise': 5709, 'wheel': 5710, 'McCarthy': 5711, 'hang': 5712, 'somerset': 5713, 'concerts': 5714, 'councillors': 5715, 'LOS': 5716, 'campaigns': 5717, 'sena': 5718, 'suisse': 5719, 'bharti': 5720, 'equal': 5721, 'domain': 5722, 'proved': 5723, 'unconscious': 5724, 'fulham': 5725, 'purchased': 5726, 'administrator': 5727, 'angela': 5728, 'manning': 5729, 'rainfall': 5730, 'creates': 5731, 'jumping': 5732, 'transparency': 5733, 'lowered': 5734, 'courthouse': 5735, 'walter': 5736, 'fleeing': 5737, 'outsourcing': 5738, 'grass': 5739, 'nurses': 5740, 'antigovernment': 5741, 'lock': 5742, 'WOMAN': 5743, 'regain': 5744, 'premiership': 5745, 'seconddegree': 5746, 'hindu': 5747, 'vermont': 5748, 'acquisitions': 5749, 'hamstring': 5750, 'violated': 5751, 'kirk': 5752, '18th': 5753, 'meters': 5754, 'intended': 5755, 'pipe': 5756, 'projected': 5757, 'complications': 5758, 'holders': 5759, 'excited': 5760, 'toss': 5761, 'counter': 5762, 'plunge': 5763, 'economists': 5764, 'bolster': 5765, 'magistrate': 5766, 'geithner': 5767, 'remake': 5768, 'cheap': 5769, 'encourage': 5770, 'vehicular': 5771, 'woes': 5772, 'a': 5773, 'revive': 5774, 'plenty': 5775, 'kingston': 5776, 'tsvangirai': 5777, 'headon': 5778, 'survives': 5779, 'occasion': 5780, 'plaza': 5781, 'grown': 5782, 'peterson': 5783, 'margin': 5784, 'retreat': 5785, 'sharon': 5786, 'profile': 5787, 'mum': 5788, 'surprised': 5789, 'autopsy': 5790, 'acquiring': 5791, 'vacation': 5792, 'natalie': 5793, 'foul': 5794, 'foreigners': 5795, 'serie': 5796, 'strausskahn': 5797, 'listing': 5798, 'capello': 5799, 'reception': 5800, 'bowler': 5801, 'slated': 5802, 'finishing': 5803, 'jayz': 5804, 'tear': 5805, 'sleeping': 5806, 'assad': 5807, 'gilbert': 5808, 'multimillion': 5809, 'halted': 5810, 'lessons': 5811, 'improvements': 5812, 'genocide': 5813, '6000': 5814, 'longoria': 5815, 'sindh': 5816, 'wallace': 5817, 'wonder': 5818, 'acclaimed': 5819, 'firearms': 5820, 'th': 5821, 'thin': 5822, 'veto': 5823, 'welsh': 5824, 'miliband': 5825, 'mistakes': 5826, 'rounds': 5827, 'checkpoint': 5828, 'containing': 5829, 'wifi': 5830, '2016': 5831, 'mountains': 5832, 'hospitalised': 5833, '300000': 5834, 'finishes': 5835, 'declaring': 5836, 'mariah': 5837, 'boris': 5838, 'remanded': 5839, '3rd': 5840, 'pack': 5841, 'fruit': 5842, 'di': 5843, 'ave': 5844, 'ET': 5845, 'travelling': 5846, 'organizers': 5847, 'IPO': 5848, 'truth': 5849, 'mobility': 5850, 'intention': 5851, 'prayer': 5852, 'taxpayers': 5853, 'turner': 5854, 'charleston': 5855, 'filled': 5856, 'henderson': 5857, 'plate': 5858, 'arraigned': 5859, 'belt': 5860, 'noel': 5861, 'excellent': 5862, 'require': 5863, 'stick': 5864, 'speeding': 5865, 'saves': 5866, 'catherine': 5867, 'golfer': 5868, 'sweeping': 5869, 'briefing': 5870, 'convertible': 5871, 'tougher': 5872, 'cage': 5873, 'doherty': 5874, 'margaret': 5875, 'percentage': 5876, 'paterson': 5877, 'inappropriate': 5878, 'soap': 5879, 'favre': 5880, 'skype': 5881, 'explain': 5882, 'criminals': 5883, 'kenyan': 5884, 'hartford': 5885, 'harvard': 5886, 'sponsorship': 5887, 'hacked': 5888, 'finale': 5889, 'settles': 5890, 'petersburg': 5891, 'slain': 5892, 'minn': 5893, 'sanjay': 5894, 'protected': 5895, 'huntington': 5896, 'knicks': 5897, 'eds': 5898, 'strict': 5899, 'damaging': 5900, 'istanbul': 5901, 'stevens': 5902, '28yearold': 5903, 'AOL': 5904, 'beatles': 5905, 'bombings': 5906, 'safely': 5907, 'carnival': 5908, 'JPMorgan': 5909, 'ports': 5910, 'hawks': 5911, 'homeland': 5912, 'engines': 5913, 'toxic': 5914, 'addressed': 5915, 'origin': 5916, 'specific': 5917, 'astros': 5918, 'sorry': 5919, '14yearold': 5920, 'stateowned': 5921, 'studying': 5922, 'proceeds': 5923, 'valuable': 5924, '15th': 5925, 'hanged': 5926, 'overweight': 5927, 'proper': 5928, 'stomach': 5929, 'banerjee': 5930, '7th': 5931, 'governing': 5932, 'guinea': 5933, 'participants': 5934, 'australians': 5935, 'associate': 5936, 'panasonic': 5937, '4G': 5938, 'donation': 5939, 'uganda': 5940, 'stretch': 5941, 'aerospace': 5942, 'tripoli': 5943, 'logo': 5944, 'journey': 5945, 'endorsement': 5946, 'presidents': 5947, 'bold': 5948, 'marines': 5949, 'farewell': 5950, 'coyotes': 5951, 'hornets': 5952, 'essex': 5953, 'palmer': 5954, 'load': 5955, 'zsa': 5956, 'reduces': 5957, 'macedonia': 5958, 'DVD': 5959, 'soaring': 5960, 'efficient': 5961, 'crane': 5962, '2002': 5963, 'enjoying': 5964, 'tip': 5965, 'wii': 5966, 'concrete': 5967, 'sudden': 5968, 'procedure': 5969, 'intensive': 5970, 'reese': 5971, 'encouraging': 5972, 'publication': 5973, 'unified': 5974, 'cruises': 5975, 'spin': 5976, 'stern': 5977, 'stuart': 5978, 'components': 5979, 'liquidity': 5980, 'diving': 5981, 'TWO': 5982, 'else': 5983, 'exciting': 5984, 'impose': 5985, 'sofia': 5986, 'sidelined': 5987, 'repairs': 5988, 'partial': 5989, 'colts': 5990, 'warrants': 5991, 'circumstances': 5992, 'religion': 5993, 'debts': 5994, 'carmaker': 5995, 'rays': 5996, 'orchestra': 5997, 'hijacked': 5998, 'ANGELES': 5999, '59': 6000, 'lieutenant': 6001, 'tumbled': 6002, 'rebuild': 6003, 'seekers': 6004, 'gosselin': 6005, 'tyson': 6006, 'passport': 6007, 'rap': 6008, 'tattoo': 6009, 'addresses': 6010, 'uk': 6011, 'credits': 6012, 'ladies': 6013, 'resigning': 6014, 'providence': 6015, 'presenter': 6016, 'bangkok': 6017, 'winfrey': 6018, 'participating': 6019, 'doug': 6020, 'bundesliga': 6021, 'faculty': 6022, 'helen': 6023, 'rebounded': 6024, 'reference': 6025, 'barton': 6026, 'deciding': 6027, 'carson': 6028, 'oscarwinning': 6029, 'portuguese': 6030, 'talked': 6031, 'pretax': 6032, 'griffin': 6033, 'resulting': 6034, 'shocking': 6035, 'saskatchewan': 6036, 'repeatedly': 6037, 'soil': 6038, 'mo': 6039, 'brawl': 6040, 'hammer': 6041, 'deployed': 6042, 'addressing': 6043, 'lucas': 6044, 'abused': 6045, 'assessment': 6046, 'attorneys': 6047, 'holder': 6048, 'qualifier': 6049, 'asthma': 6050, 'advisers': 6051, 'strengthens': 6052, 'wilmington': 6053, 'policemen': 6054, 'devastating': 6055, 'drawn': 6056, 'richie': 6057, 'marries': 6058, 'bitter': 6059, 'plotting': 6060, 'thank': 6061, 'flags': 6062, 'aung': 6063, 'freshman': 6064, 'universe': 6065, 'plymouth': 6066, 'cain': 6067, 'HD': 6068, 'combine': 6069, 'daughters': 6070, 'advocate': 6071, 'HBO': 6072, 'shoe': 6073, 'satellites': 6074, 'orbit': 6075, 'posing': 6076, 'fantasy': 6077, 'bout': 6078, 'boards': 6079, 'jakarta': 6080, 'runner': 6081, 'imported': 6082, 'alqaida': 6083, 'subsidies': 6084, 'paise': 6085, 'walks': 6086, 'solve': 6087, 'olmert': 6088, 'sit': 6089, 'shuts': 6090, 'ideas': 6091, 'activated': 6092, 'performances': 6093, 'marlins': 6094, 'brendan': 6095, 'wrist': 6096, 'colleagues': 6097, 'richardson': 6098, 'testify': 6099, 'oxford': 6100, 'mavericks': 6101, 'inventories': 6102, 'printing': 6103, 'johansson': 6104, 'cristiano': 6105, 'alberto': 6106, 'bachmann': 6107, 'associates': 6108, 'leonardo': 6109, 'amazing': 6110, 'cooperative': 6111, 'ryanair': 6112, 'burst': 6113, 'volcano': 6114, 'provinces': 6115, 'retains': 6116, 'weakens': 6117, 'LONDON': 6118, 'juvenile': 6119, 'dayton': 6120, 'outage': 6121, 'bridges': 6122, 'avalanche': 6123, 'pond': 6124, 'kobe': 6125, 'gifts': 6126, 'twotime': 6127, 'ranking': 6128, 'matters': 6129, 'hungarian': 6130, 'fabio': 6131, 'isle': 6132, 'calendar': 6133, 'sexy': 6134, 'deployment': 6135, 'buyout': 6136, 'spoken': 6137, 'humphries': 6138, '30yearold': 6139, 'mysterious': 6140, 'bribery': 6141, 'brutal': 6142, 'EA': 6143, 'suffolk': 6144, 'geneva': 6145, 'dragged': 6146, 'NYC': 6147, 'hurricanes': 6148, 'ages': 6149, 'enjoyed': 6150, 'sudanese': 6151, 'rukh': 6152, 'swings': 6153, 'noble': 6154, 'incumbent': 6155, 'jaguars': 6156, 'revealing': 6157, 'spray': 6158, 'lighting': 6159, 'noted': 6160, 'riverside': 6161, 'solidarity': 6162, 'hiding': 6163, 'krishna': 6164, 'megan': 6165, 'suppliers': 6166, 'niagara': 6167, 'addiction': 6168, 'tevez': 6169, 'sergio': 6170, 'guitar': 6171, 'fisherman': 6172, 'propose': 6173, 'graduation': 6174, 'adele': 6175, 'helicopters': 6176, 'marco': 6177, 'infielder': 6178, 'newark': 6179, 'govt': 6180, 'edges': 6181, 'pointed': 6182, 'priced': 6183, 'dominique': 6184, 'precious': 6185, 'anil': 6186, 'implemented': 6187, 'garcia': 6188, 'neighbors': 6189, 'method': 6190, 'renault': 6191, 'councillor': 6192, '16yearold': 6193, 'startup': 6194, 'earthquakes': 6195, 'dominican': 6196, 'constable': 6197, 'connected': 6198, 'mate': 6199, 'seem': 6200, 'iceland': 6201, '000': 6202, 'valencia': 6203, 'appealed': 6204, 'worlds': 6205, 'miranda': 6206, 'hart': 6207, 'garbage': 6208, 'na': 6209, 'benitez': 6210, 'bailey': 6211, 'compact': 6212, 'swung': 6213, 'metres': 6214, 'moments': 6215, 'schemes': 6216, 'lie': 6217, 'distribute': 6218, 'dragon': 6219, 'resorts': 6220, 'duncan': 6221, 'astronaut': 6222, 'adoption': 6223, 'chilean': 6224, 'gender': 6225, 'radical': 6226, 'aussie': 6227, 'disputes': 6228, 'transmission': 6229, 'aamir': 6230, 'brokerage': 6231, 'muscle': 6232, 'marketplace': 6233, 'survivors': 6234, 'pressures': 6235, 'decides': 6236, 'volkswagen': 6237, 'gym': 6238, 'challenger': 6239, 'villages': 6240, 'durham': 6241, 'segment': 6242, 'ms': 6243, 'alleging': 6244, 'metropolitan': 6245, 'castle': 6246, 'hinted': 6247, 'fate': 6248, 'perhaps': 6249, 'sparks': 6250, 'grandmother': 6251, 'reckless': 6252, 'batting': 6253, 'willie': 6254, 'vijay': 6255, 'invested': 6256, 'typhoon': 6257, 'shutting': 6258, 'questioning': 6259, 'infosys': 6260, 'gazprom': 6261, 'yousuf': 6262, 'subsidiaries': 6263, 'dhaka': 6264, 'shipments': 6265, 'daytona': 6266, 'toilet': 6267, 'katrina': 6268, 'carrie': 6269, 'djokovic': 6270, '94': 6271, 'intense': 6272, 'burglar': 6273, 'format': 6274, 'singles': 6275, 'exhusband': 6276, 'brooks': 6277, '2500': 6278, 'withdrawal': 6279, 'dengue': 6280, 'voluntarily': 6281, 'beaches': 6282, 'UPA': 6283, 'aden': 6284, 'struggled': 6285, 'bounced': 6286, 'utilities': 6287, 'destinations': 6288, 'diana': 6289, 'contributions': 6290, 'ronnie': 6291, 'clears': 6292, 'lauren': 6293, 'riders': 6294, 'assassination': 6295, 'consensus': 6296, 'bend': 6297, 'steep': 6298, 'bruno': 6299, 'spree': 6300, 'bhd': 6301, 'posed': 6302, 'excellence': 6303, 'lyon': 6304, 'smashed': 6305, 'disorderly': 6306, 'halifax': 6307, 'gala': 6308, 'disrupted': 6309, '15yearold': 6310, 'stressed': 6311, 'detected': 6312, 'economics': 6313, 'JP': 6314, 'NZ': 6315, 'powell': 6316, 'awaited': 6317, 'reynolds': 6318, 'crops': 6319, 'tumor': 6320, 'belfast': 6321, 'mothers': 6322, 'governors': 6323, 'presentation': 6324, 'facilitate': 6325, 'maintains': 6326, 'scout': 6327, 'dylan': 6328, 'particular': 6329, 'interbank': 6330, 'publicist': 6331, 'imprisonment': 6332, 'CIA': 6333, '225': 6334, 'suddenly': 6335, '160': 6336, 'palestine': 6337, 'map': 6338, 'billiton': 6339, 'iOS': 6340, 'treasurer': 6341, 'spends': 6342, 'gabrielle': 6343, 'organic': 6344, 'robbers': 6345, 'fresno': 6346, 'sidelines': 6347, 'mesa': 6348, 'subway': 6349, 'texans': 6350, 'crawford': 6351, 'hosni': 6352, 'detectives': 6353, 'nikkei': 6354, 'removing': 6355, '201112': 6356, 'hezbollah': 6357, 'peoples': 6358, 'forecasters': 6359, 'neglect': 6360, 'equality': 6361, 'explains': 6362, 'bottle': 6363, 'approached': 6364, 'firstquarter': 6365, 'partially': 6366, 'secondlargest': 6367, 'LSU': 6368, 'invitational': 6369, 'neighbor': 6370, 'consultancy': 6371, 'requested': 6372, 'fiery': 6373, 'recognize': 6374, 'shortfall': 6375, '19th': 6376, 'breakthrough': 6377, 'covers': 6378, 'boise': 6379, '30th': 6380, 'batch': 6381, 'nets': 6382, 'patents': 6383, 'FDA': 6384, 'claire': 6385, 'ceiling': 6386, 'quitting': 6387, 'counterfeit': 6388, 'unusual': 6389, 'function': 6390, 'CA': 6391, 'heather': 6392, 'battled': 6393, 'scarlett': 6394, 'jun': 6395, 'meals': 6396, '93': 6397, 'ex': 6398, 'steam': 6399, 'cigarettes': 6400, 'gonzalez': 6401, 'dreams': 6402, 'halloween': 6403, 'joey': 6404, 'videos': 6405, 'alicia': 6406, 'massacre': 6407, 'accusations': 6408, 'angola': 6409, 'hails': 6410, 'slowly': 6411, 'adjourned': 6412, 'sponsored': 6413, 'trained': 6414, 'raids': 6415, 'globally': 6416, 'pointing': 6417, 'dynamics': 6418, 'schumacher': 6419, 'harvey': 6420, 'radiation': 6421, 'notre': 6422, 'hikes': 6423, 'richards': 6424, 'cellular': 6425, 'blackhawks': 6426, 'reunited': 6427, 'comfortable': 6428, 'signature': 6429, 'biopic': 6430, 'administrators': 6431, 'contained': 6432, 'repeal': 6433, 'nawaz': 6434, 'thunderstorm': 6435, 'desire': 6436, 'luck': 6437, 'karl': 6438, 'hispanic': 6439, 'guests': 6440, 'ryder': 6441, 'fiat': 6442, 'plains': 6443, 'exclusively': 6444, 'USC': 6445, 'institutional': 6446, 'eligible': 6447, 'GE': 6448, 'samuel': 6449, 'rev': 6450, 'cardinal': 6451, '21st': 6452, 'rhode': 6453, 'opposed': 6454, 'sheet': 6455, 'advocates': 6456, 'mistake': 6457, 'hat': 6458, 'consequences': 6459, 'workplace': 6460, 'ellen': 6461, 'novak': 6462, 'barn': 6463, 'drake': 6464, 'blasted': 6465, 'hilary': 6466, 'ledger': 6467, 'offerings': 6468, 'alarm': 6469, 'humans': 6470, 'reelected': 6471, 'packages': 6472, 'cannon': 6473, 'empty': 6474, 'erupted': 6475, 'pitches': 6476, 'poses': 6477, 'congratulates': 6478, 'dismisses': 6479, 'personality': 6480, 'trigger': 6481, 'laser': 6482, 'coral': 6483, 'rig': 6484, 'nervous': 6485, 'airlifted': 6486, 'scholarship': 6487, 'rd': 6488, 'offense': 6489, 'publish': 6490, 'chrome': 6491, 'tel': 6492, 'battles': 6493, 'oliver': 6494, 'bright': 6495, 'opposite': 6496, 'symptoms': 6497, 'poisoning': 6498, 'checked': 6499, 'sluggish': 6500, 'quarterfinal': 6501, 'laptop': 6502, 'inspector': 6503, 'tragic': 6504, 'salaries': 6505, 'baptist': 6506, 'laying': 6507, 'clemens': 6508, 'downs': 6509, 'ferdinand': 6510, 'cigarette': 6511, 'TD': 6512, 'barrels': 6513, 'horizon': 6514, 'nobody': 6515, 'engage': 6516, 'brokers': 6517, 'prefer': 6518, 'moral': 6519, 'kyrgyz': 6520, 'apartments': 6521, 'dip': 6522, 'carlisle': 6523, 'canucks': 6524, 'collect': 6525, 'thief': 6526, 'underage': 6527, 'spice': 6528, 'relative': 6529, 'adopts': 6530, 'seasonal': 6531, 'postpones': 6532, 'earns': 6533, 'congratulated': 6534, 'revolutionary': 6535, 'creditors': 6536, 'allocation': 6537, 'troy': 6538, 'lanes': 6539, 'sanford': 6540, 'herman': 6541, '40th': 6542, 'ellis': 6543, 'buyer': 6544, 'halle': 6545, 'tipped': 6546, 'himachal': 6547, 'parkway': 6548, 'wider': 6549, 'inauguration': 6550, 'maintaining': 6551, 'trevor': 6552, 'mandatory': 6553, 'webber': 6554, 'sank': 6555, 'mercy': 6556, 'legislators': 6557, 'georgetown': 6558, 'error': 6559, '49ers': 6560, 'anthem': 6561, 'pensioner': 6562, 'ditch': 6563, 'progressive': 6564, 'knox': 6565, 'endangered': 6566, 'ambitious': 6567, 'maoist': 6568, 'SAN': 6569, 'panthers': 6570, 'stamford': 6571, 'lays': 6572, 'tiny': 6573, 'hopkins': 6574, 'secrets': 6575, 'yadav': 6576, 'notices': 6577, 'safer': 6578, 'repay': 6579, 'willis': 6580, 'instruments': 6581, 'lashed': 6582, 'kidnap': 6583, 'concerning': 6584, 'corrupt': 6585, 'blew': 6586, 'pearl': 6587, 'chat': 6588, 'raul': 6589, 'hampton': 6590, 'tweet': 6591, 'croatia': 6592, 'etihad': 6593, 'disabilities': 6594, 'dying': 6595, 'slovenia': 6596, 'shortstop': 6597, 'pursuit': 6598, 'riots': 6599, 'devils': 6600, 'troopers': 6601, 'nottingham': 6602, 'consortium': 6603, 'eases': 6604, 'tanzania': 6605, 'pepper': 6606, 'boosts': 6607, 'mandate': 6608, 'protecting': 6609, '250000': 6610, 'ahmad': 6611, 'venue': 6612, 'apparel': 6613, 'balotelli': 6614, 'patel': 6615, 'grenade': 6616, 'symbol': 6617, 'unexpected': 6618, 'climbing': 6619, 'clippers': 6620, 'shutdown': 6621, 'programmes': 6622, 'exchanges': 6623, 'restricted': 6624, 'submit': 6625, 'autumn': 6626, 'priyanka': 6627, 'intellectual': 6628, 'hassan': 6629, 'widened': 6630, '97': 6631, 'wolf': 6632, 'flew': 6633, 'collected': 6634, 'consultation': 6635, 'teeth': 6636, 'municipality': 6637, 'flee': 6638, 'degrees': 6639, 'bengals': 6640, 'broader': 6641, 'unite': 6642, 'greene': 6643, 'polling': 6644, 'quake': 6645, 'distributed': 6646, 'railroad': 6647, 'uprising': 6648, 'santos': 6649, 'AAA': 6650, 'specifically': 6651, 'friendship': 6652, '29yearold': 6653, 'sore': 6654, 'cops': 6655, 'setback': 6656, 'citi': 6657, 'jackie': 6658, 'roots': 6659, 'bloody': 6660, 'recommendations': 6661, 'accidental': 6662, 'heating': 6663, 'restructure': 6664, 'merchant': 6665, 'caps': 6666, 'nose': 6667, 'reaction': 6668, 'elements': 6669, 'banning': 6670, 'snapped': 6671, 'busch': 6672, 'anonymous': 6673, 'patch': 6674, 'rwanda': 6675, 'sweeps': 6676, 'meaning': 6677, 'micro': 6678, 'stood': 6679, 'firstdegree': 6680, 'unemployed': 6681, 'nielsen': 6682, 'mancini': 6683, 'integrity': 6684, 'GDP': 6685, '23rd': 6686, 'contender': 6687, 'tap': 6688, 'fractured': 6689, 'strained': 6690, 'hodgson': 6691, 'puerto': 6692, 'falcons': 6693, 'desktop': 6694, 'victor': 6695, 'shaun': 6696, 'rough': 6697, 'generate': 6698, 'revenge': 6699, 'guardian': 6700, 'ministries': 6701, 'bankrupt': 6702, 'joy': 6703, 'diamondbacks': 6704, 'medium': 6705, 'mercedes': 6706, 'bullish': 6707, 'punch': 6708, 'battered': 6709, 'uniform': 6710, 'appropriate': 6711, 'grey': 6712, 'dpa': 6713, 'snap': 6714, '02': 6715, 'hussain': 6716, 'attendance': 6717, 'respectively': 6718, 'burlington': 6719, 'bombers': 6720, 'hacking': 6721, 'criticised': 6722, 'removal': 6723, 'subscription': 6724, 'showcase': 6725, 'ballots': 6726, 'vick': 6727, 'messaging': 6728, 'relegation': 6729, 'permanently': 6730, 'flyers': 6731, 'coup': 6732, 'renovation': 6733, 'loaded': 6734, 'singersongwriter': 6735, 'kiss': 6736, 'wounding': 6737, 'pierce': 6738, 'heels': 6739, 'exercises': 6740, 'counterparts': 6741, 'dogg': 6742, 'hiphop': 6743, 'consultant': 6744, 'wilkinson': 6745, 'ghost': 6746, 'revival': 6747, '12000': 6748, 'explosives': 6749, 'pelosi': 6750, 'depth': 6751, 'ousted': 6752, 'carlo': 6753, 'pages': 6754, 'nova': 6755, 'jenkins': 6756, 'completing': 6757, 'jorge': 6758, 'lone': 6759, 'bharatiya': 6760, 'accra': 6761, 'certainly': 6762, 'eyed': 6763, 'acute': 6764, 'mouth': 6765, 'broking': 6766, 'withdrawing': 6767, 'accelerated': 6768, 'nato': 6769, 'bullpen': 6770, 'behavior': 6771, 'thus': 6772, 'narrow': 6773, 'km': 6774, 'charities': 6775, 'O2': 6776, 'quarters': 6777, 'graduates': 6778, 'jockey': 6779, 'scrapped': 6780, 'forming': 6781, 'arriving': 6782, 'compound': 6783, 'productivity': 6784, 'zac': 6785, 'offseason': 6786, '15day': 6787, 'introducing': 6788, 'chaos': 6789, 'opponent': 6790, 'amazoncom': 6791, 'stance': 6792, 'chips': 6793, 'surrey': 6794, 'consolidation': 6795, 'designs': 6796, 'borough': 6797, 'pfizer': 6798, 'vista': 6799, 'kidman': 6800, 'audi': 6801, 'cocacola': 6802, 'zuckerberg': 6803, 'washed': 6804, 'tenn': 6805, 'sentences': 6806, \"o'neal\": 6807, 'reorganization': 6808, 'shale': 6809, 'pistorius': 6810, 'lobby': 6811, 'yacht': 6812, 'RBI': 6813, 'surcharge': 6814, 'territorial': 6815, 'invests': 6816, 'reject': 6817, 'nuggets': 6818, 'surrender': 6819, 'ejected': 6820, 'explodes': 6821, 'ducks': 6822, 'marginally': 6823, 'derivatives': 6824, 'wellknown': 6825, 'curtis': 6826, 'zimbabwean': 6827, 'hoped': 6828, 'telegraph': 6829, 'delighted': 6830, 'reputation': 6831, 'walt': 6832, 'dictator': 6833, 'tuition': 6834, 'volatility': 6835, 'surrendered': 6836, 'suns': 6837, 'monica': 6838, 'paula': 6839, 'prop': 6840, 'platforms': 6841, 'approaching': 6842, 'stunning': 6843, 'mix': 6844, 'janet': 6845, 'maps': 6846, 'packed': 6847, 'deserve': 6848, 'exam': 6849, 'drummer': 6850, 'popularity': 6851, 'burke': 6852, 'kurt': 6853, 'atletico': 6854, 'legs': 6855, 'sanders': 6856, 'abduction': 6857, 'dubbed': 6858, 'chocolate': 6859, 'florence': 6860, 'pills': 6861, 'robust': 6862, 'households': 6863, 'medicines': 6864, 'bible': 6865, 'sabah': 6866, 'padres': 6867, 'trader': 6868, 'u': 6869, '6th': 6870, 'telekom': 6871, 'legacy': 6872, 'les': 6873, 'preserve': 6874, 'outperform': 6875, 'signals': 6876, 'tanks': 6877, 'cleaning': 6878, 'vernon': 6879, 'bee': 6880, 'tebow': 6881, 'LeBron': 6882, 'travelers': 6883, 'coventry': 6884, 'hundred': 6885, 'example': 6886, 'seal': 6887, 'reunite': 6888, 'leafs': 6889, 'vettel': 6890, 'floating': 6891, 'stanford': 6892, '1100': 6893, 'merrill': 6894, 'expresses': 6895, 'F1': 6896, 'simmons': 6897, 'overtime': 6898, 'premises': 6899, 'maradona': 6900, 'regard': 6901, 'montag': 6902, 'andrews': 6903, 'cheaper': 6904, 'cavaliers': 6905, '400000': 6906, 'competing': 6907, 'preston': 6908, 'findings': 6909, 'consent': 6910, 'pets': 6911, 'burma': 6912, 'panic': 6913, 'accountability': 6914, 'openly': 6915, 'islamist': 6916, 'distributing': 6917, 'yards': 6918, 'crazy': 6919, 'rica': 6920, 'rage': 6921, 'miguel': 6922, 'h': 6923, 'chartered': 6924, 'infections': 6925, 'youngsters': 6926, 'iPod': 6927, 'oppose': 6928, 'volvo': 6929, 'ministerial': 6930, 'MLS': 6931, 'requires': 6932, 'youngest': 6933, 'ehud': 6934, 'entrepreneur': 6935, '17yearold': 6936, 'displaced': 6937, 'lansing': 6938, 'adjusted': 6939, '2001': 6940, 'IP': 6941, 'prayers': 6942, 'waves': 6943, 'alassad': 6944, 'firmly': 6945, 'courtroom': 6946, 'marie': 6947, 'permit': 6948, '175': 6949, 'rodgers': 6950, 'gadhafi': 6951, 'medicaid': 6952, 'purpose': 6953, 'franco': 6954, 'proposing': 6955, 'klitschko': 6956, 'reactor': 6957, 'algeria': 6958, 'satisfaction': 6959, 'ITV': 6960, 'panels': 6961, 'automation': 6962, 'toshiba': 6963, 'aware': 6964, 'locker': 6965, 'ponting': 6966, 'consulate': 6967, 'gossip': 6968, 'groin': 6969, 'ASEAN': 6970, 'motel': 6971, 'researcher': 6972, 'controller': 6973, 'yield': 6974, 'demonstrators': 6975, 'goaltender': 6976, 'highlights': 6977, 'holland': 6978, 'paltrow': 6979, 'rescues': 6980, 'publishes': 6981, 'sullivan': 6982, 'lowers': 6983, 'slows': 6984, 'replaces': 6985, 'initially': 6986, 'demolition': 6987, 'mph': 6988, 'nutrition': 6989, 'highprofile': 6990, 'seri': 6991, 'skating': 6992, 'reflecting': 6993, 'winslet': 6994, 'pierre': 6995, 'predict': 6996, 'shocked': 6997, 'initiated': 6998, '8th': 6999, 'succeed': 7000, 'stayed': 7001, 'lover': 7002, 'nitish': 7003, 'length': 7004, 'collections': 7005, 'bucks': 7006, 'reinstated': 7007, 'shadow': 7008, 'wizards': 7009, 'li': 7010, 'cab': 7011, 'visual': 7012, 'dominated': 7013, 'rover': 7014, 'cooking': 7015, 'fannie': 7016, 'payroll': 7017, 'teach': 7018, 'greenhouse': 7019, 'sequel': 7020, 'sole': 7021, 'headline': 7022, 'laboratory': 7023, 'agreeing': 7024, 'felipe': 7025, '201011': 7026, 'epic': 7027, 'murders': 7028, 'jul': 7029, 'jointly': 7030, 'eBay': 7031, 'councilman': 7032, 'dressed': 7033, 'observers': 7034, 'upside': 7035, 'underwood': 7036, 'hemsworth': 7037, 'conducting': 7038, 'statutory': 7039, 'mayo': 7040, 'bret': 7041, 'penalties': 7042, 'bump': 7043, 'hewitt': 7044, 'reservation': 7045, 'prairie': 7046, 'confrontation': 7047, 'malawi': 7048, 'predicts': 7049, 'blames': 7050, 'confirming': 7051, 'transactions': 7052, 'bonus': 7053, 'bicycle': 7054, 'duff': 7055, 'sometimes': 7056, 'indoor': 7057, 'huntsman': 7058, 'rossi': 7059, 'boil': 7060, 'tradition': 7061, 'rogue': 7062, 'disappeared': 7063, 'caroline': 7064, 'amsterdam': 7065, 'presenting': 7066, 'earning': 7067, 'founding': 7068, 'puppy': 7069, 'lynn': 7070, 'dump': 7071, 'dutt': 7072, 'XI': 7073, 'clay': 7074, 'paulo': 7075, 'madoff': 7076, 'katherine': 7077, 'minors': 7078, 'FTSE': 7079, 'councils': 7080, 'programming': 7081, 'tracy': 7082, 'neighbouring': 7083, 'jared': 7084, 'foreclosures': 7085, 'altercation': 7086, 'da': 7087, 'aviv': 7088, 'guys': 7089, 'pitching': 7090, 'harbour': 7091, 'cheated': 7092, 'eventually': 7093, 'LTE': 7094, 'bernie': 7095, 'relating': 7096, 'physically': 7097, 'approaches': 7098, 'gubernatorial': 7099, 'MySpace': 7100, 'glory': 7101, 'greenback': 7102, 'middleweight': 7103, 'mayweather': 7104, 'evacuate': 7105, 'requests': 7106, 'paterno': 7107, '140': 7108, 'seizure': 7109, 'oasis': 7110, 'scanner': 7111, 'lightweight': 7112, 'scotia': 7113, 'cattle': 7114, 'lancaster': 7115, 'admission': 7116, 'automatic': 7117, 'touring': 7118, 'silent': 7119, 'advani': 7120, 'tighten': 7121, 'yoga': 7122, 'christ': 7123, 'ike': 7124, '40000': 7125, 'martial': 7126, '2003': 7127, 'mick': 7128, 'shahid': 7129, 'workout': 7130, 'imminent': 7131, 'funny': 7132, 'incentives': 7133, 'weakening': 7134, 'columnist': 7135, 'gingrich': 7136, 'formation': 7137, 'runoff': 7138, 'hyundai': 7139, 'raymond': 7140, 'blunt': 7141, 'javier': 7142, 'axe': 7143, 'ramp': 7144, 'sometime': 7145, 'appreciation': 7146, 'uncertain': 7147, 'facial': 7148, 'ICICI': 7149, 'netflix': 7150, 'lehman': 7151, 'notorious': 7152, 'sara': 7153, 'classroom': 7154, 'lies': 7155, 'pig': 7156, 'commissioned': 7157, 'highspeed': 7158, 'outages': 7159, 'publishers': 7160, 'enemy': 7161, 'stalking': 7162, 'lawsuits': 7163, 'gabriel': 7164, 'perez': 7165, 'courtney': 7166, 'gerard': 7167, 'secondquarter': 7168, 'accessories': 7169, 'hunters': 7170, 'ethanol': 7171, 'gwyneth': 7172, 'consolidate': 7173, 'minerals': 7174, 'dover': 7175, 'discusses': 7176, 'businessmen': 7177, 'injures': 7178, '96': 7179, 'dock': 7180, 'happiness': 7181, 'busted': 7182, 'servants': 7183, 'repeated': 7184, 'poet': 7185, 'inn': 7186, 'livestock': 7187, 'symphony': 7188, 'reviewing': 7189, 'bombay': 7190, 'blogger': 7191, 'victorian': 7192, 'famed': 7193, 'flown': 7194, 'amidst': 7195, 'diane': 7196, 'happens': 7197, 'burton': 7198, 'departure': 7199, 'lionel': 7200, 'methods': 7201, 'hostile': 7202, 'baba': 7203, 'villagers': 7204, 'neighbour': 7205, 'sailing': 7206, 'ethiopian': 7207, 'brooke': 7208, '99': 7209, 'brewer': 7210, 'pirate': 7211, 'telstra': 7212, 'sergeant': 7213, 'legends': 7214, 'filipino': 7215, 'myrtle': 7216, '105': 7217, 'commuters': 7218, 'negotiating': 7219, 'johnston': 7220, 'survivor': 7221, 'allrounder': 7222, 'vienna': 7223, 'starter': 7224, 'stating': 7225, 'crossborder': 7226, 'reunion': 7227, '26yearold': 7228, 'matthews': 7229, 'achievement': 7230, 'irene': 7231, 'doubts': 7232, 'slid': 7233, 'sand': 7234, 'playboy': 7235, 'freeway': 7236, 'cathedral': 7237, 'hackers': 7238, 'monument': 7239, 'handset': 7240, 'introduction': 7241, 'tunnel': 7242, 'undercover': 7243, 'walters': 7244, 'counsel': 7245, 'welterweight': 7246, 'DiCaprio': 7247, 'painting': 7248, 'jeffrey': 7249, 'goodwill': 7250, 'malcolm': 7251, 'pawlenty': 7252, 'caution': 7253, 'klum': 7254, 'arrangements': 7255, 'LTTE': 7256, 'cyclone': 7257, 'killings': 7258, 'maybe': 7259, 'bands': 7260, 'lets': 7261, 'ripped': 7262, 'requiring': 7263, 'nice': 7264, 'levi': 7265, 'americas': 7266, 'panama': 7267, 'lots': 7268, 'antony': 7269, 'self': 7270, 'taiwanese': 7271, 'sparking': 7272, 'sitcom': 7273, 'discussing': 7274, 'sting': 7275, 'sunny': 7276, 'freeagent': 7277, 'jermaine': 7278, 'installation': 7279, 'gunshot': 7280, 'marsh': 7281, 'slower': 7282, 'indigenous': 7283, '04': 7284, 'clinched': 7285, 'vandals': 7286, 'midlands': 7287, 'portable': 7288, 'beirut': 7289, 'damon': 7290, 'drain': 7291, 'clayton': 7292, 'ai': 7293, 'fairfax': 7294, 'daylight': 7295, 'chandigarh': 7296, 'booking': 7297, 'reliable': 7298, 'shiv': 7299, 'lehigh': 7300, 'sussex': 7301, 'gig': 7302, 'rutgers': 7303, 'contempt': 7304, 'banker': 7305, '01': 7306, 'brunswick': 7307, 'stamp': 7308, 'bafana': 7309, 'pushes': 7310, 'chuck': 7311, 'anger': 7312, 'shaw': 7313, 'exhibit': 7314, 'burnt': 7315, 'punching': 7316, 'nickel': 7317, 'yang': 7318, 'lawn': 7319, 'animation': 7320, 'fullback': 7321, 'fifa': 7322, 'tonne': 7323, 'bingo': 7324, 'pancreatic': 7325, 'spotlight': 7326, 'plunges': 7327, 'slips': 7328, 'crosby': 7329, 'BAE': 7330, 'hayden': 7331, 'endangerment': 7332, 'amongst': 7333, 'negotiate': 7334, 'arquette': 7335, 'disturbance': 7336, 'disruption': 7337, 'rewards': 7338, 'khloe': 7339, 'bargain': 7340, 'chose': 7341, 'hide': 7342, 'endeavour': 7343, 'anand': 7344, 'humanity': 7345, 'subdued': 7346, 'medication': 7347, 'renewal': 7348, 'trash': 7349, 'WBC': 7350, 'rocked': 7351, 'operated': 7352, 'landlord': 7353, 'rent': 7354, 'indicates': 7355, 'organisations': 7356, 'purdue': 7357, 'egg': 7358, 'repeat': 7359, 'successor': 7360, 'trio': 7361, 'dated': 7362, 'croatian': 7363, 'copyright': 7364, 'aliyev': 7365, 'cal': 7366, 'burger': 7367, 'remarkable': 7368, 'lou': 7369, 'fiance': 7370, 'factories': 7371, 'cleanup': 7372, 'ND': 7373, 'mich': 7374, 'der': 7375, 'nexus': 7376, 'widens': 7377, 'arabian': 7378, 'ton': 7379, 'scouts': 7380, 'operates': 7381, '60th': 7382, 'arlington': 7383, 'maldives': 7384, 'convert': 7385, 'builder': 7386, 'insight': 7387, 'pyongyang': 7388, 'awaiting': 7389, '1600': 7390, 'michel': 7391, 'contemporary': 7392, 'nolan': 7393, 'khalifa': 7394, 'entrance': 7395, 'grabbed': 7396, 'apologise': 7397, 'trustees': 7398, 'barrier': 7399, 'davies': 7400, 'inches': 7401, 'avoided': 7402, 'handing': 7403, 'proof': 7404, 'morrison': 7405, 'afraid': 7406, 'wet': 7407, 'relationships': 7408, 'majors': 7409, 'clegg': 7410, 'informs': 7411, 'piracy': 7412, 'surpassed': 7413, 'casting': 7414, 'waive': 7415, 'demolished': 7416, 'showers': 7417, '16th': 7418, 'thunderstorms': 7419, 'linking': 7420, 'ramirez': 7421, 'coma': 7422, 'toys': 7423, 'usual': 7424, 'riley': 7425, 'surgeon': 7426, 'slovakia': 7427, 'macquarie': 7428, 'hidden': 7429, 'embattled': 7430, 'dramatically': 7431, 'tumble': 7432, 'erie': 7433, 'wrap': 7434, 'chevrolet': 7435, 'inspectors': 7436, 'forbes': 7437, 'nazi': 7438, '180': 7439, 'passage': 7440, 'restart': 7441, 'kay': 7442, 'abraham': 7443, 'travellers': 7444, 'ralph': 7445, 'devastated': 7446, 'muamba': 7447, 'manner': 7448, 'mitsubishi': 7449, 'pa': 7450, 'usain': 7451, 'NYSE': 7452, 'laboratories': 7453, 'sailor': 7454, 'purchasing': 7455, 'folk': 7456, 'GP': 7457, 'secretly': 7458, 'kamal': 7459, 'tomas': 7460, 'reconstruction': 7461, 'followers': 7462, 'evaluation': 7463, 'pubs': 7464, '5th': 7465, 'unfair': 7466, 'rifle': 7467, 'landslide': 7468, 'admit': 7469, 'indexes': 7470, 'AB': 7471, 'champ': 7472, 'estimate': 7473, 'earl': 7474, 'ordinary': 7475, 'indeed': 7476, 'salvation': 7477, 'conglomerate': 7478, 'webb': 7479, 'indie': 7480, 'libel': 7481, 'radcliffe': 7482, 'reversing': 7483, 'pine': 7484, 'hannah': 7485, 'highways': 7486, 'wipro': 7487, 'tweeted': 7488, 'laurent': 7489, 'pietersen': 7490, 'jade': 7491, 'westminster': 7492, 'butt': 7493, 'budgets': 7494, 'roughly': 7495, 'hernandez': 7496, 'queens': 7497, 'soared': 7498, 'lockout': 7499, 'fairfield': 7500, 'eggs': 7501, 'macon': 7502, 'mayoral': 7503, 'acid': 7504, 'criticized': 7505, 'midland': 7506, 'arrivals': 7507, 'sponsors': 7508, 'congo': 7509, 'promotes': 7510, 'meth': 7511, 'uruguay': 7512, 'appetite': 7513, 'constituency': 7514, 'cop': 7515, 'faulty': 7516, 'interesting': 7517, 'oilers': 7518, 'ceremonies': 7519, 'PMLn': 7520, 'upheld': 7521, 'enjoys': 7522, 'rory': 7523, 'toy': 7524, 'rico': 7525, 'ounce': 7526, 'makeover': 7527, 'confirmation': 7528, 'indicating': 7529, 'telecoms': 7530, 'color': 7531, 'rank': 7532, 'explained': 7533, 'impossible': 7534, 'hostages': 7535, 'dementia': 7536, 'attacker': 7537, 'slight': 7538, '32yearold': 7539, 'dodge': 7540, 'reinstate': 7541, 'alonso': 7542, 'boots': 7543, 'generic': 7544, 'divisions': 7545, 'remainder': 7546, 'amir': 7547, 'dissident': 7548, 'wash': 7549, 'capsized': 7550, 'theory': 7551, 'treating': 7552, 'wed': 7553, 'infected': 7554, 'roethlisberger': 7555, 'mode': 7556, 'speeds': 7557, 'reflect': 7558, 'seng': 7559, 'semi': 7560, 'wembley': 7561, 'cables': 7562, 'upward': 7563, 'mainstream': 7564, 'cure': 7565, 'afford': 7566, '201213': 7567, 'stopping': 7568, 'planting': 7569, 'mali': 7570, 'bases': 7571, 'AFC': 7572, 'islanders': 7573, 'chester': 7574, 'achievements': 7575, 'isaac': 7576, 'liability': 7577, 'rebecca': 7578, 'sewer': 7579, 'debris': 7580, 'spirits': 7581, 'ECB': 7582, 'provision': 7583, 'deny': 7584, 'tycoon': 7585, 'penny': 7586, 'conan': 7587, 'prosperity': 7588, 'thermal': 7589, 'berkeley': 7590, 'successive': 7591, 'derailed': 7592, 'alley': 7593, 'bargaining': 7594, 'prefers': 7595, 'cohen': 7596, 'fourthquarter': 7597, 'skies': 7598, 'von': 7599, 'editorial': 7600, 'adaptation': 7601, 'reservoir': 7602, 'rid': 7603, 'bones': 7604, 'textile': 7605, 'messi': 7606, 'ana': 7607, 'porsche': 7608, 'pot': 7609, 'clinics': 7610, 'frankfurt': 7611, 'recommends': 7612, 'sounds': 7613, 'transformation': 7614, 'lucknow': 7615, 'oval': 7616, 'pieces': 7617, 'toledo': 7618, 'redknapp': 7619, 'fortune': 7620, 'rated': 7621, 'truly': 7622, 'massa': 7623, 'amateur': 7624, 'fraser': 7625, 'BSE': 7626, 'belmont': 7627, 'combination': 7628, 'guantanamo': 7629, 'mirza': 7630, 'anywhere': 7631, 'srinagar': 7632, 'albums': 7633, 'AK': 7634, 'holocaust': 7635, 'mediterranean': 7636, 'profitability': 7637, 'samajwadi': 7638, 'yeddyurappa': 7639, 'showdown': 7640, 'harsh': 7641, 'deepening': 7642, 'describing': 7643, 'sovereignty': 7644, 'vale': 7645, 'draws': 7646, 'resolved': 7647, 'acknowledged': 7648, 'hogan': 7649, 'oral': 7650, 'vegetables': 7651, 'bhutto': 7652, 'inventory': 7653, 'attendant': 7654, 'bread': 7655, '730': 7656, 'JD': 7657, 'kerr': 7658, 'harm': 7659, 'deploy': 7660, 'aurora': 7661, 'stays': 7662, 'BNP': 7663, 'mob': 7664, 'samantha': 7665, 'shawn': 7666, 'aging': 7667, 'wen': 7668, 'destruction': 7669, 'reddy': 7670, 'huffington': 7671, 'hell': 7672, 'alice': 7673, 'errors': 7674, 'reiterates': 7675, 'halftime': 7676, 'lashes': 7677, 'vendors': 7678, 'FOX': 7679, 'narrowed': 7680, 'burden': 7681, 'BT': 7682, 'raleigh': 7683, 'sandusky': 7684, 'sat': 7685, 'millionaire': 7686, 'reno': 7687, 'worcester': 7688, 'albion': 7689, 'hindi': 7690, 'detection': 7691, 'rouge': 7692, 'grandfather': 7693, 'persistent': 7694, 'debates': 7695, 'entrepreneurs': 7696, 'USS': 7697, 'hazardous': 7698, 'swat': 7699, 'stalled': 7700, 'urgent': 7701, 'aquino': 7702, '104': 7703, 'snyder': 7704, 'restoration': 7705, 'resistances': 7706, 'disgraced': 7707, 'abbey': 7708, '103': 7709, '31yearold': 7710, 'laureate': 7711, 'cleric': 7712, 'clearly': 7713, 'robertson': 7714, 'uzbekistan': 7715, 'tornadoes': 7716, 'RCMP': 7717, 'dividends': 7718, 'turnover': 7719, 'internationally': 7720, 'establishment': 7721, 'alzheimer': 7722, 'demonstrations': 7723, '8000': 7724, 'MRI': 7725, 'ashok': 7726, 'GaGa': 7727, 'flooded': 7728, 'actively': 7729, 'bride': 7730, 'disorders': 7731, 'hook': 7732, 'wrapped': 7733, 'preparations': 7734, 'junction': 7735, 'highlighting': 7736, 'taught': 7737, 'situations': 7738, 'gloucester': 7739, 'rescuers': 7740, 'treatments': 7741, 'sailors': 7742, 'colleague': 7743, 'fragile': 7744, 'mouse': 7745, 'hague': 7746, 'polar': 7747, 'jude': 7748, 'wanderers': 7749, 'bentley': 7750, 'contamination': 7751, 'manitoba': 7752, 'asiapacific': 7753, 'bulk': 7754, 'dawson': 7755, 'annually': 7756, 'snoop': 7757, 'firmer': 7758, 'bloc': 7759, 'knockout': 7760, 'spectacular': 7761, 'founded': 7762, 'difficulties': 7763, 'wallabies': 7764, 'leonard': 7765, 'cabin': 7766, 'taste': 7767, 'donor': 7768, 'shortages': 7769, 'represents': 7770, 'placing': 7771, '102': 7772, 'hurdle': 7773, 'committees': 7774, 'demonstrate': 7775, 'albania': 7776, 'emails': 7777, '03': 7778, 'tube': 7779, 'morocco': 7780, 'rocks': 7781, 'shannon': 7782, 'catching': 7783, 'dale': 7784, 'RIM': 7785, 'smash': 7786, 'exporter': 7787, 'trademark': 7788, 'POLICE': 7789, 'sum': 7790, 'nationally': 7791, 'novelist': 7792, 'mineral': 7793, 'correctional': 7794, 'macau': 7795, 'plug': 7796, 'ammunition': 7797, 'hitachi': 7798, '35yearold': 7799, 'chevron': 7800, 'filling': 7801, 'tightened': 7802, 'item': 7803, 'scared': 7804, 'astronauts': 7805, 'advisors': 7806, 'besides': 7807, 'worsening': 7808, 'aleague': 7809, 'bottles': 7810, 'kuwaiti': 7811, 'yearold': 7812, 'cave': 7813, 'freeman': 7814, 'characters': 7815, 'opposes': 7816, 'learnt': 7817, 'MVP': 7818, 'malaria': 7819, 'recreation': 7820, 'antitrust': 7821, 'critic': 7822, 'convinced': 7823, 'respects': 7824, 'songwriter': 7825, 'newsday': 7826, 'russians': 7827, 'charts': 7828, 'amended': 7829, 'doctorate': 7830, 'QB': 7831, 'cory': 7832, 'consideration': 7833, 'turnout': 7834, 'everybody': 7835, 'wheelchair': 7836, 'kingfisher': 7837, 'leone': 7838, 'thirdquarter': 7839, 'leigh': 7840, 'neighboring': 7841, 'recognised': 7842, 'disappointment': 7843, 'evan': 7844, 'zones': 7845, 'viral': 7846, 'visas': 7847, 'carol': 7848, 'sprained': 7849, 'suspending': 7850, 'judgment': 7851, 'vandalism': 7852, 'fence': 7853, '106': 7854, 'pratibha': 7855, 'durban': 7856, 'newt': 7857, 'commuter': 7858, 'FedEx': 7859, 'certified': 7860, 'principle': 7861, 'methodist': 7862, 'immigrant': 7863, 'minsk': 7864, 'sunshine': 7865, 'ramesh': 7866, 'tenants': 7867, 'generating': 7868, 'MW': 7869, 'nano': 7870, 'par': 7871, 'triumph': 7872, 'vic': 7873, 'roommate': 7874, 'monaco': 7875, 'casinos': 7876, 'airspace': 7877, 'qualifiers': 7878, 'cannes': 7879, 'gore': 7880, 'cease': 7881, 'atlantis': 7882, 'poultry': 7883, 'letterman': 7884, 'spare': 7885, 'kurdish': 7886, 'hillsborough': 7887, 'cumberland': 7888, 'activate': 7889, 'workshops': 7890, 'forgery': 7891, 'choppy': 7892, 'nights': 7893, 'strokes': 7894, 'wrongful': 7895, 'auctioned': 7896, 'zurich': 7897, 'burnley': 7898, 'experiences': 7899, 'lacrosse': 7900, 'portman': 7901, 'volumes': 7902, 'metric': 7903, 'sheboygan': 7904, 'pray': 7905, 'collide': 7906, 'elects': 7907, 'chaudhry': 7908, 'immunity': 7909, 'contestant': 7910, 'haley': 7911, 'aftermath': 7912, '9000': 7913, 'binghamton': 7914, 'cavendish': 7915, 'moines': 7916, 'vast': 7917, 'peters': 7918, 'lokpal': 7919, 'commons': 7920, '50yearold': 7921, 'shook': 7922, 'gerrard': 7923, 'nearing': 7924, 'freezing': 7925, 'repurchase': 7926, 'bathroom': 7927, 'treasure': 7928, 'continent': 7929, 'qld': 7930, 'monster': 7931, 'experimental': 7932, 'pill': 7933, 'eli': 7934, 'bass': 7935, 'extremists': 7936, 'saeed': 7937, 'denying': 7938, 'lagos': 7939, 'en': 7940, 'kraft': 7941, 'alltime': 7942, 'crist': 7943, 'assess': 7944, 'ronson': 7945, 'havoc': 7946, 'ODI': 7947, 'blaming': 7948, 'procedures': 7949, 'implications': 7950, 'strictly': 7951, 'efron': 7952, 'shifted': 7953, 'wildfires': 7954, 'flexible': 7955, 'undergone': 7956, 'grains': 7957, 'knoxville': 7958, 'MSNBC': 7959, 'witnessed': 7960, 'copies': 7961, 'math': 7962, 'mercer': 7963, 'basin': 7964, 'luther': 7965, '27yearold': 7966, 'rajapaksa': 7967, 'fourday': 7968, 'adobe': 7969, 'scratched': 7970, 'felix': 7971, 'gateway': 7972, 'exceed': 7973, 'capitals': 7974, 'suburbs': 7975, 'downloads': 7976, 'clinch': 7977, 'raceway': 7978, 'lists': 7979, 'westwood': 7980, '135': 7981, 'McDonnell': 7982, 'tweets': 7983, 'concludes': 7984, 'spying': 7985, 'ritchie': 7986, 'forever': 7987, 'whip': 7988, 'mechanism': 7989, 'balls': 7990, 'impaired': 7991, 'hewlettpackard': 7992, 'tightening': 7993, 'respiratory': 7994, 'litre': 7995, 'JSE': 7996, 'upbeat': 7997, 'conservatives': 7998, 'stallone': 7999, '107': 8000, 'slashes': 8001, 'blockade': 8002, 'canberra': 8003, 'belonging': 8004, 'flies': 8005, 'garrett': 8006, 'examine': 8007, 'dentist': 8008, 'adventure': 8009, 'dealt': 8010, 'sidney': 8011, 'soviet': 8012, 'zimmerman': 8013, 'experiencing': 8014, 'statistical': 8015, 'stint': 8016, 'outlet': 8017, 'kuala': 8018, 'MotoGP': 8019, 'transform': 8020, 'kindle': 8021, 'WA': 8022, 'disasters': 8023, 'peers': 8024, 'supervisors': 8025, 'kodak': 8026, 'panetta': 8027, 'counting': 8028, 'obtain': 8029, 'ambush': 8030, 'highlight': 8031, 'punk': 8032, 'disability': 8033, 'hungry': 8034, 'kylie': 8035, 'silva': 8036, 'thefts': 8037, 'SP': 8038, 'acted': 8039, 'weaken': 8040, 'inform': 8041, 'factors': 8042, 'mickey': 8043, 'duchess': 8044, 'biotechnology': 8045, 'indictment': 8046, 'sad': 8047, 'defrauding': 8048, 'yy': 8049, 'chess': 8050, 'AS': 8051, 'towers': 8052, 'machinery': 8053, 'trim': 8054, 'relation': 8055, 'paint': 8056, 'touching': 8057, 'powered': 8058, 'serves': 8059, 'formerly': 8060, 'stupid': 8061, 'transparent': 8062, 'abandon': 8063, 'watford': 8064, 'firstround': 8065, 'searched': 8066, 'peruvian': 8067, 'bet': 8068, 'shriver': 8069, 'comparison': 8070, 'scrutiny': 8071, 'hepatitis': 8072, 'escalating': 8073, 'widow': 8074, 'strange': 8075, 'concessions': 8076, 'jackpot': 8077, 'joan': 8078, 'incentive': 8079, '112': 8080, 'nonstop': 8081, 'bearish': 8082, 'settlers': 8083, 'connections': 8084, 'medalist': 8085, 'attends': 8086, 'literature': 8087, 'listen': 8088, 'gallon': 8089, 'eden': 8090, 'strongest': 8091, 'grip': 8092, 'purse': 8093, 'screens': 8094, 'AirTran': 8095, '7000': 8096, 'caucus': 8097, 'torres': 8098, 'builds': 8099, 'sinks': 8100, 'boutique': 8101, 'lea': 8102, 'wis': 8103, 'contributed': 8104, 'tymoshenko': 8105, '750': 8106, '00': 8107, 'indicate': 8108, 'belgrade': 8109, 'requirement': 8110, 'disclosure': 8111, 'lodge': 8112, 'prodemocracy': 8113, 'bishops': 8114, 'protested': 8115, '450': 8116, 'knocks': 8117, 'clashed': 8118, 'expense': 8119, 'attracted': 8120, 'barred': 8121, 'dipped': 8122, 'automobile': 8123, 'longawaited': 8124, 'bolivia': 8125, 'otherwise': 8126, 'breathing': 8127, 'helm': 8128, 'wound': 8129, 'deepika': 8130, 'pure': 8131, 'outreach': 8132, 'snowfall': 8133, 'camden': 8134, 'jessie': 8135, 'grande': 8136, 'albuquerque': 8137, 'casualties': 8138, 'q': 8139, 'bias': 8140, 'injection': 8141, 'norms': 8142, 'marilyn': 8143, 'driveby': 8144, 'longrunning': 8145, 'LLP': 8146, 'lorry': 8147, 'attracting': 8148, 'breached': 8149, 'FM': 8150, 'tan': 8151, 'borrow': 8152, 'bow': 8153, 'spike': 8154, 'conceded': 8155, 'conversation': 8156, 'committing': 8157, '111': 8158, 'dustin': 8159, 'pike': 8160, 'achieving': 8161, 'avoiding': 8162, 'fare': 8163, 'lecture': 8164, 'churches': 8165, 'comcast': 8166, 'describes': 8167, '115': 8168, 'coronation': 8169, 'rear': 8170, 'flame': 8171, 'dominate': 8172, 'payne': 8173, 'sevilla': 8174, 'savannah': 8175, 'jenna': 8176, 'infamous': 8177, 'balanced': 8178, 'boulder': 8179, 'tide': 8180, 'commencement': 8181, 'tunisian': 8182, 'holly': 8183, 'webcast': 8184, 'extradited': 8185, 'curfew': 8186, 'banner': 8187, 'marched': 8188, 'jackets': 8189, 'loose': 8190, 'aground': 8191, 'establishing': 8192, 'focuses': 8193, 'embezzling': 8194, 'piers': 8195, 'sultan': 8196, 'embezzlement': 8197, 'clemson': 8198, 'nixon': 8199, 'clarkson': 8200, 'freezes': 8201, 'exploitation': 8202, 'sears': 8203, 'warship': 8204, 'logan': 8205, 'brave': 8206, 'duck': 8207, 'responds': 8208, 'prolonged': 8209, 'minorities': 8210, 'securing': 8211, 'vitamin': 8212, 'outskirts': 8213, 'lowe': 8214, 'supermarkets': 8215, 'bikini': 8216, 'aggregate': 8217, 'rodney': 8218, 'ind': 8219, 'bypass': 8220, 'tory': 8221, 'spate': 8222, 'sight': 8223, 'unilever': 8224, 'closures': 8225, 'monitors': 8226, 'wikileaks': 8227, 'autobiography': 8228, 'versions': 8229, 'browser': 8230, 'slim': 8231, 'architect': 8232, 'hacker': 8233, 'scholarships': 8234, '12yearold': 8235, 'melissa': 8236, 'baron': 8237, 'attached': 8238, 'testified': 8239, 'lafayette': 8240, 'laptops': 8241, 'owed': 8242, 'pitched': 8243, 'baton': 8244, 'hates': 8245, 'contrary': 8246, 'beloved': 8247, 'controlling': 8248, 'eid': 8249, 'soar': 8250, 'chesapeake': 8251, 'palo': 8252, 'multimedia': 8253, 'umpire': 8254, 'gavin': 8255, 'exceeded': 8256, 'loyal': 8257, 'intelligent': 8258, 'Ã¢': 8259, 'condolences': 8260, 'pharma': 8261, 'frame': 8262, 'scherzinger': 8263, 'calf': 8264, 'liberation': 8265, 'wholly': 8266, 'ugly': 8267, 'bangladeshi': 8268, 'sophomore': 8269, 'dual': 8270, 'accord': 8271, 'database': 8272, '1300': 8273, 'preventing': 8274, 'invite': 8275, 'bitten': 8276, 'dancer': 8277, 'ensuring': 8278, 'bedroom': 8279, 'conferences': 8280, 'margins': 8281, 'optical': 8282, 'emily': 8283, 'PCs': 8284, 'lure': 8285, 'uncle': 8286, 'drowning': 8287, 'tina': 8288, 'episodes': 8289, 'didier': 8290, 'lowcost': 8291, 'mozambique': 8292, 'salon': 8293, 'spots': 8294, 'yankee': 8295, 'shortterm': 8296, 'bestselling': 8297, 'deeply': 8298, 'breaching': 8299, 'magistrates': 8300, 'cambodia': 8301, 'choices': 8302, 'refuge': 8303, 'modified': 8304, 'protocol': 8305, 'daniels': 8306, \"o'donnell\": 8307, 'insurers': 8308, 'articles': 8309, 'opted': 8310, 'salisbury': 8311, 'shiite': 8312, 'rumor': 8313, 'upto': 8314, 'leisure': 8315, 'peacefully': 8316, '06': 8317, 'hood': 8318, 'lennon': 8319, 'hottest': 8320, 'colon': 8321, 'zach': 8322, 'menu': 8323, 'alec': 8324, 'unanimous': 8325, 'directing': 8326, 'protestors': 8327, 'spreads': 8328, 'rumored': 8329, 'donors': 8330, 'regret': 8331, 'grammer': 8332, 'carr': 8333, 'ventura': 8334, 'killers': 8335, 'debuts': 8336, 'examiner': 8337, 'roland': 8338, 'incorporated': 8339, 'realtime': 8340, 'partly': 8341, 'starred': 8342, 'preview': 8343, 'southampton': 8344, 'lifting': 8345, 'please': 8346, 'comfort': 8347, 'loud': 8348, 'overwhelmingly': 8349, 'aloud': 8350, 'biological': 8351, 'conjunction': 8352, 'here': 8353, 'occupation': 8354, 'canterbury': 8355, 'animated': 8356, 'jews': 8357, 'betterthanexpected': 8358, 'detailed': 8359, 'bracing': 8360, 'collecting': 8361, 'mid': 8362, 'relatively': 8363, 'continuous': 8364, 'complained': 8365, 'afghans': 8366, 'issuer': 8367, 'honolulu': 8368, 'galway': 8369, 'carries': 8370, 'kourtney': 8371, 'revamped': 8372, 'meltdown': 8373, '150000': 8374, 'incredible': 8375, 'fraudulent': 8376, 'reagan': 8377, 'roses': 8378, 'gunfire': 8379, 'gradually': 8380, 'downing': 8381, 'testimony': 8382, 'forestry': 8383, 'slumped': 8384, 'venues': 8385, 'napoli': 8386, 'audiences': 8387, 'kit': 8388, 'allamerican': 8389, 'homer': 8390, 'fielder': 8391, 'vaccines': 8392, 'hurley': 8393, 'injunction': 8394, 'hiked': 8395, 'nasdaq': 8396, 'dunn': 8397, 'alto': 8398, 'landfall': 8399, 'raided': 8400, 'blackpool': 8401, 'brighton': 8402, 'stunned': 8403, 'ATP': 8404, 'totally': 8405, 'onevehicle': 8406, 'sikh': 8407, 'rooms': 8408, 'cautioned': 8409, 'dismissal': 8410, 'fulltime': 8411, 'batman': 8412, 'frequent': 8413, 'timor': 8414, 'anchorage': 8415, 'exploring': 8416, 'trafford': 8417, 'larceny': 8418, 'productions': 8419, 'goody': 8420, 'rescheduled': 8421, 'personally': 8422, 'TSX': 8423, 'novosti': 8424, 'owes': 8425, 'vigil': 8426, '39yearold': 8427, 'alba': 8428, 'gotten': 8429, 'mahendra': 8430, 'groupon': 8431, 'lucrative': 8432, 'jiabao': 8433, 'mirror': 8434, 'bloom': 8435, 'leaking': 8436, 'rai': 8437, 'kazakh': 8438, 'OK': 8439, 'splash': 8440, 'contracted': 8441, 'offenses': 8442, 'wachovia': 8443, 'array': 8444, 'PayPal': 8445, 'ubisoft': 8446, 'hangs': 8447, 'achieves': 8448, '1960s': 8449, 'topeka': 8450, 'monte': 8451, 'socialist': 8452, 'dynamo': 8453, 'DWI': 8454, 'leinster': 8455, 'polk': 8456, 'gamble': 8457, '07': 8458, 'chan': 8459, 'arguing': 8460, 'destroying': 8461, 'finalized': 8462, 'distance': 8463, 'denise': 8464, 'peas': 8465, 'java': 8466, 'composite': 8467, 'homage': 8468, 'batteries': 8469, 'borrowers': 8470, '13yearold': 8471, 'mirren': 8472, 'lilly': 8473, 'auditorium': 8474, 'psychiatric': 8475, 'julio': 8476, 'passion': 8477, 'trent': 8478, 'barrymore': 8479, 'akhtar': 8480, 'examination': 8481, '650': 8482, 'highland': 8483, 'paralympic': 8484, 'expires': 8485, 'associations': 8486, 'decisive': 8487, 'keeper': 8488, 'convoy': 8489, 'historian': 8490, 'diverted': 8491, 'patience': 8492, 'kg': 8493, 'indication': 8494, 'coldplay': 8495, 'nash': 8496, 'knifepoint': 8497, 'donating': 8498, 'pedestrians': 8499, 'languages': 8500, 'custom': 8501, 'instructor': 8502, 'highlighted': 8503, 'moratorium': 8504, 'syndrome': 8505, 'obsessed': 8506, 'anticorruption': 8507, 'warships': 8508, 'memories': 8509, 'whales': 8510, 'waiver': 8511, '27th': 8512, 'wellness': 8513, 'LED': 8514, 'kelsey': 8515, 'handsets': 8516, 'backyard': 8517, 'explorer': 8518, 'outgoing': 8519, '08': 8520, 'habitat': 8521, 'dish': 8522, 'principles': 8523, 'module': 8524, 'motorist': 8525, 'lodged': 8526, 'discipline': 8527, 'parkinson': 8528, 'funded': 8529, 'imaging': 8530, 'bahraini': 8531, 'transfers': 8532, 'honours': 8533, 'predators': 8534, 'paraguay': 8535, 'diva': 8536, 'vampire': 8537, 'boxes': 8538, 'temperature': 8539, 'mrs': 8540, 'ossetia': 8541, 'richest': 8542, 'impersonating': 8543, 'highlands': 8544, 'brigade': 8545, 'stimulate': 8546, 'valuation': 8547, 'dana': 8548, 'affiliated': 8549, 'fletcher': 8550, 'McIlroy': 8551, 'detainees': 8552, 'narcotics': 8553, 'grizzlies': 8554, 'hobbit': 8555, 'UKbased': 8556, 'precision': 8557, 'fenway': 8558, 'collaborate': 8559, 'northampton': 8560, 'restoring': 8561, 'pumps': 8562, 'fertilizer': 8563, 'patterson': 8564, 'alexandra': 8565, 'cohost': 8566, 'slashing': 8567, 'benson': 8568, 'amar': 8569, 'wooden': 8570, 'virtually': 8571, 'MTN': 8572, 'captures': 8573, 'lewd': 8574, 'leno': 8575, 'rupees': 8576, 'CPI': 8577, 'ulster': 8578, 'tears': 8579, 'liberals': 8580, 'sinking': 8581, 'crushing': 8582, 'breakdown': 8583, 'lumpur': 8584, 'senegal': 8585, 'lined': 8586, 'heated': 8587, 'psychological': 8588, 'CNBC': 8589, 'surfaced': 8590, 'disposal': 8591, 'slugger': 8592, 'separated': 8593, 'theaters': 8594, 'linda': 8595, 'beverage': 8596, 'dumping': 8597, 'shipment': 8598, \"o'neill\": 8599, 'immune': 8600, 'oversight': 8601, 'letting': 8602, 'apologize': 8603, 'undefeated': 8604, 'barrett': 8605, 'rahman': 8606, 'jaguar': 8607, 'respective': 8608, '2G': 8609, 'weigh': 8610, 'fabrice': 8611, 'bizarre': 8612, 'whatever': 8613, 'deliberately': 8614, 'noting': 8615, 'roddick': 8616, 'ibrahim': 8617, 'auctions': 8618, 'unsecured': 8619, 'surf': 8620, 'donovan': 8621, 'interviews': 8622, 'dust': 8623, 'boot': 8624, 'fantastic': 8625, 'bigg': 8626, 'geological': 8627, 'quietly': 8628, 'bruised': 8629, 'absolute': 8630, 'automated': 8631, 'pleasant': 8632, 'copa': 8633, 'hai': 8634, 'RIA': 8635, 'seth': 8636, 'GPS': 8637, 'fisheries': 8638, 'indicators': 8639, 'daytime': 8640, 'bicyclist': 8641, 'moammar': 8642, 'accreditation': 8643, 'lotus': 8644, 'booth': 8645, 'understands': 8646, 'washing': 8647, 'spark': 8648, 'conway': 8649, '38yearold': 8650, 'pedro': 8651, 'budapest': 8652, 'greenville': 8653, 'WBA': 8654, 'asda': 8655, 'steals': 8656, 'intensified': 8657, 'provisions': 8658, 'tactics': 8659, 'tajikistan': 8660, 'promotional': 8661, 'ga': 8662, 'twist': 8663, 'spiderman': 8664, 'sort': 8665, 'junk': 8666, 'swimmer': 8667, 'lloyds': 8668, 'dannii': 8669, 'ANZ': 8670, 'booker': 8671, 'leighton': 8672, 'gurgaon': 8673, 'eyeing': 8674, 'extinction': 8675, 'kissing': 8676, 'finalised': 8677, 'meal': 8678, 'indices': 8679, 'ordering': 8680, 'marina': 8681, 'sienna': 8682, 'farming': 8683, 'ballistic': 8684, 'stray': 8685, 'designate': 8686, 'competitors': 8687, 'bosnia': 8688, 'polanski': 8689, 'barker': 8690, 'mayawati': 8691, 'pains': 8692, 'divided': 8693, 'console': 8694, '24th': 8695, 'campaigning': 8696, 'shrink': 8697, 'thatcher': 8698, 'follows': 8699, 'cricketers': 8700, 'mila': 8701, 'bassist': 8702, 'realty': 8703, 'tenure': 8704, 'priorities': 8705, 'harder': 8706, 'zynga': 8707, 'deportation': 8708, 'outcome': 8709, 'ratio': 8710, 'vessels': 8711, 'delegates': 8712, 'wesley': 8713, 'disqualified': 8714, 'affects': 8715, 'shower': 8716, 'flowers': 8717, 'savage': 8718, 'overturns': 8719, 'ny': 8720, 'bullets': 8721, 'furious': 8722, 'spokane': 8723, 'bidding': 8724, 'kashmiri': 8725, 'knock': 8726, 'firsthalf': 8727, 'EP': 8728, 'lengthy': 8729, 'approvals': 8730, 'solomon': 8731, 'lunar': 8732, 'sotomayor': 8733, 'consolidated': 8734, 'julius': 8735, 'righthanded': 8736, 'shelters': 8737, 'comply': 8738, 'kickoff': 8739, 'intoxication': 8740, 'territories': 8741, 'trips': 8742, 'none': 8743, 'rao': 8744, 'cornwall': 8745, 'hawke': 8746, 'latter': 8747, 'observe': 8748, 'scenario': 8749, 'shrank': 8750, 'travolta': 8751, 'participated': 8752, 'lindsey': 8753, 'underwear': 8754, 'diamonds': 8755, 'jackman': 8756, 'jong': 8757, '630': 8758, 'abuses': 8759, 'blocking': 8760, 'ranging': 8761, 'bermuda': 8762, 'frederick': 8763, 'steroids': 8764, 'aer': 8765, 'spacecraft': 8766, 'antiterrorism': 8767, 'enables': 8768, 'IV': 8769, 'affirmed': 8770, 'deeper': 8771, 'loyalty': 8772, 'timing': 8773, 'halfway': 8774, 'naming': 8775, 'ho': 8776, 'mentor': 8777, 'lied': 8778, 'bean': 8779, 'chambers': 8780, 'strait': 8781, 'ArcelorMittal': 8782, 'maid': 8783, 'shahrukh': 8784, 'forests': 8785, 'freestyle': 8786, 'memoir': 8787, 'pared': 8788, 'owens': 8789, 'fiber': 8790, 'salmonella': 8791, 'deficits': 8792, 'reaffirmed': 8793, 'paternity': 8794, '1400': 8795, 'shepherd': 8796, 'paving': 8797, 'webster': 8798, 'lancashire': 8799, 'aides': 8800, 'strauss': 8801, 'registry': 8802, '108': 8803, 'mideast': 8804, 'akron': 8805, 'commissions': 8806, 'collides': 8807, 'pensioners': 8808, 'piper': 8809, 'eugene': 8810, 'filmed': 8811, 'drogba': 8812, 'slapped': 8813, 'everywhere': 8814, 'shake': 8815, 'eliminating': 8816, 'taxation': 8817, 'viktor': 8818, 'hospitality': 8819, 'entertainer': 8820, 'firearm': 8821, 'disrupt': 8822, 'categories': 8823, '9th': 8824, 'brewing': 8825, 'inner': 8826, 'headley': 8827, 'augusta': 8828, 'saga': 8829, 'martha': 8830, 'splitting': 8831, 'imperial': 8832, 'ole': 8833, 'favourites': 8834, 'cardiovascular': 8835, 'deserves': 8836, 'panda': 8837, 'shia': 8838, 'wrestler': 8839, 'cameroon': 8840, 'gainesville': 8841, 'deemed': 8842, 'smooth': 8843, 'khurshid': 8844, '1700': 8845, 'reopening': 8846, 'doha': 8847, 'wondering': 8848, 'ariz': 8849, 'sao': 8850, 'ideal': 8851, 'carlyle': 8852, 'bite': 8853, 'weighing': 8854, 'jill': 8855, 'appearances': 8856, 'guinness': 8857, 'arroyo': 8858, 'alcoa': 8859, 'JC': 8860, 'cutler': 8861, '230': 8862, '28th': 8863, 'opt': 8864, 'threetime': 8865, '2018': 8866, 'dundee': 8867, 'literacy': 8868, 'touchdown': 8869, 'fergie': 8870, 'conflicts': 8871, 'ranbir': 8872, 'mosley': 8873, 'pan': 8874, 'heathrow': 8875, 'byrne': 8876, 'improper': 8877, 'manufacture': 8878, 'RSS': 8879, 'prof': 8880, 'graphic': 8881, 'shirley': 8882, 'sections': 8883, 'fingers': 8884, 'isolated': 8885, 'runaway': 8886, 'graffiti': 8887, 'barely': 8888, 'irvine': 8889, 'karunanidhi': 8890, 'expression': 8891, 'catastrophic': 8892, 'architecture': 8893, 'obligations': 8894, 'column': 8895, 'negligent': 8896, 'snowmobile': 8897, 'limerick': 8898, 'sword': 8899, 'sedan': 8900, 'crowe': 8901, 'overwhelming': 8902, '1800': 8903, 'petraeus': 8904, 'surging': 8905, 'rejoin': 8906, 'mosquito': 8907, 'TI': 8908, 'nicholas': 8909, 'jenny': 8910, 'saskatoon': 8911, 'khyber': 8912, 'supervisor': 8913, 'unlimited': 8914, 'epidemic': 8915, 'barney': 8916, 'PepsiCo': 8917, 'AJ': 8918, 'pleas': 8919, 'eager': 8920, 'bosnian': 8921, 'cellphone': 8922, 'tired': 8923, 'properly': 8924, 'pacers': 8925, 'caterpillar': 8926, 'belarusian': 8927, 'tab': 8928, 'naples': 8929, 'eleven': 8930, 'credited': 8931, 'rainbow': 8932, 'speedy': 8933, 'employed': 8934, 'ramadan': 8935, 'types': 8936, 'halts': 8937, 'measuring': 8938, 'reads': 8939, '22nd': 8940, 'shipyard': 8941, 'precautionary': 8942, 'cheat': 8943, '600000': 8944, 'knights': 8945, 'intensify': 8946, 'xperia': 8947, 'balloon': 8948, 'poster': 8949, 'pupil': 8950, 'rampage': 8951, 'unmanned': 8952, 'breakaway': 8953, 'sewage': 8954, 'cheese': 8955, 'nate': 8956, 'slot': 8957, 'synthetic': 8958, 'contador': 8959, 'flintoff': 8960, 'warplanes': 8961, 'liz': 8962, 'duet': 8963, 'persian': 8964, 'AirAsia': 8965, 'electrocuted': 8966, 'gearing': 8967, 'knightley': 8968, 'intentionally': 8969, 'kunis': 8970, 'ashore': 8971, 'obese': 8972, 'beck': 8973, 'ID': 8974, 'pictured': 8975, 'upsets': 8976, 'bronx': 8977, 'attitude': 8978, 'seizes': 8979, 'kristin': 8980, 'keane': 8981, 'surges': 8982, 'icahn': 8983, 'frontline': 8984, 'schalke': 8985, 'jenner': 8986, 'upholds': 8987, 'establishes': 8988, 'commitments': 8989, 'guatemala': 8990, 'putnam': 8991, 'roanoke': 8992, 'goalless': 8993, 'flats': 8994, 'evolution': 8995, 'romo': 8996, 'milton': 8997, 'ligament': 8998, 'pianist': 8999, 'polio': 9000, 'worry': 9001, 'turnaround': 9002, 'granite': 9003, 'teaming': 9004, 'flick': 9005, 'modestly': 9006, 'drag': 9007, 'accelerate': 9008, 'weeklong': 9009, 'viewing': 9010, 'christine': 9011, 'billings': 9012, 'elsewhere': 9013, 'touches': 9014, 'fog': 9015, 'darling': 9016, 'inevitable': 9017, 'kilometres': 9018, 'warne': 9019, 'promoter': 9020, 'notebook': 9021, 'answered': 9022, 'seemed': 9023, 'maestro': 9024, 'vegetable': 9025, 'kochi': 9026, 'cult': 9027, 'EST': 9028, 'deliveries': 9029, 'produces': 9030, 'twovehicle': 9031, 'tendon': 9032, 'candlestick': 9033, 'composition': 9034, 'goodbye': 9035, 'headlines': 9036, 'bulldogs': 9037, 'USled': 9038, 'connectivity': 9039, 'aluminum': 9040, 'obstruction': 9041, 'jurors': 9042, 'happening': 9043, 'physicians': 9044, 'surfer': 9045, 'ilham': 9046, 'relevant': 9047, 'commenced': 9048, 'BCCI': 9049, 'elimination': 9050, 'recognizes': 9051, 'canadiens': 9052, 'lithuania': 9053, 'prisons': 9054, 'sack': 9055, 'anfield': 9056, 'huawei': 9057, 'crow': 9058, 'johns': 9059, 'commemorate': 9060, 'virtualization': 9061, 'pile': 9062, 'globes': 9063, 'fragrance': 9064, 'vetoes': 9065, 'curry': 9066, 'va': 9067, 'kaif': 9068, 'handgun': 9069, 'flows': 9070, 'buccaneers': 9071, 'conspiring': 9072, 'seasonally': 9073, 'commence': 9074, 'capped': 9075, 'enrichment': 9076, 'wonderful': 9077, 'fidel': 9078, 'reshuffle': 9079, 'sixmonth': 9080, 'neither': 9081, 'lufthansa': 9082, 'havana': 9083, 'payable': 9084, 'huckabee': 9085, 'anticipation': 9086, 'daryl': 9087, 'bal': 9088, 'liquid': 9089, 'rabies': 9090, 'aliens': 9091, 'checking': 9092, 'dynamic': 9093, 'prasad': 9094, '41yearold': 9095, 'namibia': 9096, 'directions': 9097, 'aluminium': 9098, 'handful': 9099, 'legally': 9100, 'coordination': 9101, 'enemies': 9102, 'freak': 9103, 'pork': 9104, 'ajay': 9105, 'chandler': 9106, 'habits': 9107, 'joplin': 9108, 'humane': 9109, 'exist': 9110, 'postpone': 9111, 'concentrate': 9112, 'kendra': 9113, '70000': 9114, 'mellon': 9115, 'bullying': 9116, 'shelves': 9117, 'shoaib': 9118, 'bacteria': 9119, 'tv': 9120, 'scottsdale': 9121, 'MS': 9122, 'clijsters': 9123, 'malibu': 9124, 'hearings': 9125, 'cindy': 9126, 'colbert': 9127, 'emerges': 9128, 'tables': 9129, 'stakeholders': 9130, 'bali': 9131, 'mongolia': 9132, 'regulate': 9133, 'manipur': 9134, 'sainsbury': 9135, 'MT': 9136, 'joke': 9137, '170': 9138, 'sylvester': 9139, 'kane': 9140, 'hudgens': 9141, 'snake': 9142, 'condemn': 9143, 'libraries': 9144, 'enabling': 9145, 'diversified': 9146, 'servers': 9147, 'smallest': 9148, 'assurance': 9149, 'tariffs': 9150, 'twenty': 9151, 'corridor': 9152, 'portrait': 9153, 'supervision': 9154, 'endorsing': 9155, '4S': 9156, 'chhattisgarh': 9157, 'booming': 9158, 'locals': 9159, 'woody': 9160, 'surprisingly': 9161, 'ramdev': 9162, 'desk': 9163, 'builders': 9164, 'carney': 9165, 'haul': 9166, 'nephew': 9167, 'stephanie': 9168, 'ancelotti': 9169, 'pretoria': 9170, 'slalom': 9171, 'jindal': 9172, 'automakers': 9173, 'shahbaz': 9174, 'apollo': 9175, 'smokers': 9176, 'competitiveness': 9177, '1970s': 9178, 'DMK': 9179, 'yearonyear': 9180, 'fibre': 9181, '47yearold': 9182, 'emission': 9183, 'sheep': 9184, 'owing': 9185, 'marvel': 9186, 'acceptance': 9187, 'aviva': 9188, 'doncaster': 9189, 'detect': 9190, 'secretarygeneral': 9191, 'harare': 9192, 'liga': 9193, 'lockheed': 9194, 'seacrest': 9195, 'orthodox': 9196, 'shropshire': 9197, 'blown': 9198, '31st': 9199, 'trainers': 9200, 'switching': 9201, 'lords': 9202, 'stun': 9203, 'radar': 9204, '10year': 9205, 'gyllenhaal': 9206, 'mahama': 9207, 'incredibly': 9208, 'carrey': 9209, 'livingston': 9210, 'colour': 9211, 'candy': 9212, 'overtake': 9213, 'appliances': 9214, 'prevented': 9215, 'generations': 9216, 'brit': 9217, 'instant': 9218, 'edwin': 9219, 'revoked': 9220, 'honoring': 9221, 'ruth': 9222, 'interface': 9223, 'africans': 9224, 'submarine': 9225, 'guarantees': 9226, 'JetBlue': 9227, 'steering': 9228, 'divorced': 9229, 'bahamas': 9230, 'pepsi': 9231, 'gibb': 9232, 'airplane': 9233, 'trinamool': 9234, 'banquet': 9235, 'bynes': 9236, 'onboard': 9237, 'powder': 9238, 'searches': 9239, 'reader': 9240, 'amendments': 9241, 'honduras': 9242, 'landfill': 9243, 'allied': 9244, 'thrilled': 9245, 'rotary': 9246, 'eclipse': 9247, 'engulfing': 9248, 'colonial': 9249, 'iPhones': 9250, 'procurement': 9251, 'abdominal': 9252, 'brutally': 9253, 'truce': 9254, 'tone': 9255, 'crusaders': 9256, 'burglars': 9257, 'wore': 9258, 'skilled': 9259, 'crowds': 9260, 'WBO': 9261, 'braced': 9262, 'aquarium': 9263, 'pursuing': 9264, 'stan': 9265, 'amend': 9266, 'PR': 9267, 'perdue': 9268, 'interviewed': 9269, 'crosses': 9270, 'paramedics': 9271, 'ahmedabad': 9272, 'ACT': 9273, 'tier': 9274, 'chivas': 9275, 'hiatus': 9276, 'shetty': 9277, 'flower': 9278, 'subsidy': 9279, 'onetime': 9280, 'specialists': 9281, 'artificial': 9282, 'middlesbrough': 9283, 'processor': 9284, 'inflationary': 9285, 'straw': 9286, 'imposes': 9287, 'inaugurates': 9288, 'installs': 9289, 'mickelson': 9290, 'unlawful': 9291, 'mln': 9292, 'represented': 9293, 'byrd': 9294, 'nod': 9295, 'municipalities': 9296, 'usage': 9297, 'kiev': 9298, 'dirt': 9299, 'shelton': 9300, 'atop': 9301, 'twoyearold': 9302, 'iranians': 9303, 'height': 9304, 'advocacy': 9305, 'karan': 9306, 'avery': 9307, 'boca': 9308, 'shields': 9309, 'jamaican': 9310, '11yearold': 9311, 'meyer': 9312, 'physician': 9313, 'whilst': 9314, 'exposing': 9315, 'madhya': 9316, 'elephants': 9317, 'ronald': 9318, 'supposed': 9319, 'hazard': 9320, 'advancing': 9321, 'correct': 9322, 'gill': 9323, 'primarily': 9324, 'paribas': 9325, 'tortured': 9326, 'imagine': 9327, 'outrage': 9328, 'fundamental': 9329, 'harlem': 9330, 'powerball': 9331, 'NDA': 9332, 'missions': 9333, 'lifeline': 9334, 'contention': 9335, 'lovers': 9336, 'balochistan': 9337, 'expel': 9338, 'apprentice': 9339, 'rides': 9340, 'McAfee': 9341, 'adverse': 9342, 'arrow': 9343, 'expired': 9344, 'lefthander': 9345, 'intimate': 9346, 'FCC': 9347, 'leaf': 9348, 'predicting': 9349, 'guaranteed': 9350, 'blackberry': 9351, 'primetime': 9352, 'chairperson': 9353, 'pardew': 9354, 'penelope': 9355, 'hotspur': 9356, 'relegated': 9357, 'venus': 9358, 'rivera': 9359, 'wouldbe': 9360, 'monkey': 9361, 'multinational': 9362, 'ugandan': 9363, 'miracle': 9364, 'bismarck': 9365, 'forks': 9366, 'groundbreaking': 9367, 'hancock': 9368, 'militia': 9369, 'fastgrowing': 9370, 'evicted': 9371, 'ST': 9372, 'tune': 9373, 'terrible': 9374, '200809': 9375, 'summoned': 9376, 'sectarian': 9377, 'pocket': 9378, 'mounted': 9379, 'bribes': 9380, 'musicians': 9381, '09': 9382, 'circus': 9383, 'prostitute': 9384, 'costing': 9385, 'hung': 9386, 'desmond': 9387, 'geo': 9388, 'jaipur': 9389, 'nigel': 9390, 'falcon': 9391, 'pawar': 9392, 'jerome': 9393, 'SAS': 9394, 'carpenter': 9395, 'migrant': 9396, 'inch': 9397, 'kia': 9398, 'gesture': 9399, 'fixture': 9400, 'norton': 9401, 'jokes': 9402, 'refining': 9403, 'dangers': 9404, 'supplying': 9405, \"o'connor\": 9406, 'driveway': 9407, 'keira': 9408, 'sprinter': 9409, 'impending': 9410, 'ear': 9411, 'eminem': 9412, 'negligence': 9413, 'heineken': 9414, 'ringgit': 9415, 'consultants': 9416, 'McQueen': 9417, 'tripura': 9418, 'migration': 9419, 'identifying': 9420, 'corey': 9421, 'hulk': 9422, 'marvin': 9423, 'bipartisan': 9424, 'soup': 9425, 'footprint': 9426, 'iftikhar': 9427, 'airstrike': 9428, 'methamphetamine': 9429, 'pakistanis': 9430, 'resumption': 9431, 'implementing': 9432, 'nassau': 9433, 'biel': 9434, 'staples': 9435, 'mt': 9436, 'kara': 9437, 'chains': 9438, 'candidacy': 9439, '145': 9440, 'collapsing': 9441, 'shakes': 9442, 'hon': 9443, 'literally': 9444, 'investigator': 9445, 'feelings': 9446, 'limiting': 9447, 'aka': 9448, 'busiest': 9449, 'patriot': 9450, 'misleading': 9451, 'chapel': 9452, 'impressed': 9453, 'dominant': 9454, 'il': 9455, 'dixon': 9456, 'premiums': 9457, 'victories': 9458, 'competent': 9459, 'beam': 9460, 'exported': 9461, 'petrochemical': 9462, 'institutes': 9463, 'restive': 9464, 'hatch': 9465, 'triggering': 9466, 'lauderdale': 9467, 'medallist': 9468, 'travels': 9469, 'vonn': 9470, 'evil': 9471, 'hardy': 9472, 'lynchburg': 9473, '26th': 9474, 'runners': 9475, '40yearold': 9476, 'headquartered': 9477, 'paulson': 9478, 'vandalized': 9479, 'booze': 9480, 'lingus': 9481, 'merit': 9482, 'devon': 9483, 'prescribed': 9484, 'wardrobe': 9485, 'credible': 9486, 'lara': 9487, 'quincy': 9488, 'lorenzo': 9489, 'icy': 9490, 'rawalpindi': 9491, 'tense': 9492, 'prom': 9493, 'oneida': 9494, 'hop': 9495, 'berkshire': 9496, 'stormed': 9497, 'sanctuary': 9498, 'yusuf': 9499, 'afridi': 9500, 'deere': 9501, 'jam': 9502, 'armenians': 9503, 'papua': 9504, 'peso': 9505, 'firstever': 9506, 'rubbish': 9507, 'antidoping': 9508, 'spared': 9509, 'schmidt': 9510, 'britons': 9511, 'foray': 9512, 'disturbing': 9513, 'MGM': 9514, 'iPads': 9515, 'cafe': 9516, 'dealerships': 9517, 'bethlehem': 9518, 'spa': 9519, 'fiancee': 9520, 'breaches': 9521, 'meredith': 9522, 'except': 9523, 'boone': 9524, 'confidential': 9525, 'xavier': 9526, 'sticks': 9527, 'kyiv': 9528, '33yearold': 9529, 'blazers': 9530, 'financially': 9531, 'drills': 9532, 'hutchison': 9533, 'courtesy': 9534, 'rosa': 9535, 'thermo': 9536, 'canton': 9537, 'caucasus': 9538, 'looming': 9539, 'caretaker': 9540, 'ballet': 9541, 'johan': 9542, 'paddy': 9543, 'refuse': 9544, 'optimization': 9545, 'brittany': 9546, 'garner': 9547, 'tall': 9548, 'UC': 9549, 'trusted': 9550, 'fault': 9551, 'gutted': 9552, 'concord': 9553, 'salvador': 9554, 'troubles': 9555, 'shotgun': 9556, 'counseling': 9557, 'CITY': 9558, 'conversion': 9559, 'capability': 9560, 'lap': 9561, 'osborne': 9562, 'lingering': 9563, 'luxembourg': 9564, 'NYPD': 9565, 'swayze': 9566, 'chi': 9567, 'mitch': 9568, 'surrounded': 9569, 'lisbon': 9570, 'punished': 9571, 'discounts': 9572, 'vocal': 9573, 'PA': 9574, 'basu': 9575, 'mercantile': 9576, 'phillip': 9577, 'duluth': 9578, 'elena': 9579, 'phelps': 9580, 'weisz': 9581, 'dioxide': 9582, 'UConn': 9583, 'pendleton': 9584, 'richter': 9585, 'fayetteville': 9586, 'punish': 9587, 'switched': 9588, 'hayes': 9589, 'facts': 9590, 'gabor': 9591, 'nordstrom': 9592, 'soybean': 9593, 'ACC': 9594, 'lazio': 9595, 'xerox': 9596, 'akshay': 9597, 'delaying': 9598, 'shrinks': 9599, 'chooses': 9600, 'nominates': 9601, 'aerial': 9602, 'jacques': 9603, 'partnerships': 9604, 'EMC': 9605, 'uttarakhand': 9606, 'NH': 9607, 'intoxicated': 9608, 'movements': 9609, 'moreno': 9610, 'nike': 9611, 'jaime': 9612, 'threegame': 9613, 'explosions': 9614, 'gloria': 9615, 'penney': 9616, 'ansari': 9617, 'convictions': 9618, 'geoff': 9619, 'wealthy': 9620, 'commentator': 9621, 'sutherland': 9622, '45yearold': 9623, 'designers': 9624, 'assaults': 9625, 'ruler': 9626, 'dissent': 9627, 'eastman': 9628, 'containers': 9629, 'najib': 9630, 'maori': 9631, 'youngster': 9632, 'processors': 9633, 'applying': 9634, 'choosing': 9635, 'prolific': 9636, 'LNG': 9637, 'gardner': 9638, 'assemblyman': 9639, 'observer': 9640, 'telangana': 9641, 'malema': 9642, 'receivers': 9643, 'cairn': 9644, 'contaminated': 9645, 'mayors': 9646, 'lingerie': 9647, 'nitin': 9648, '550': 9649, 'debit': 9650, 'expertise': 9651, 'cork': 9652, 'asheville': 9653, 'saab': 9654, 'abhishek': 9655, 'bash': 9656, 'finalist': 9657, 'licensed': 9658, 'connecting': 9659, 'estates': 9660, 'directorial': 9661, 'enrollment': 9662, 'gangster': 9663, 'redistricting': 9664, 'defenceman': 9665, 'copenhagen': 9666, 'biting': 9667, 'sai': 9668, 'dismal': 9669, 'BART': 9670, 'wrongly': 9671, 'OJ': 9672, 'refinancing': 9673, 'inked': 9674, 'background': 9675, 'mentioned': 9676, 'sacrifice': 9677, 'speakers': 9678, 'campaigners': 9679, 'harrington': 9680, 'luncheon': 9681, 'turtle': 9682, 'baxter': 9683, 'graphics': 9684, 'averages': 9685, 'OSCE': 9686, 'NV': 9687, 'clint': 9688, 'closet': 9689, 'deserved': 9690, 'danielle': 9691, 'maxwell': 9692, 'manufactured': 9693, 'component': 9694, 'cubic': 9695, 'benazir': 9696, 'gosling': 9697, 'appalachian': 9698, 'colony': 9699, 'bachelor': 9700, 'aboriginal': 9701, 'presley': 9702, 'elvis': 9703, 'verge': 9704, 'NL': 9705, 'rita': 9706, 'wears': 9707, 'mask': 9708, 'lowering': 9709, 'MD': 9710, 'delicious': 9711, 'cooling': 9712, 'branding': 9713, 'rodham': 9714, 'separation': 9715, 'mound': 9716, 'shifting': 9717, 'snapping': 9718, 'surviving': 9719, 'suicidal': 9720, 'erin': 9721, 'sunni': 9722, 'convince': 9723, 'sail': 9724, 'VAT': 9725, 'tumour': 9726, 'yerevan': 9727, 'euronext': 9728, 'everyday': 9729, 'arbor': 9730, 'complaining': 9731, 'LPGA': 9732, 'motorway': 9733, 'entirely': 9734, 'diplomacy': 9735, 'olivia': 9736, 'robinho': 9737, 'marred': 9738, 'aishwarya': 9739, 'igor': 9740, 'chasing': 9741, 'patrols': 9742, 'root': 9743, 'regularly': 9744, 'vogue': 9745, 'gareth': 9746, 'basement': 9747, 'sufficient': 9748, 'sacred': 9749, 'recruits': 9750, 'rex': 9751, 'olive': 9752, 'reductions': 9753, 'fallon': 9754, 'calvin': 9755, 'footage': 9756, 'jacobs': 9757, 'abkhazia': 9758, 'ordinance': 9759, 'buenos': 9760, 'aires': 9761, 'pearce': 9762, 'madden': 9763, 'bon': 9764, 'affirms': 9765, 'bounces': 9766, 'robs': 9767, 'fullyear': 9768, 'vetoed': 9769, 'mourning': 9770, 'holes': 9771, 'slaying': 9772, 'eskom': 9773, 'triangle': 9774, 'licences': 9775, 'suarez': 9776, 'grounded': 9777, 'cartoon': 9778, 'extremism': 9779, 'courteney': 9780, 'thirdlargest': 9781, 'proves': 9782, 'jenson': 9783, 'shooter': 9784, 'initiates': 9785, 'mateo': 9786, 'leap': 9787, '430': 9788, 'conclusion': 9789, 'kandahar': 9790, 'herbert': 9791, 'corrections': 9792, 'settlements': 9793, 'welch': 9794, 'classified': 9795, 'elder': 9796, 'grab': 9797, 'bury': 9798, 'importing': 9799, 'drum': 9800, 'belongs': 9801, 'shrine': 9802, 'pilgrim': 9803, 'monoxide': 9804, 'exams': 9805, 'outer': 9806, 'underlying': 9807, 'bidder': 9808, 'pipes': 9809, 'mammoth': 9810, 'retreated': 9811, 'partnered': 9812, 'ICT': 9813, 'relieved': 9814, 'davidson': 9815, 'integrate': 9816, 'petitions': 9817, 'pad': 9818, 'LK': 9819, 'clearance': 9820, 'concedes': 9821, 'motivated': 9822, 'liberia': 9823, 'vanderbilt': 9824, 'cherokee': 9825, 'trauma': 9826, 'keegan': 9827, 'perjury': 9828, 'termination': 9829, 'penske': 9830, 'expenditure': 9831, 'skiing': 9832, 'serb': 9833, '830': 9834, 'deadliest': 9835, 'TNA': 9836, 'transmitted': 9837, 'interaction': 9838, 'pools': 9839, 'thrashers': 9840, 'hospice': 9841, 'careers': 9842, 'tackling': 9843, 'patriotic': 9844, 'credentials': 9845, 'autonomous': 9846, 'CIS': 9847, 'labrador': 9848, 'highend': 9849, 'cousins': 9850, 'ignored': 9851, 'jubilee': 9852, 'organising': 9853, '70th': 9854, 'consistent': 9855, 'plain': 9856, 'sunset': 9857, 'benghazi': 9858, 'reversed': 9859, 'highlevel': 9860, 'basket': 9861, 'denny': 9862, 'inspiration': 9863, 'boating': 9864, 'ivan': 9865, 'festivals': 9866, 'displays': 9867, 'achilles': 9868, 'SWAT': 9869, 'propaganda': 9870, 'landlords': 9871, 'MLB': 9872, 'hurting': 9873, 'cartel': 9874, 'raft': 9875, 'stormy': 9876, '42yearold': 9877, 'timber': 9878, '10yearold': 9879, 'joyce': 9880, 'emmanuel': 9881, 'costly': 9882, 'cousin': 9883, 'tesla': 9884, 'buck': 9885, 'supplements': 9886, 'motorcycles': 9887, 'mood': 9888, 'alcoholic': 9889, 'grandson': 9890, 'chattanooga': 9891, 'shutout': 9892, 'politically': 9893, 'erdogan': 9894, 'downgrade': 9895, 'hank': 9896, 'corbett': 9897, 'lounge': 9898, 'supplement': 9899, 'object': 9900, 'edison': 9901, 'asbestos': 9902, 'challengers': 9903, 'noah': 9904, 'pressing': 9905, 'opposing': 9906, 'ravi': 9907, 'rebate': 9908, 'selloff': 9909, 'bremen': 9910, 'consultations': 9911, 'luiz': 9912, 'offence': 9913, 'warrior': 9914, 'porter': 9915, 'excise': 9916, 'saleh': 9917, 'tyre': 9918, 'gadkari': 9919, 'cialis': 9920, 'irrigation': 9921, 'seaside': 9922, 'shakira': 9923, 'klein': 9924, 'cheltenham': 9925, 'dwight': 9926, 'disappearance': 9927, 'missoula': 9928, 'knocking': 9929, 'surpasses': 9930, 'boundary': 9931, 'vita': 9932, 'blade': 9933, 'ISD': 9934, 'bloomington': 9935, 'fractures': 9936, 'outburst': 9937, 'cry': 9938, 'berth': 9939, 'threeyearold': 9940, 'trek': 9941, 'hebron': 9942, 'belief': 9943, 'dresses': 9944, 'rings': 9945, 'subdivision': 9946, 'paramount': 9947, 'oriental': 9948, 'albans': 9949, 'pled': 9950, 'mistress': 9951, 'nepali': 9952, 'spotify': 9953, 'relaunch': 9954, 'qureshi': 9955, 'respected': 9956, 'honeymoon': 9957, 'substitute': 9958, 'pressured': 9959, 'landscape': 9960, 'decreased': 9961, 'arvind': 9962, 'patna': 9963, 'talented': 9964, 'tariff': 9965, '149': 9966, 'closest': 9967, 'influenza': 9968, 'LinkedIn': 9969, 'inflows': 9970, 'backdrop': 9971, 'weston': 9972, 'dismiss': 9973, 'purposes': 9974, 'ignore': 9975, '18000': 9976, 'supplied': 9977, '200910': 9978, 'mercedesbenz': 9979, 'anymore': 9980, 'nightmare': 9981, 'cautiously': 9982, 'stab': 9983, 'deepen': 9984, 'treasuries': 9985, 'patriarch': 9986, 'balcony': 9987, 'cypriot': 9988, 'gupta': 9989, 'assists': 9990, 'SBI': 9991, 'antigay': 9992, 'peterborough': 9993, '117': 9994, 'topless': 9995, 'ortiz': 9996, 'insurgency': 9997, 'flynn': 9998, 'DeGeneres': 9999}\n"
     ]
    }
   ],
   "execution_count": 109
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a name='e4'></a>\n",
    "### Exercise 4: Bag of Words\n",
    "(1p) Here we will create the bag-of-words representation of the sentences. The function will take a single sentence (list of tokens) and return an array of size `vocab_size` with the counts of each word in the vocabulary. The\n",
    "`vocab_size` is calculated as the length of the passed `token_to_id` dictionary. The resulting array should have zeros everywhere but the indices corresponding to the words in the vocabulary where it should have the counts of the words in the sentence. For example, if the sentence is `['fox', 'and', 'deer']` and the vocabulary is `{'fox': 0, 'and': 1, 'deer': 2}`, the resulting array should be `[1, 1, 1]`. If the sentence is `['fox', 'and', 'fox', 'deer']`, the resulting array should be `[2, 1, 1]`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:48:38.870531Z",
     "start_time": "2025-04-20T22:48:38.866480Z"
    }
   },
   "source": [
    "def bag_of_words(sentence, token_to_id):\n",
    "    \"\"\"\n",
    "    Creates a bag-of-words representation of the sentence\n",
    "    Args:\n",
    "        sentence: a list of tokens\n",
    "        token_to_id: a dictionary mapping each word to an index in the vocabulary\n",
    "\n",
    "    Returns:: a numpy array of size vocab_size with the counts of each word in the vocabulary\n",
    "\n",
    "    \"\"\"\n",
    "    vocab_size = len(token_to_id)\n",
    "    bow = np.zeros(vocab_size, dtype=int)\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    # copilot used when writing the code\n",
    "    for token in sentence:\n",
    "        if token in token_to_id:\n",
    "            index = token_to_id[token]\n",
    "            bow[index] += 1\n",
    "    ### YOUR CODE ENDS HERE\n",
    "\n",
    "    return bow"
   ],
   "outputs": [],
   "execution_count": 110
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's see how the function works on a single sentence. The output should be a numpy array of size `vocab_size` with the counts of each word in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:48:39.067607Z",
     "start_time": "2025-04-20T22:48:39.061596Z"
    }
   },
   "source": [
    "print('Tokenized sentence:')\n",
    "print(tokenized_sentences[0])\n",
    "sentence_bow = bag_of_words(tokenized_sentences[0], token_to_id)\n",
    "\n",
    "print('Bag of words:')\n",
    "print(sentence_bow)\n",
    "print('Type of bag of words:')\n",
    "print(type(sentence_bow))\n",
    "print('Shape of bag of words:')\n",
    "print(sentence_bow.shape)\n",
    "print('Non-zero elements in bag of words:')\n",
    "print(np.nonzero(sentence_bow)[0])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized sentence:\n",
      "['LONDON', 'drugmaker', 'AstraZeneca', 'PLC', 'says', 'abandoning', 'plans', 'develop', 'new', 'antiovarian', 'cancer', 'drug', 'also', 'says', 'planned', 'antidepressant', 'underperformed', 'tests']\n",
      "Bag of words:\n",
      "[0 1 0 ... 0 0 0]\n",
      "Type of bag of words:\n",
      "<class 'numpy.ndarray'>\n",
      "Shape of bag of words:\n",
      "(10000,)\n",
      "Non-zero elements in bag of words:\n",
      "[   1   18   94  206  268  435 1273 1505 1633 4485 6118]\n"
     ]
    }
   ],
   "execution_count": 111
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can also check in detail what words and their counts are in the bag-of-words representation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:48:39.263336Z",
     "start_time": "2025-04-20T22:48:39.258739Z"
    }
   },
   "source": [
    "sentence_non_zero_bow = np.nonzero(sentence_bow)[0]\n",
    "print('Non-zero elements in bag of words:')\n",
    "print(sentence_non_zero_bow)\n",
    "for i in sentence_non_zero_bow:\n",
    "    print(vocab[i][0], ':', sentence_bow[i])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-zero elements in bag of words:\n",
      "[   1   18   94  206  268  435 1273 1505 1633 4485 6118]\n",
      "new : 1\n",
      "says : 2\n",
      "plans : 1\n",
      "drug : 1\n",
      "cancer : 1\n",
      "also : 1\n",
      "planned : 1\n",
      "develop : 1\n",
      "tests : 1\n",
      "PLC : 1\n",
      "LONDON : 1\n"
     ]
    }
   ],
   "execution_count": 112
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The following function will apply all the steps we implemented to a single sentence. It returns a bag of words representation that we will use to calculate the similarity between different sentences."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:48:39.446173Z",
     "start_time": "2025-04-20T22:48:39.442939Z"
    }
   },
   "source": [
    "def embed_text(text, clean_fn, tokenize_fn, embed_fn):\n",
    "    cleaned = clean_fn(text)\n",
    "    tokens = tokenize_fn(cleaned)\n",
    "    embedding = embed_fn(tokens)\n",
    "    return embedding"
   ],
   "outputs": [],
   "execution_count": 113
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a name='e5'></a>\n",
    "### Exercise 5: Cosine Similarity between two vectors\n",
    "\n",
    "(1p) Complete the following function that given any two vectors will compute the cosine similarity. If you don't remember the formula for the cosine similarity, revisit the course material. Notice that the function receives numpy arrays and recall that you can express cosine similarity as a dot product. Use numpy functions to write an efficient implementation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:48:39.815117Z",
     "start_time": "2025-04-20T22:48:39.810975Z"
    }
   },
   "source": [
    "def cosine_similarity(vector1, vector2):\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity between two vectors\n",
    "    Args:\n",
    "        vector1: numpy array of the first vector\n",
    "        vector2: numpy array of the second vector\n",
    "\n",
    "    Returns: cosine similarity\n",
    "\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    dot_product = np.dot(vector1, vector2)\n",
    "    # square root of the sum of squares of the vector1\n",
    "    divider = np.sqrt(np.dot(vector1, vector1))*np.sqrt(np.dot(vector2, vector2))\n",
    "    if divider == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return dot_product / divider\n",
    "    ### YOUR CODE ENDS HERE"
   ],
   "outputs": [],
   "execution_count": 114
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:48:40.046599Z",
     "start_time": "2025-04-20T22:48:40.040264Z"
    }
   },
   "source": [
    "cosine_similarity(np.array([0, 1, 2]), np.array([0, 2, 4]))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999998"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 115
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:48:40.066483Z",
     "start_time": "2025-04-20T22:48:40.056341Z"
    }
   },
   "source": [
    "sentences = [\n",
    "    'The quick brown fox jumps over the lazy dog.',\n",
    "    'Some interesting document containin sentences.',\n",
    "    'The quick brown fox jumps over the lazy cat and some other stuff.',\n",
    "    'Fox and deer are not friends.',\n",
    "    'Fox and deer are not friends. But this document is a lot longer than the previous one. We can add sentence by sentence and see how the embeddings change.',\n",
    "]\n",
    "embedded_sentences = [\n",
    "    embed_text(sentence, clean, tokenize, lambda x: bag_of_words(x, token_to_id))\n",
    "    for sentence in sentences\n",
    "]\n",
    "\n",
    "query = 'fox and deer'\n",
    "embedded_query = embed_text(query, clean, tokenize, lambda x: bag_of_words(x, token_to_id))\n",
    "\n",
    "cosine_similarities = [\n",
    "    cosine_similarity(embedded_query, embedded_sentence)\n",
    "    for embedded_sentence in embedded_sentences\n",
    "]\n",
    "print(f'Query: {query}')\n",
    "for sent, cos_sim in zip(sentences, cosine_similarities):\n",
    "    print(f'Cosine Similarity: {cos_sim:.4f} - Sentence: {sent}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: fox and deer\n",
      "Cosine Similarity: 0.3162 - Sentence: The quick brown fox jumps over the lazy dog.\n",
      "Cosine Similarity: 0.0000 - Sentence: Some interesting document containin sentences.\n",
      "Cosine Similarity: 0.3162 - Sentence: The quick brown fox jumps over the lazy cat and some other stuff.\n",
      "Cosine Similarity: 0.8165 - Sentence: Fox and deer are not friends.\n",
      "Cosine Similarity: 0.3651 - Sentence: Fox and deer are not friends. But this document is a lot longer than the previous one. We can add sentence by sentence and see how the embeddings change.\n"
     ]
    }
   ],
   "execution_count": 116
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We will apply the function to the whole dataset. This might take a while, so be patient. The result will be stored in the `sentence_bow` and `compressed_bow` fields of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:48:40.257322Z",
     "start_time": "2025-04-20T22:48:40.253204Z"
    }
   },
   "source": [
    "def bag_of_words_dataset(example):\n",
    "    \"\"\"\n",
    "    Creates a bag-of-words representation of the sentence and compressed sentence in the example from the Dataset\n",
    "    Args:\n",
    "        example: an example from the Dataset\n",
    "\n",
    "    Returns: updated example with 'sentence_bow' and 'compressed_bow' columns\n",
    "\n",
    "    \"\"\"\n",
    "    sentence_tokens = example['sentence_tokens']\n",
    "    compressed_tokens = example['compressed_tokens']\n",
    "\n",
    "    sentence_bow = bag_of_words(sentence_tokens, token_to_id)\n",
    "    compressed_bow = bag_of_words(compressed_tokens, token_to_id)\n",
    "\n",
    "    example['sentence_bow'] = sentence_bow\n",
    "    example['compressed_bow'] = compressed_bow\n",
    "    return example"
   ],
   "outputs": [],
   "execution_count": 117
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The following cell will apply the function to the whole dataset. The result will be stored in the `sentence_bow` and `compressed_bow` fields of the dataset. We will also convert the dataset's fields `sentence_bow` and `compressed_bow` to numpy format for easier manipulation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:49:17.613227Z",
     "start_time": "2025-04-20T22:48:40.444116Z"
    }
   },
   "source": [
    "test_ds = split_ds['test'].map(bag_of_words_dataset)\n",
    "test_ds = test_ds.with_format('np', columns=['sentence_bow', 'compressed_bow'], dtype=float)\n",
    "print(test_ds)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/36000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "73f931042e4645cc95af7ba462a71215"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['set', 'clean_sentence', 'clean_compressed', 'sentence_tokens', 'compressed_tokens', 'sentence_bow', 'compressed_bow'],\n",
      "    num_rows: 36000\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 118
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's check the results. The `sentence_bow` and `compressed_bow` fields should contain the bag-of-words representation of the sentences and compressed sentences, respectively."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:49:17.812551Z",
     "start_time": "2025-04-20T22:49:17.805740Z"
    }
   },
   "source": [
    "print(test_ds[0])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence_bow': array([0., 0., 0., ..., 0., 0., 0.]), 'compressed_bow': array([0., 0., 0., ..., 0., 0., 0.])}\n"
     ]
    }
   ],
   "execution_count": 119
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:49:38.832107Z",
     "start_time": "2025-04-20T22:49:18.166234Z"
    }
   },
   "source": [
    "sentences_bows = test_ds['sentence_bow']\n",
    "print(sentences_bows.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36000, 10000)\n"
     ]
    }
   ],
   "execution_count": 120
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we can start building a retriever based on the bag of words representation. The first step is to calculate the cosine similarity between two vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a name='e6'></a>\n",
    "### Exercise 6: Cosine Similarity between a vector and an array of vectors\n",
    "\n",
    "(2p) The next step in our retrieval system, would be to calculate the proximity of a query to our retrieval corpus (in our case that is all the sentences).\n",
    "\n",
    "Complete the following function to calculate the cosine similarity between a vector (first parameter `vector`, that will usually be the query vector) and all other vectors (second parameter `other_vectors`, that will be the sentence embeddings in our case). Note that the `other_vectors` parameter is a single numpy array of size `N x D`, where $N$ is the number of vectors and $D$ is the dimension of each vector.\n",
    "\n",
    "For maximum efficiency (we will need it) do not use loops. Try to write the implementation with numpy functions. Hint: matrix multiplication can be seen as calculating the dot product between rows and columns of the multiplied matrices."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LgaV2b3fpSOR",
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:49:39.403799Z",
     "start_time": "2025-04-20T22:49:39.396291Z"
    }
   },
   "source": [
    "def cosine_similarity_1_to_n(vector, other_vectors):\n",
    "    \"\"\"\n",
    "    Calculates the cosine similarity between a single vector and other vectors.\n",
    "    Args:\n",
    "        vector: a numpy array representing a vector of D dimensions\n",
    "        other_vectors: a 2D numpy array representing other vectors (of the size NxD, where N is the number of vectors and D is their dimension)\n",
    "\n",
    "    Returns: a 1D numpy array of size N containing the cosine similarity between the vector and all the other vectors\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #### YOUR CODE HERE\n",
    "    #chatGPT Prompt: Can you explain what is this exercise about so I can understand how to do it?\n",
    "    #Formula for cosine similarity\n",
    "    #The nominator being the dot product of the vector with other vectors\n",
    "    dot_products = np.dot(other_vectors, vector)\n",
    "\n",
    "    #The denominator being the product of the norms\n",
    "    norm_vector = np.linalg.norm(vector)\n",
    "    norm_others = np.linalg.norm(other_vectors, axis=1)\n",
    "\n",
    "    #chatGPT suggestion for debugging to avoid division by zero\n",
    "    norms_product = norm_vector * norm_others + 1e-10\n",
    "\n",
    "    #cosine similarity according to the formula\n",
    "    cosine_sim = dot_products / norms_product\n",
    "    return cosine_sim\n",
    "    ### YOUR CODE ENDS HERE"
   ],
   "outputs": [],
   "execution_count": 121
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "irNqAJZLpSOR",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We will use the function to calculate the similarity of all sentences in the dataset to our query."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-21T00:07:55.607568Z",
     "start_time": "2025-04-21T00:07:55.602570Z"
    }
   },
   "source": [
    "query = ('the and is of to')\n",
    "embedded_query = embed_text(query, clean, tokenize, lambda x: bag_of_words(x, token_to_id))"
   ],
   "outputs": [],
   "execution_count": 192
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uD9mVAhYpSOR",
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-21T00:08:02.826653Z",
     "start_time": "2025-04-21T00:07:58.040909Z"
    }
   },
   "source": [
    "query_similarity = cosine_similarity_1_to_n(embedded_query, sentences_bows)\n",
    "print(query_similarity.shape)\n",
    "print(query_similarity[:10])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36000,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "execution_count": 193
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "_l3erVTNpSOR",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The following cell will select the most similar sentence."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0wWa4AWHpSOR",
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-21T00:08:06.026684Z",
     "start_time": "2025-04-21T00:08:06.015381Z"
    }
   },
   "source": [
    "most_similar = int(np.argmax(query_similarity))\n",
    "print(most_similar)\n",
    "print(query_similarity[most_similar])\n",
    "print(split_ds['test'][most_similar]['set'][0])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.0\n",
      "Kim Kardashian, the reality TV star, was ``flour bombed'' on the red carpet, after a woman threw powder over her.\n"
     ]
    }
   ],
   "execution_count": 194
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "fpdJHFD1pSOR",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The following function will return the indices of the top-k elements in the array."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QFUNI9elpSOS",
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T23:57:07.854011Z",
     "start_time": "2025-04-20T23:57:07.849824Z"
    }
   },
   "source": [
    "def top_k_indices(array, k, sorted=True):\n",
    "    \"\"\"\n",
    "    Returns top-k indices from the 1D array. If `sorted` is `True` the returned indices are sorted in the descending order\n",
    "    Args:\n",
    "        array: a 1D numpy array\n",
    "        k: a number of top indices to return\n",
    "        sorted: if True, the returned indices are sorted in descending order\n",
    "\n",
    "    Returns: a 1D array containing top-k indices\n",
    "\n",
    "    \"\"\"\n",
    "    top_k = np.argpartition(array, -k)[-k:]\n",
    "    if sorted:\n",
    "        selected = array[top_k]\n",
    "        sorted_selected = (-selected).argsort()\n",
    "        top_k = top_k[sorted_selected]\n",
    "    return top_k"
   ],
   "outputs": [],
   "execution_count": 182
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nY8vvJdepSOS",
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-21T00:08:22.041306Z",
     "start_time": "2025-04-21T00:08:22.033778Z"
    }
   },
   "source": [
    "top_indices = top_k_indices(query_similarity, k=10).tolist()\n",
    "for idx in top_indices:\n",
    "    print(split_ds['test'][idx]['set'][0])\n",
    "    print(f'similarity: {query_similarity[idx]}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manila, Philippines - Following a similar move by the Philippines, China pulled out its fishing boats from Panatag Shoal last Sunday due to ``inclement'' weather.\n",
      "similarity: 0.0\n",
      "Galatasaray have signed Uruguay goalkeeper Fernando Muslera from Lazio in a five-year deal, the Turkish club said today.\n",
      "similarity: 0.0\n",
      "A man was arrested this morning, suspected of pointing a revolver at a woman's head at an Ypsilanti home, where the two were socializing with another man and woman.\n",
      "similarity: 0.0\n",
      "'Riddick', the next installment in the 'Pitch Black' series, is now official.\n",
      "similarity: 0.0\n",
      "As she prepares to launch her cosmetic range K for black skin, soul diva Beverley Knight tells us why she thinks the beauty industry is still leaving black women behind...\n",
      "similarity: 0.0\n",
      "American rapper Jay-Z wants to have yoga lessons with Coldplay frontman Chris Martin, because he is jealous of Martin's dance moves.\n",
      "similarity: 0.0\n",
      "An Indian woman student from Andhra Pradesh was killed in the US by unidentified miscreants, the student's family said Tuesday.\n",
      "similarity: 0.0\n",
      "April fools day is a tradition or custom celebrated Every first day of april.It was originated from the julian calendar when Europe switch it to the gregorian in the 1500s which changed New year's Day from late march to january 1 and created an easy oppurtunity to play aprank on the forgetful.\n",
      "similarity: 0.0\n",
      "The Silver Creek Village Board is feeling the reality of the ``you have to spend money to make money'' adage, deciding Monday to spend $7,600 to apply for grants to improve the village.\n",
      "similarity: 0.0\n",
      "But it's official -- former UVa standout and Golden Spikes Award finalist Danny Hultzen has signed with the Mariners and will not be returning to Virginia to bring us back to the promised land known as Omaha.\n",
      "similarity: 0.0\n"
     ]
    }
   ],
   "execution_count": 195
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "BuRI2JzQpSOS",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a name='e7'></a>\n",
    "### Exercise 7: Analyzing and improving BOW search results\n",
    "\n",
    "Experiment with different queries (taking into account the nature of the dataset and your insights from the analysis so far).\n",
    "Answer the following questions:\n",
    "- (5p) Does the search perform well? When does it fail? Discuss several examples that are we get an expected but also unexpected results (find at least 3 from each category). Provide reasons for the good/bad result in each case (e.g. is there some error in the data, is there some linguistic phenomenon that we don't capture, is something wrong with our modeling with average embeddings, ...)\n",
    "- (5p) If you see problems with search, how could you improve your implementation? Change the functions above, if you think there is room for improvement. Describe your changes and how they made the search better or (in case you made no changes) explain what made the search robust enough to work well."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sEQKHAvcpSOS",
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:49:45.273586Z",
     "start_time": "2025-04-20T22:49:45.268128Z"
    }
   },
   "source": [
    "#### YOUR CODE HERE\n",
    "#Yes the initial query contains word 'and' The fact that the most similar results we got contained fox multiple times 'fox' or 'deer' means that the stop-words cleaning function worked well and did not take the word 'the' included in the initial query into addition.\n",
    "\n",
    "#At the beggining our result indeed included sentence with multiple 'the' but after quick clean it started to match sentences excluding stop-words.\n",
    "#We tested multiple queries like 'Artificial Intelligence at the park' to include some filler words and none of the matches included AI - possibly because its old newspapers when the topic was not that 'hot'.\n",
    "\n",
    "#To test if the function does care about word order we tested two queries 1)poachers killed another rhino (resulting:0.6324555320136759) and 2)killed rhino another poachers (resulting:0.6324555320136759) and since the similarity turned to be exactly the same our function does not care about order of the words.\n",
    "\n",
    "#Another thing worth mentioning is the fact that multiple sentences including the word 'park' twice had different similarity - that might be caused because they include different number of filler words do the similarity differs. example would be, for the query 'park' sentence 'park park I love park' has bigger similarity than 'park park I love park so so much'\n",
    "\n",
    "#We also tested query: 'On Saturday, poachers killed another rhino at Kaziranga National Park and chopped off its horn.' for the sentence we knew existed to check if the similarity is extremely high and the result was 0.99999 and the output was the exact same sentence as the most similar one.\n",
    "\n",
    "#Lastly we decided to check if the system finds synonyms using the query \"car\" and k=1000 (so we can check a wide range of sentences. the lowest similarity had a very log sentence that included the word car but that means that our function does not take into addition synonyms like 'vehicle' which could be a significant improvement.\n",
    "\n",
    "### YOUR CODE ENDS HERE"
   ],
   "outputs": [],
   "execution_count": 127
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eiIGTfq6eFI5",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "// your comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Term Frequency - Inverse Document Frequency (TF-IDF)\n",
    "\n",
    "In this section we will implement the TF-IDF algorithm. While BOW is a simple way to represent the documents, it has some limitations. For example, it does not take into account the importance of each word in the document. TF-IDF representation takes into account the frequency of each word in the document and the frequency of the word in the whole dataset. It is a widely used technique in information retrieval and text mining. Refer to the lecture slides for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a name='e8'></a>\n",
    "### Exercise 8: Inverse Document Frequency (IDF)\n",
    "(5p) In this exercise, you will implement the TF-IDF algorithm. First, calculate Inverse Document Frequency (IDF) for each word in the vocabulary. Intuitively, it is a measure of how informative a word is based on the whole dataset. Consult the lecture slides for the details. The IDF is calculated as follows:\n",
    "$$\n",
    "IDF(t) = log_{10}(N/df(t))$$\n",
    "where $N$ is the total number of documents (sentences) in the dataset and $df(t)$ is the number of documents containing the word $t$.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-21T00:12:31.480503Z",
     "start_time": "2025-04-21T00:12:30.609050Z"
    }
   },
   "source": [
    "def calculate_idf(bows):\n",
    "    \"\"\"\n",
    "    Calculates the IDF for each word in the vocabulary\n",
    "    Args:\n",
    "        bows: numpty array of size (N x D) where N is the number of documents and D is the vocabulary size\n",
    "\n",
    "    Returns: a numpy array of size D with IDF values for each token\n",
    "    \"\"\"\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    " # copilot used when writing the code\n",
    "    n = bows.shape[0]\n",
    "    dft = np.sum(bows > 0, axis=0)\n",
    "    #changed that line because of division by zero being possible\n",
    "    #idf = np.where(dft > 0, np.log10(n / dft), 0)\n",
    "    idf = np.log10(n / (dft + 1))\n",
    "    return idf\n",
    "\n",
    "\n",
    "    ### YOUR CODE ENDS HERE\n",
    "\n",
    "idf = calculate_idf(sentences_bows)"
   ],
   "outputs": [],
   "execution_count": 197
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a name='e9'></a>\n",
    "### Exercise 9: TF-IDF\n",
    "- (5p) Calculate TF-IDF on the `test` subset of the dataset.\n",
    "- (5p) Analyze the search results based on your implemented TF-IDF. Does the search perform well? When does it fail? Discuss several examples that are we get an expected but also unexpected results (find at least 3 from each category). Provide reasons for the good/bad result in each case (e.g. is there some error in the data, is there some linguistic phenomenon that we don't capture, is something wrong with our modeling with average embeddings, ...)\n",
    "- (5p) Compare the results with the ones you got with the bag-of-words representation. Discuss the differences and similarities. Do you think TF-IDF is a better representation for this task? Why or why not? Provide examples to support your arguments.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-21T00:15:35.139240Z",
     "start_time": "2025-04-21T00:15:03.193919Z"
    }
   },
   "source": [
    "### YOUR CODE HERE\n",
    "# copilot used when writing the code\n",
    "def calculate_tfidf(bows, idf):\n",
    "    \"\"\"\n",
    "    Calculates the TF-IDF for each word in the vocabulary\n",
    "    Args:\n",
    "        bows: numpy array of size (N x D) where N is the number of documents and D is the vocabulary size\n",
    "        idf: a numpy array of size D with IDF values for each token\n",
    "\n",
    "    returns: a numpy array of size (N x D) with TF-IDF values for each token in each document\n",
    "    \"\"\"\n",
    "    tf = bows.copy()\n",
    "    #This line was debugged by ChatGPT to avoid deletion by zero\n",
    "    #tf_weighted = np.where(tf > 0, 1 + np.log10(tf), 0)\n",
    "    tf_safe = np.where(tf > 0, tf, 1)  # Replace zeros with 1 just for safe log\n",
    "    tf_weighted = np.where(tf > 0, 1 + np.log10(tf_safe), 0)\n",
    "    weights = tf_weighted * idf\n",
    "    return weights\n",
    "\n",
    "results = calculate_tfidf(sentences_bows, idf)\n",
    "# print head of the results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### YOUR CODE ENDS HERE\n",
    "\n",
    "### YOU CAN ADD MORE CELLS"
   ],
   "outputs": [],
   "execution_count": 199
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "// your comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4. Word Embeddings\n",
    "\n",
    "In this section you will load the pre-trained word embeddings model - Glove. You can read more about it [here](https://aclanthology.org/D14-1162/) ([https://aclanthology.org/D14-1162/](https://aclanthology.org/D14-1162/)). The embeddings are trained on a large corpus of text and are available in different dimensions. We will start with the dimension of 100, but later you will be asked to experiment with other dimensions.\n",
    "Gensim library maintains a storage containing some pre-trained models. You can read more about it [here](https://github.com/piskvorky/gensim-data) ([https://github.com/piskvorky/gensim-data](https://github.com/piskvorky/gensim-data)). Be sure to read the README of this repository.\n",
    "\n",
    "Let's first load the info of what models are available."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-21T00:16:47.151263Z",
     "start_time": "2025-04-21T00:16:47.042743Z"
    }
   },
   "source": [
    "import json\n",
    "import gensim.downloader as api\n",
    "\n",
    "info = api.info()  # show info about available models/datasets\n",
    "print(json.dumps(info['models'], indent=2))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"fasttext-wiki-news-subwords-300\": {\n",
      "    \"num_records\": 999999,\n",
      "    \"file_size\": 1005007116,\n",
      "    \"base_dataset\": \"Wikipedia 2017, UMBC webbase corpus and statmt.org news dataset (16B tokens)\",\n",
      "    \"reader_code\": \"https://github.com/RaRe-Technologies/gensim-data/releases/download/fasttext-wiki-news-subwords-300/__init__.py\",\n",
      "    \"license\": \"https://creativecommons.org/licenses/by-sa/3.0/\",\n",
      "    \"parameters\": {\n",
      "      \"dimension\": 300\n",
      "    },\n",
      "    \"description\": \"1 million word vectors trained on Wikipedia 2017, UMBC webbase corpus and statmt.org news dataset (16B tokens).\",\n",
      "    \"read_more\": [\n",
      "      \"https://fasttext.cc/docs/en/english-vectors.html\",\n",
      "      \"https://arxiv.org/abs/1712.09405\",\n",
      "      \"https://arxiv.org/abs/1607.01759\"\n",
      "    ],\n",
      "    \"checksum\": \"de2bb3a20c46ce65c9c131e1ad9a77af\",\n",
      "    \"file_name\": \"fasttext-wiki-news-subwords-300.gz\",\n",
      "    \"parts\": 1\n",
      "  },\n",
      "  \"conceptnet-numberbatch-17-06-300\": {\n",
      "    \"num_records\": 1917247,\n",
      "    \"file_size\": 1225497562,\n",
      "    \"base_dataset\": \"ConceptNet, word2vec, GloVe, and OpenSubtitles 2016\",\n",
      "    \"reader_code\": \"https://github.com/RaRe-Technologies/gensim-data/releases/download/conceptnet-numberbatch-17-06-300/__init__.py\",\n",
      "    \"license\": \"https://github.com/commonsense/conceptnet-numberbatch/blob/master/LICENSE.txt\",\n",
      "    \"parameters\": {\n",
      "      \"dimension\": 300\n",
      "    },\n",
      "    \"description\": \"ConceptNet Numberbatch consists of state-of-the-art semantic vectors (also known as word embeddings) that can be used directly as a representation of word meanings or as a starting point for further machine learning. ConceptNet Numberbatch is part of the ConceptNet open data project. ConceptNet provides lots of ways to compute with word meanings, one of which is word embeddings. ConceptNet Numberbatch is a snapshot of just the word embeddings. It is built using an ensemble that combines data from ConceptNet, word2vec, GloVe, and OpenSubtitles 2016, using a variation on retrofitting.\",\n",
      "    \"read_more\": [\n",
      "      \"http://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14972\",\n",
      "      \"https://github.com/commonsense/conceptnet-numberbatch\",\n",
      "      \"http://conceptnet.io/\"\n",
      "    ],\n",
      "    \"checksum\": \"fd642d457adcd0ea94da0cd21b150847\",\n",
      "    \"file_name\": \"conceptnet-numberbatch-17-06-300.gz\",\n",
      "    \"parts\": 1\n",
      "  },\n",
      "  \"word2vec-ruscorpora-300\": {\n",
      "    \"num_records\": 184973,\n",
      "    \"file_size\": 208427381,\n",
      "    \"base_dataset\": \"Russian National Corpus (about 250M words)\",\n",
      "    \"reader_code\": \"https://github.com/RaRe-Technologies/gensim-data/releases/download/word2vec-ruscorpora-300/__init__.py\",\n",
      "    \"license\": \"https://creativecommons.org/licenses/by/4.0/deed.en\",\n",
      "    \"parameters\": {\n",
      "      \"dimension\": 300,\n",
      "      \"window_size\": 10\n",
      "    },\n",
      "    \"description\": \"Word2vec Continuous Skipgram vectors trained on full Russian National Corpus (about 250M words). The model contains 185K words.\",\n",
      "    \"preprocessing\": \"The corpus was lemmatized and tagged with Universal PoS\",\n",
      "    \"read_more\": [\n",
      "      \"https://www.academia.edu/24306935/WebVectors_a_Toolkit_for_Building_Web_Interfaces_for_Vector_Semantic_Models\",\n",
      "      \"http://rusvectores.org/en/\",\n",
      "      \"https://github.com/RaRe-Technologies/gensim-data/issues/3\"\n",
      "    ],\n",
      "    \"checksum\": \"9bdebdc8ae6d17d20839dd9b5af10bc4\",\n",
      "    \"file_name\": \"word2vec-ruscorpora-300.gz\",\n",
      "    \"parts\": 1\n",
      "  },\n",
      "  \"word2vec-google-news-300\": {\n",
      "    \"num_records\": 3000000,\n",
      "    \"file_size\": 1743563840,\n",
      "    \"base_dataset\": \"Google News (about 100 billion words)\",\n",
      "    \"reader_code\": \"https://github.com/RaRe-Technologies/gensim-data/releases/download/word2vec-google-news-300/__init__.py\",\n",
      "    \"license\": \"not found\",\n",
      "    \"parameters\": {\n",
      "      \"dimension\": 300\n",
      "    },\n",
      "    \"description\": \"Pre-trained vectors trained on a part of the Google News dataset (about 100 billion words). The model contains 300-dimensional vectors for 3 million words and phrases. The phrases were obtained using a simple data-driven approach described in 'Distributed Representations of Words and Phrases and their Compositionality' (https://code.google.com/archive/p/word2vec/).\",\n",
      "    \"read_more\": [\n",
      "      \"https://code.google.com/archive/p/word2vec/\",\n",
      "      \"https://arxiv.org/abs/1301.3781\",\n",
      "      \"https://arxiv.org/abs/1310.4546\",\n",
      "      \"https://www.microsoft.com/en-us/research/publication/linguistic-regularities-in-continuous-space-word-representations/?from=http%3A%2F%2Fresearch.microsoft.com%2Fpubs%2F189726%2Frvecs.pdf\"\n",
      "    ],\n",
      "    \"checksum\": \"a5e5354d40acb95f9ec66d5977d140ef\",\n",
      "    \"file_name\": \"word2vec-google-news-300.gz\",\n",
      "    \"parts\": 1\n",
      "  },\n",
      "  \"glove-wiki-gigaword-50\": {\n",
      "    \"num_records\": 400000,\n",
      "    \"file_size\": 69182535,\n",
      "    \"base_dataset\": \"Wikipedia 2014 + Gigaword 5 (6B tokens, uncased)\",\n",
      "    \"reader_code\": \"https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-wiki-gigaword-50/__init__.py\",\n",
      "    \"license\": \"http://opendatacommons.org/licenses/pddl/\",\n",
      "    \"parameters\": {\n",
      "      \"dimension\": 50\n",
      "    },\n",
      "    \"description\": \"Pre-trained vectors based on Wikipedia 2014 + Gigaword, 5.6B tokens, 400K vocab, uncased (https://nlp.stanford.edu/projects/glove/).\",\n",
      "    \"preprocessing\": \"Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-wiki-gigaword-50.txt`.\",\n",
      "    \"read_more\": [\n",
      "      \"https://nlp.stanford.edu/projects/glove/\",\n",
      "      \"https://nlp.stanford.edu/pubs/glove.pdf\"\n",
      "    ],\n",
      "    \"checksum\": \"c289bc5d7f2f02c6dc9f2f9b67641813\",\n",
      "    \"file_name\": \"glove-wiki-gigaword-50.gz\",\n",
      "    \"parts\": 1\n",
      "  },\n",
      "  \"glove-wiki-gigaword-100\": {\n",
      "    \"num_records\": 400000,\n",
      "    \"file_size\": 134300434,\n",
      "    \"base_dataset\": \"Wikipedia 2014 + Gigaword 5 (6B tokens, uncased)\",\n",
      "    \"reader_code\": \"https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-wiki-gigaword-100/__init__.py\",\n",
      "    \"license\": \"http://opendatacommons.org/licenses/pddl/\",\n",
      "    \"parameters\": {\n",
      "      \"dimension\": 100\n",
      "    },\n",
      "    \"description\": \"Pre-trained vectors based on Wikipedia 2014 + Gigaword 5.6B tokens, 400K vocab, uncased (https://nlp.stanford.edu/projects/glove/).\",\n",
      "    \"preprocessing\": \"Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-wiki-gigaword-100.txt`.\",\n",
      "    \"read_more\": [\n",
      "      \"https://nlp.stanford.edu/projects/glove/\",\n",
      "      \"https://nlp.stanford.edu/pubs/glove.pdf\"\n",
      "    ],\n",
      "    \"checksum\": \"40ec481866001177b8cd4cb0df92924f\",\n",
      "    \"file_name\": \"glove-wiki-gigaword-100.gz\",\n",
      "    \"parts\": 1\n",
      "  },\n",
      "  \"glove-wiki-gigaword-200\": {\n",
      "    \"num_records\": 400000,\n",
      "    \"file_size\": 264336934,\n",
      "    \"base_dataset\": \"Wikipedia 2014 + Gigaword 5 (6B tokens, uncased)\",\n",
      "    \"reader_code\": \"https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-wiki-gigaword-200/__init__.py\",\n",
      "    \"license\": \"http://opendatacommons.org/licenses/pddl/\",\n",
      "    \"parameters\": {\n",
      "      \"dimension\": 200\n",
      "    },\n",
      "    \"description\": \"Pre-trained vectors based on Wikipedia 2014 + Gigaword, 5.6B tokens, 400K vocab, uncased (https://nlp.stanford.edu/projects/glove/).\",\n",
      "    \"preprocessing\": \"Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-wiki-gigaword-200.txt`.\",\n",
      "    \"read_more\": [\n",
      "      \"https://nlp.stanford.edu/projects/glove/\",\n",
      "      \"https://nlp.stanford.edu/pubs/glove.pdf\"\n",
      "    ],\n",
      "    \"checksum\": \"59652db361b7a87ee73834a6c391dfc1\",\n",
      "    \"file_name\": \"glove-wiki-gigaword-200.gz\",\n",
      "    \"parts\": 1\n",
      "  },\n",
      "  \"glove-wiki-gigaword-300\": {\n",
      "    \"num_records\": 400000,\n",
      "    \"file_size\": 394362229,\n",
      "    \"base_dataset\": \"Wikipedia 2014 + Gigaword 5 (6B tokens, uncased)\",\n",
      "    \"reader_code\": \"https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-wiki-gigaword-300/__init__.py\",\n",
      "    \"license\": \"http://opendatacommons.org/licenses/pddl/\",\n",
      "    \"parameters\": {\n",
      "      \"dimension\": 300\n",
      "    },\n",
      "    \"description\": \"Pre-trained vectors based on Wikipedia 2014 + Gigaword, 5.6B tokens, 400K vocab, uncased (https://nlp.stanford.edu/projects/glove/).\",\n",
      "    \"preprocessing\": \"Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-wiki-gigaword-300.txt`.\",\n",
      "    \"read_more\": [\n",
      "      \"https://nlp.stanford.edu/projects/glove/\",\n",
      "      \"https://nlp.stanford.edu/pubs/glove.pdf\"\n",
      "    ],\n",
      "    \"checksum\": \"29e9329ac2241937d55b852e8284e89b\",\n",
      "    \"file_name\": \"glove-wiki-gigaword-300.gz\",\n",
      "    \"parts\": 1\n",
      "  },\n",
      "  \"glove-twitter-25\": {\n",
      "    \"num_records\": 1193514,\n",
      "    \"file_size\": 109885004,\n",
      "    \"base_dataset\": \"Twitter (2B tweets, 27B tokens, 1.2M vocab, uncased)\",\n",
      "    \"reader_code\": \"https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-twitter-25/__init__.py\",\n",
      "    \"license\": \"http://opendatacommons.org/licenses/pddl/\",\n",
      "    \"parameters\": {\n",
      "      \"dimension\": 25\n",
      "    },\n",
      "    \"description\": \"Pre-trained vectors based on 2B tweets, 27B tokens, 1.2M vocab, uncased (https://nlp.stanford.edu/projects/glove/).\",\n",
      "    \"preprocessing\": \"Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-twitter-25.txt`.\",\n",
      "    \"read_more\": [\n",
      "      \"https://nlp.stanford.edu/projects/glove/\",\n",
      "      \"https://nlp.stanford.edu/pubs/glove.pdf\"\n",
      "    ],\n",
      "    \"checksum\": \"50db0211d7e7a2dcd362c6b774762793\",\n",
      "    \"file_name\": \"glove-twitter-25.gz\",\n",
      "    \"parts\": 1\n",
      "  },\n",
      "  \"glove-twitter-50\": {\n",
      "    \"num_records\": 1193514,\n",
      "    \"file_size\": 209216938,\n",
      "    \"base_dataset\": \"Twitter (2B tweets, 27B tokens, 1.2M vocab, uncased)\",\n",
      "    \"reader_code\": \"https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-twitter-50/__init__.py\",\n",
      "    \"license\": \"http://opendatacommons.org/licenses/pddl/\",\n",
      "    \"parameters\": {\n",
      "      \"dimension\": 50\n",
      "    },\n",
      "    \"description\": \"Pre-trained vectors based on 2B tweets, 27B tokens, 1.2M vocab, uncased (https://nlp.stanford.edu/projects/glove/)\",\n",
      "    \"preprocessing\": \"Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-twitter-50.txt`.\",\n",
      "    \"read_more\": [\n",
      "      \"https://nlp.stanford.edu/projects/glove/\",\n",
      "      \"https://nlp.stanford.edu/pubs/glove.pdf\"\n",
      "    ],\n",
      "    \"checksum\": \"c168f18641f8c8a00fe30984c4799b2b\",\n",
      "    \"file_name\": \"glove-twitter-50.gz\",\n",
      "    \"parts\": 1\n",
      "  },\n",
      "  \"glove-twitter-100\": {\n",
      "    \"num_records\": 1193514,\n",
      "    \"file_size\": 405932991,\n",
      "    \"base_dataset\": \"Twitter (2B tweets, 27B tokens, 1.2M vocab, uncased)\",\n",
      "    \"reader_code\": \"https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-twitter-100/__init__.py\",\n",
      "    \"license\": \"http://opendatacommons.org/licenses/pddl/\",\n",
      "    \"parameters\": {\n",
      "      \"dimension\": 100\n",
      "    },\n",
      "    \"description\": \"Pre-trained vectors based on  2B tweets, 27B tokens, 1.2M vocab, uncased (https://nlp.stanford.edu/projects/glove/)\",\n",
      "    \"preprocessing\": \"Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-twitter-100.txt`.\",\n",
      "    \"read_more\": [\n",
      "      \"https://nlp.stanford.edu/projects/glove/\",\n",
      "      \"https://nlp.stanford.edu/pubs/glove.pdf\"\n",
      "    ],\n",
      "    \"checksum\": \"b04f7bed38756d64cf55b58ce7e97b15\",\n",
      "    \"file_name\": \"glove-twitter-100.gz\",\n",
      "    \"parts\": 1\n",
      "  },\n",
      "  \"glove-twitter-200\": {\n",
      "    \"num_records\": 1193514,\n",
      "    \"file_size\": 795373100,\n",
      "    \"base_dataset\": \"Twitter (2B tweets, 27B tokens, 1.2M vocab, uncased)\",\n",
      "    \"reader_code\": \"https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-twitter-200/__init__.py\",\n",
      "    \"license\": \"http://opendatacommons.org/licenses/pddl/\",\n",
      "    \"parameters\": {\n",
      "      \"dimension\": 200\n",
      "    },\n",
      "    \"description\": \"Pre-trained vectors based on 2B tweets, 27B tokens, 1.2M vocab, uncased (https://nlp.stanford.edu/projects/glove/).\",\n",
      "    \"preprocessing\": \"Converted to w2v format with `python -m gensim.scripts.glove2word2vec -i <fname> -o glove-twitter-200.txt`.\",\n",
      "    \"read_more\": [\n",
      "      \"https://nlp.stanford.edu/projects/glove/\",\n",
      "      \"https://nlp.stanford.edu/pubs/glove.pdf\"\n",
      "    ],\n",
      "    \"checksum\": \"e52e8392d1860b95d5308a525817d8f9\",\n",
      "    \"file_name\": \"glove-twitter-200.gz\",\n",
      "    \"parts\": 1\n",
      "  },\n",
      "  \"__testing_word2vec-matrix-synopsis\": {\n",
      "    \"description\": \"[THIS IS ONLY FOR TESTING] Word vecrors of the movie matrix.\",\n",
      "    \"parameters\": {\n",
      "      \"dimensions\": 50\n",
      "    },\n",
      "    \"preprocessing\": \"Converted to w2v using a preprocessed corpus. Converted to w2v format with `python3.5 -m gensim.models.word2vec -train <input_filename> -iter 50 -output <output_filename>`.\",\n",
      "    \"read_more\": [],\n",
      "    \"checksum\": \"534dcb8b56a360977a269b7bfc62d124\",\n",
      "    \"file_name\": \"__testing_word2vec-matrix-synopsis.gz\",\n",
      "    \"parts\": 1\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 200
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-04-21T00:16:57.345709Z"
    }
   },
   "source": [
    "glove_model = api.load(\"glove-wiki-gigaword-100\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can use the loaded model's `key_to_index` attribute to retrieve the whole vocabulary (aka for how many words we learned embeddings for)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:50:50.608371Z",
     "start_time": "2025-04-20T22:50:50.587432Z"
    }
   },
   "source": [
    "vocab = list(glove_model.key_to_index)\n",
    "print(len(vocab))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n"
     ]
    }
   ],
   "execution_count": 132
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's explore a bit further the embeddings. In the following cells, the embedding of a single word is returned. Double-check the dimensions (as sanity check). This is like inspecting the `W` matrix (weights) that we discussed in the lecture."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:50:50.824583Z",
     "start_time": "2025-04-20T22:50:50.813031Z"
    }
   },
   "source": [
    "# vector of a particular model. note that it is 100 dimensional as specified.\n",
    "glove_model['what']"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.5180e-01,  3.8409e-01,  8.9340e-01, -4.2421e-01, -9.2161e-01,\n",
       "        3.7988e-02, -3.2026e-01,  3.4119e-03,  2.2101e-01, -2.2045e-01,\n",
       "        1.6661e-01,  2.1956e-01,  2.5325e-01, -2.9267e-01,  1.0171e-01,\n",
       "       -7.5491e-02, -6.0406e-02,  2.8194e-01, -5.8519e-01,  4.8271e-01,\n",
       "        1.7504e-02, -1.2086e-01, -1.0990e-01, -6.9554e-01,  1.5600e-01,\n",
       "        7.0558e-02, -1.5058e-01, -8.1811e-01, -1.8535e-01, -3.6863e-01,\n",
       "        3.1650e-02,  7.6616e-01,  8.4041e-02,  2.6928e-03, -2.7440e-01,\n",
       "        2.1815e-01, -3.5157e-02,  3.2569e-01,  1.0032e-01, -6.0932e-01,\n",
       "       -7.0316e-01,  1.8299e-01,  3.3134e-01, -1.2416e-01, -9.0542e-01,\n",
       "       -3.9157e-02,  4.4719e-01, -5.7338e-01, -4.0172e-01, -8.2234e-01,\n",
       "        5.5740e-01,  1.5101e-01,  2.4598e-01,  1.0113e+00, -4.6626e-01,\n",
       "       -2.7133e+00,  4.3273e-01, -1.6314e-01,  1.5828e+00,  5.5081e-01,\n",
       "       -2.4738e-01,  1.4184e+00, -1.6867e-02, -1.9368e-01,  1.0090e+00,\n",
       "       -5.9864e-02,  9.1853e-01,  4.3022e-01, -2.0624e-01,  7.6127e-02,\n",
       "        2.1595e-01, -2.6834e-01, -3.3342e-01, -3.7151e-01,  4.5197e-01,\n",
       "       -8.2460e-02,  3.2984e-01, -5.7376e-01, -1.3042e+00,  2.7121e-01,\n",
       "        6.6277e-01, -7.9626e-02, -7.9167e-01, -5.3662e-03, -1.7916e+00,\n",
       "       -3.3298e-01, -3.0698e-01, -3.3980e-01, -5.5618e-01, -6.9471e-01,\n",
       "        2.7427e-01, -2.1898e-01, -2.6714e-01,  2.2561e-03, -5.0178e-01,\n",
       "       -3.2775e-01, -4.5670e-01, -2.7123e-01,  2.2157e-01,  9.2112e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 133
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Gensim objects offers different methods to easily run very common tasks. For example, there are different functions to find the most similar words.\n",
    "\n",
    "Check the documentation on how [`most_similar`](https://tedboy.github.io/nlps/generated/generated/gensim.models.Word2Vec.most_similar.html) and [`similar_by_word`](https://tedboy.github.io/nlps/generated/generated/gensim.models.Word2Vec.similar_by_word.html) can be used."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:50:51.364003Z",
     "start_time": "2025-04-20T22:50:51.189728Z"
    }
   },
   "source": [
    "# most similar words to a given word\n",
    "print(glove_model.most_similar('what', topn=10))\n",
    "\n",
    "# also u can use\n",
    "print(glove_model.similar_by_word('miss', topn=5))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('how', 0.9303215742111206), ('why', 0.9196363091468811), ('fact', 0.906943678855896), ('know', 0.8876389265060425), ('that', 0.8810365796089172), ('think', 0.8772969841957092), ('so', 0.8753098249435425), ('even', 0.8751895427703857), ('something', 0.874744176864624), ('if', 0.8702542781829834)]\n",
      "[('play', 0.6266524791717529), ('missed', 0.608065128326416), ('she', 0.596325695514679), ('chance', 0.5839369297027588), ('tournament', 0.572258710861206)]\n"
     ]
    }
   ],
   "execution_count": 134
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:50:51.390493Z",
     "start_time": "2025-04-20T22:50:51.374426Z"
    }
   },
   "source": [
    "print(glove_model.most_similar('why', topn=10))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('know', 0.944094181060791), ('what', 0.9196362495422363), ('think', 0.9086559414863586), ('how', 0.9020735621452332), ('tell', 0.8923122882843018), (\"n't\", 0.8890628814697266), ('sure', 0.8870969414710999), ('thought', 0.8747684955596924), ('believe', 0.8745115399360657), ('say', 0.8730075359344482)]\n"
     ]
    }
   ],
   "execution_count": 135
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:50:51.607396Z",
     "start_time": "2025-04-20T22:50:51.586984Z"
    }
   },
   "source": [
    "print(glove_model.similar_by_word('who', topn=5))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('whom', 0.8642492890357971), ('he', 0.8201969861984253), ('whose', 0.8143677711486816), ('had', 0.8035843968391418), ('others', 0.7708418965339661)]\n"
     ]
    }
   ],
   "execution_count": 136
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can now compare our implementation with the one in the pre-trained model and confirm what we already expected."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:50:51.793881Z",
     "start_time": "2025-04-20T22:50:51.787356Z"
    }
   },
   "source": [
    "# simalarity between two words\n",
    "word1 = 'alive'\n",
    "word2 = 'biology'\n",
    "print(glove_model.similarity(word1, word2))\n",
    "print(cosine_similarity(glove_model[word1], glove_model[word2]))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15712576\n",
      "0.15712577\n"
     ]
    }
   ],
   "execution_count": 137
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:50:51.978269Z",
     "start_time": "2025-04-20T22:50:51.972323Z"
    }
   },
   "source": [
    "# simalarity between two words. similar words\n",
    "word1 = 'alive'\n",
    "word2 = 'life'\n",
    "print(glove_model.similarity(word1, word2))\n",
    "print(cosine_similarity(glove_model[word1], glove_model[word2]))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6400605\n",
      "0.6400605\n"
     ]
    }
   ],
   "execution_count": 138
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:50:52.173801Z",
     "start_time": "2025-04-20T22:50:52.169187Z"
    }
   },
   "source": [
    "# simalarity between two words. dissimilar words\n",
    "word1 = 'alive'\n",
    "word2 = 'dead'\n",
    "print(glove_model.similarity(word1, word2))\n",
    "print(cosine_similarity(glove_model[word1], glove_model[word2]))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7103517\n",
      "0.71035177\n"
     ]
    }
   ],
   "execution_count": 139
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:50:52.356815Z",
     "start_time": "2025-04-20T22:50:52.352512Z"
    }
   },
   "source": [
    "# simalarity between two words. unrelated words\n",
    "word1 = 'alive'\n",
    "word2 = 'horse'\n",
    "print(glove_model.similarity(word1, word2))\n",
    "print(cosine_similarity(glove_model[word1], glove_model[word2]))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34625494\n",
      "0.34625497\n"
     ]
    }
   ],
   "execution_count": 140
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:50:52.536731Z",
     "start_time": "2025-04-20T22:50:52.532565Z"
    }
   },
   "source": [
    "# simalarity between two SAME words\n",
    "glove_model.similarity('equal', 'equal')\n",
    "word1 = 'equal'\n",
    "word2 = 'equal'\n",
    "print(glove_model.similarity(word1, word2))\n",
    "print(cosine_similarity(glove_model[word1], glove_model[word2]))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0000001\n"
     ]
    }
   ],
   "execution_count": 141
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The next function contains the code to plot a similarity matrix between multiple words (e.g. if we want to compare 10 words and their pair-wise similarities). It requires a matrix with similarities (as input) and labels (aka the words) to display in the final figure."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:50:52.739295Z",
     "start_time": "2025-04-20T22:50:52.731095Z"
    }
   },
   "source": [
    "def plot_similarity_matrix(matrix, labels):\n",
    "    \"\"\"\n",
    "    Displays a plot of the `matrix` of size (N x N) with the labels specified as a list of size N\n",
    "    Args:\n",
    "        matrix: a square-sized (N x N) numpy array\n",
    "        labels: a list of strings of hte size N\n",
    "    \"\"\"\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(matrix)\n",
    "\n",
    "    # Show all ticks and label them with the respective list entries\n",
    "    ax.set_xticks(np.arange(len(labels)), labels=labels)\n",
    "    ax.set_yticks(np.arange(len(labels)), labels=labels)\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            text = ax.text(j, i, f'{matrix[i, j]:.2f}',\n",
    "                           ha=\"center\", va=\"center\", color=\"w\")\n",
    "\n",
    "    # ax.set_title(\"Give a title if you want\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": 142
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a name='e10'></a>\n",
    "### Exercise 10: Plotting similarities between words\n",
    "\n",
    "(10p) In the following, we will explore some properties of word embeddings through some examples. We will use 6 example words for this purpose but experiment with other set of words as well. Fill in the next cell to create a similarity matrix between a list of words.\n",
    "\n",
    "Experiment with different words and their similarities plotted. Try at least 3 different sets of words of at least 6 words each. Use the `plot_similarity_matrix` function to visualize the results.\n",
    "Comment on the results. Do they make sense? Why some words are closer to each other than others? What does it mean?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:50:53.372622Z",
     "start_time": "2025-04-20T22:50:52.909350Z"
    }
   },
   "source": [
    "list_of_words = ['love', 'hate', 'life', 'equal', 'alive', 'dead']\n",
    "\n",
    "similarity_matrix = np.zeros((len(list_of_words), len(list_of_words)), dtype=float)\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### YOUR CODE ENDS HERE\n",
    "\n",
    "\n",
    "plot_similarity_matrix(similarity_matrix, list_of_words)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 143
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:50:53.545408Z",
     "start_time": "2025-04-20T22:50:53.542460Z"
    }
   },
   "source": [
    "#### YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "### YOUR CODE ENDS HERE"
   ],
   "outputs": [],
   "execution_count": 144
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a name='e11'></a>\n",
    "### Exercise 11: Other pre-trained word embeddings\n",
    "(10p) For this exercise, experiment with at least one different word embedding model. You can choose Glove with different dimensions or other pre-trained models. Use the gensim library to download and use the models.\n",
    "Plot similarity matrices between sets of words you used in the previous exercise and compare the results. Are there noticeable differences? Why (not)?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:50:53.722690Z",
     "start_time": "2025-04-20T22:50:53.720287Z"
    }
   },
   "source": [
    "#### YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "### YOUR CODE ENDS HERE"
   ],
   "outputs": [],
   "execution_count": 145
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "// your comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 5. Sentence Embeddings by Averaging Word Embeddings\n",
    "\n",
    "Word embeddings are a powerful model for representing words and their meaning (in terms of distributional similarity). As we discussed in class, we can use them in a wide variety of tasks with more complex architectures. Word vectors offer a dense vector for each word. What if we wanted to represent a sentence (or a document) based on word vectors. How can we do that?\n",
    "\n",
    "In the course, we will see different architectures that take into account the sequence of words (by combining their vectors). A first naive but simple and sometimes (as we are going to see) quite effective approach would be to represent a sentence with an embedding vector that is the average of the word vectors that form the sentence.\n",
    "\n",
    "So formally, this is what we are aiming for:\n",
    "\n",
    "$\n",
    "\\text{Sentence_Embedding} = \\frac{1}{N} \\sum_{i=1}^{N} \\text{Word_Embedding}_i\n",
    "$\n",
    "\n",
    "where:\n",
    "* $N$ is the number of words in a sentence\n",
    "* $\\text{Word_Embedding}_i$ is the word vector for the $i$-th in the sentence.\n",
    "\n",
    "Things to note:\n",
    "* The embedding vector for the sentence will obviously have the same dimension as the word embedding.\n",
    "* This representation ignores the word order (like bag-of-words). During the course we will see how we can overcome this limitation by using sequence models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a name='e12'></a>\n",
    "### Exercise 12: Sentence Embedding\n",
    "\n",
    "(10p) Complete the function below that takes as input the sentence in the form of tokens (so it's a list of words) and calculates the sentence embedding vector. First, we would need to retrieve the word embeddings for each word from our loaded model and then average the vectors.\n",
    "\n",
    "Note: There can be cases where all tokens from a sentence are out-of-vocabulary words (OOV). Think what to do in this case and make sure to discuss it in the report."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:50:53.904451Z",
     "start_time": "2025-04-20T22:50:53.901124Z"
    }
   },
   "source": [
    "def embed_sentence_word_model(tokens, model):\n",
    "    \"\"\"\n",
    "    Calculates the sentence embedding by averaging the embeddings of the tokens\n",
    "    Args:\n",
    "        tokens: a list of words from the sentence\n",
    "        model: a trained word embeddings model\n",
    "\n",
    "    Returns: a numpy array of the sentence embedding\n",
    "\n",
    "    \"\"\"\n",
    "    #### YOUR CODE HERE\n",
    "    #### CAUTION: be sure to cover the case where all tokens are out-of-vocabulary!!!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### YOUR CODE ENDS HERE"
   ],
   "outputs": [],
   "execution_count": 146
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we can apply the function to the whole dataset. Here we do it both for the sentence and the compressed version. You should know it by now, but this operation might take some time. The next cells will apply your function to the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:50:54.086730Z",
     "start_time": "2025-04-20T22:50:54.081911Z"
    }
   },
   "source": [
    "def embed_sentence_word_model_dataset(example, model):\n",
    "    \"\"\"\n",
    "    Embeds the sentence and the compressed sentence in the example from the Dataset\n",
    "    Args:\n",
    "        example: an example from the Dataset\n",
    "        model: a trained word embeddings model\n",
    "\n",
    "    Returns: updated example with 'sentence_embedding' and 'compressed_embedding' columns\n",
    "\n",
    "    \"\"\"\n",
    "    sentence_tokens = example['sentence_tokens']\n",
    "    clean_compressed = example['clean_compressed']\n",
    "    compressed_tokens = tokenize(clean_compressed)\n",
    "\n",
    "    sentence_embedding = embed_sentence_word_model(sentence_tokens, model)\n",
    "    compressed_embedding = embed_sentence_word_model(compressed_tokens, model)\n",
    "\n",
    "    example['sentence_embedding'] = sentence_embedding\n",
    "    example['compressed_embedding'] = compressed_embedding\n",
    "    return example"
   ],
   "outputs": [],
   "execution_count": 147
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-04-20T22:51:30.464728Z",
     "start_time": "2025-04-20T22:50:54.419291Z"
    }
   },
   "source": [
    "test_ds = test_ds.map(embed_sentence_word_model_dataset, fn_kwargs={'model': glove_model})\n",
    "print(test_ds)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/36000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "21adf6f388b743e4998c733a01ca313c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ArrowInvalid",
     "evalue": "arrays to be concatenated must be identically typed, but string and null were encountered.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mArrowInvalid\u001B[0m                              Traceback (most recent call last)",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/datasets/arrow_dataset.py:3508\u001B[0m, in \u001B[0;36mDataset._map_single\u001B[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001B[0m\n\u001B[1;32m   3507\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 3508\u001B[0m         writer\u001B[38;5;241m.\u001B[39mwrite(example)\n\u001B[1;32m   3509\u001B[0m num_examples_progress_update \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/datasets/arrow_writer.py:538\u001B[0m, in \u001B[0;36mArrowWriter.write\u001B[0;34m(self, example, key, writer_batch_size)\u001B[0m\n\u001B[1;32m    536\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhkey_record \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m--> 538\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwrite_examples_on_file()\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/datasets/arrow_writer.py:496\u001B[0m, in \u001B[0;36mArrowWriter.write_examples_on_file\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    492\u001B[0m         batch_examples[col] \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    493\u001B[0m             row[\u001B[38;5;241m0\u001B[39m][col]\u001B[38;5;241m.\u001B[39mto_pylist()[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(row[\u001B[38;5;241m0\u001B[39m][col], (pa\u001B[38;5;241m.\u001B[39mArray, pa\u001B[38;5;241m.\u001B[39mChunkedArray)) \u001B[38;5;28;01melse\u001B[39;00m row[\u001B[38;5;241m0\u001B[39m][col]\n\u001B[1;32m    494\u001B[0m             \u001B[38;5;28;01mfor\u001B[39;00m row \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_examples\n\u001B[1;32m    495\u001B[0m         ]\n\u001B[0;32m--> 496\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwrite_batch(batch_examples\u001B[38;5;241m=\u001B[39mbatch_examples)\n\u001B[1;32m    497\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_examples \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/datasets/arrow_writer.py:606\u001B[0m, in \u001B[0;36mArrowWriter.write_batch\u001B[0;34m(self, batch_examples, writer_batch_size)\u001B[0m\n\u001B[1;32m    605\u001B[0m typed_sequence \u001B[38;5;241m=\u001B[39m OptimizedTypedSequence(col_values, \u001B[38;5;28mtype\u001B[39m\u001B[38;5;241m=\u001B[39mcol_type, try_type\u001B[38;5;241m=\u001B[39mcol_try_type, col\u001B[38;5;241m=\u001B[39mcol)\n\u001B[0;32m--> 606\u001B[0m arrays\u001B[38;5;241m.\u001B[39mappend(pa\u001B[38;5;241m.\u001B[39marray(typed_sequence))\n\u001B[1;32m    607\u001B[0m inferred_features[col] \u001B[38;5;241m=\u001B[39m typed_sequence\u001B[38;5;241m.\u001B[39mget_inferred_type()\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/pyarrow/array.pxi:252\u001B[0m, in \u001B[0;36mpyarrow.lib.array\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/pyarrow/array.pxi:114\u001B[0m, in \u001B[0;36mpyarrow.lib._handle_arrow_array_protocol\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/datasets/arrow_writer.py:226\u001B[0m, in \u001B[0;36mTypedSequence.__arrow_array__\u001B[0;34m(self, type)\u001B[0m\n\u001B[1;32m    225\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, \u001B[38;5;28mlist\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m data \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(first_non_null_value(data)[\u001B[38;5;241m1\u001B[39m], np\u001B[38;5;241m.\u001B[39mndarray):\n\u001B[0;32m--> 226\u001B[0m     out \u001B[38;5;241m=\u001B[39m list_of_np_array_to_pyarrow_listarray(data)\n\u001B[1;32m    227\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/datasets/features/features.py:1541\u001B[0m, in \u001B[0;36mlist_of_np_array_to_pyarrow_listarray\u001B[0;34m(l_arr, type)\u001B[0m\n\u001B[1;32m   1540\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(l_arr) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m list_of_pa_arrays_to_pyarrow_listarray(\n\u001B[1;32m   1542\u001B[0m         [numpy_to_pyarrow_listarray(arr, \u001B[38;5;28mtype\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mtype\u001B[39m) \u001B[38;5;28;01mif\u001B[39;00m arr \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m arr \u001B[38;5;129;01min\u001B[39;00m l_arr]\n\u001B[1;32m   1543\u001B[0m     )\n\u001B[1;32m   1544\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/datasets/features/features.py:1534\u001B[0m, in \u001B[0;36mlist_of_pa_arrays_to_pyarrow_listarray\u001B[0;34m(l_arr)\u001B[0m\n\u001B[1;32m   1533\u001B[0m offsets \u001B[38;5;241m=\u001B[39m pa\u001B[38;5;241m.\u001B[39marray(offsets, \u001B[38;5;28mtype\u001B[39m\u001B[38;5;241m=\u001B[39mpa\u001B[38;5;241m.\u001B[39mint32())\n\u001B[0;32m-> 1534\u001B[0m values \u001B[38;5;241m=\u001B[39m pa\u001B[38;5;241m.\u001B[39mconcat_arrays(l_arr)\n\u001B[1;32m   1535\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pa\u001B[38;5;241m.\u001B[39mListArray\u001B[38;5;241m.\u001B[39mfrom_arrays(offsets, values)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/pyarrow/array.pxi:4822\u001B[0m, in \u001B[0;36mpyarrow.lib.concat_arrays\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/pyarrow/error.pxi:155\u001B[0m, in \u001B[0;36mpyarrow.lib.pyarrow_internal_check_status\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/pyarrow/error.pxi:92\u001B[0m, in \u001B[0;36mpyarrow.lib.check_status\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mArrowInvalid\u001B[0m: arrays to be concatenated must be identically typed, but string and null were encountered.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mArrowInvalid\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[148], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m test_ds \u001B[38;5;241m=\u001B[39m test_ds\u001B[38;5;241m.\u001B[39mmap(embed_sentence_word_model_dataset, fn_kwargs\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m'\u001B[39m: glove_model})\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(test_ds)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/datasets/arrow_dataset.py:557\u001B[0m, in \u001B[0;36mtransmit_format.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    550\u001B[0m self_format \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    551\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtype\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_type,\n\u001B[1;32m    552\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mformat_kwargs\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_kwargs,\n\u001B[1;32m    553\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcolumns\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_columns,\n\u001B[1;32m    554\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutput_all_columns\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output_all_columns,\n\u001B[1;32m    555\u001B[0m }\n\u001B[1;32m    556\u001B[0m \u001B[38;5;66;03m# apply actual function\u001B[39;00m\n\u001B[0;32m--> 557\u001B[0m out: Union[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDatasetDict\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    558\u001B[0m datasets: \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(out\u001B[38;5;241m.\u001B[39mvalues()) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(out, \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m [out]\n\u001B[1;32m    559\u001B[0m \u001B[38;5;66;03m# re-apply format to the output\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/datasets/arrow_dataset.py:3074\u001B[0m, in \u001B[0;36mDataset.map\u001B[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001B[0m\n\u001B[1;32m   3068\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m transformed_dataset \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   3069\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m hf_tqdm(\n\u001B[1;32m   3070\u001B[0m         unit\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m examples\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   3071\u001B[0m         total\u001B[38;5;241m=\u001B[39mpbar_total,\n\u001B[1;32m   3072\u001B[0m         desc\u001B[38;5;241m=\u001B[39mdesc \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMap\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   3073\u001B[0m     ) \u001B[38;5;28;01mas\u001B[39;00m pbar:\n\u001B[0;32m-> 3074\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m rank, done, content \u001B[38;5;129;01min\u001B[39;00m Dataset\u001B[38;5;241m.\u001B[39m_map_single(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mdataset_kwargs):\n\u001B[1;32m   3075\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m done:\n\u001B[1;32m   3076\u001B[0m                 shards_done \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/datasets/arrow_dataset.py:3543\u001B[0m, in \u001B[0;36mDataset._map_single\u001B[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001B[0m\n\u001B[1;32m   3541\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m update_data:\n\u001B[1;32m   3542\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m writer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 3543\u001B[0m         writer\u001B[38;5;241m.\u001B[39mfinalize()\n\u001B[1;32m   3544\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m tmp_file \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   3545\u001B[0m         tmp_file\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/datasets/arrow_writer.py:637\u001B[0m, in \u001B[0;36mArrowWriter.finalize\u001B[0;34m(self, close_stream)\u001B[0m\n\u001B[1;32m    635\u001B[0m     \u001B[38;5;66;03m# Re-intializing to empty list for next batch\u001B[39;00m\n\u001B[1;32m    636\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhkey_record \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m--> 637\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwrite_examples_on_file()\n\u001B[1;32m    638\u001B[0m \u001B[38;5;66;03m# If schema is known, infer features even if no examples were written\u001B[39;00m\n\u001B[1;32m    639\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpa_writer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mschema:\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/datasets/arrow_writer.py:496\u001B[0m, in \u001B[0;36mArrowWriter.write_examples_on_file\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    491\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    492\u001B[0m         batch_examples[col] \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    493\u001B[0m             row[\u001B[38;5;241m0\u001B[39m][col]\u001B[38;5;241m.\u001B[39mto_pylist()[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(row[\u001B[38;5;241m0\u001B[39m][col], (pa\u001B[38;5;241m.\u001B[39mArray, pa\u001B[38;5;241m.\u001B[39mChunkedArray)) \u001B[38;5;28;01melse\u001B[39;00m row[\u001B[38;5;241m0\u001B[39m][col]\n\u001B[1;32m    494\u001B[0m             \u001B[38;5;28;01mfor\u001B[39;00m row \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_examples\n\u001B[1;32m    495\u001B[0m         ]\n\u001B[0;32m--> 496\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwrite_batch(batch_examples\u001B[38;5;241m=\u001B[39mbatch_examples)\n\u001B[1;32m    497\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_examples \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/datasets/arrow_writer.py:606\u001B[0m, in \u001B[0;36mArrowWriter.write_batch\u001B[0;34m(self, batch_examples, writer_batch_size)\u001B[0m\n\u001B[1;32m    604\u001B[0m         col_try_type \u001B[38;5;241m=\u001B[39m try_features[col] \u001B[38;5;28;01mif\u001B[39;00m try_features \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m col \u001B[38;5;129;01min\u001B[39;00m try_features \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    605\u001B[0m         typed_sequence \u001B[38;5;241m=\u001B[39m OptimizedTypedSequence(col_values, \u001B[38;5;28mtype\u001B[39m\u001B[38;5;241m=\u001B[39mcol_type, try_type\u001B[38;5;241m=\u001B[39mcol_try_type, col\u001B[38;5;241m=\u001B[39mcol)\n\u001B[0;32m--> 606\u001B[0m         arrays\u001B[38;5;241m.\u001B[39mappend(pa\u001B[38;5;241m.\u001B[39marray(typed_sequence))\n\u001B[1;32m    607\u001B[0m         inferred_features[col] \u001B[38;5;241m=\u001B[39m typed_sequence\u001B[38;5;241m.\u001B[39mget_inferred_type()\n\u001B[1;32m    608\u001B[0m schema \u001B[38;5;241m=\u001B[39m inferred_features\u001B[38;5;241m.\u001B[39marrow_schema \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpa_writer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mschema\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/pyarrow/array.pxi:252\u001B[0m, in \u001B[0;36mpyarrow.lib.array\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/pyarrow/array.pxi:114\u001B[0m, in \u001B[0;36mpyarrow.lib._handle_arrow_array_protocol\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/datasets/arrow_writer.py:226\u001B[0m, in \u001B[0;36mTypedSequence.__arrow_array__\u001B[0;34m(self, type)\u001B[0m\n\u001B[1;32m    224\u001B[0m     out \u001B[38;5;241m=\u001B[39m numpy_to_pyarrow_listarray(data)\n\u001B[1;32m    225\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, \u001B[38;5;28mlist\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m data \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(first_non_null_value(data)[\u001B[38;5;241m1\u001B[39m], np\u001B[38;5;241m.\u001B[39mndarray):\n\u001B[0;32m--> 226\u001B[0m     out \u001B[38;5;241m=\u001B[39m list_of_np_array_to_pyarrow_listarray(data)\n\u001B[1;32m    227\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    228\u001B[0m     trying_cast_to_python_objects \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/datasets/features/features.py:1541\u001B[0m, in \u001B[0;36mlist_of_np_array_to_pyarrow_listarray\u001B[0;34m(l_arr, type)\u001B[0m\n\u001B[1;32m   1539\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Build a PyArrow ListArray from a possibly nested list of NumPy arrays\"\"\"\u001B[39;00m\n\u001B[1;32m   1540\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(l_arr) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m list_of_pa_arrays_to_pyarrow_listarray(\n\u001B[1;32m   1542\u001B[0m         [numpy_to_pyarrow_listarray(arr, \u001B[38;5;28mtype\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mtype\u001B[39m) \u001B[38;5;28;01mif\u001B[39;00m arr \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m arr \u001B[38;5;129;01min\u001B[39;00m l_arr]\n\u001B[1;32m   1543\u001B[0m     )\n\u001B[1;32m   1544\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1545\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m pa\u001B[38;5;241m.\u001B[39marray([], \u001B[38;5;28mtype\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mtype\u001B[39m)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/datasets/features/features.py:1534\u001B[0m, in \u001B[0;36mlist_of_pa_arrays_to_pyarrow_listarray\u001B[0;34m(l_arr)\u001B[0m\n\u001B[1;32m   1532\u001B[0m offsets \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39minsert(offsets, null_indices, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m   1533\u001B[0m offsets \u001B[38;5;241m=\u001B[39m pa\u001B[38;5;241m.\u001B[39marray(offsets, \u001B[38;5;28mtype\u001B[39m\u001B[38;5;241m=\u001B[39mpa\u001B[38;5;241m.\u001B[39mint32())\n\u001B[0;32m-> 1534\u001B[0m values \u001B[38;5;241m=\u001B[39m pa\u001B[38;5;241m.\u001B[39mconcat_arrays(l_arr)\n\u001B[1;32m   1535\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pa\u001B[38;5;241m.\u001B[39mListArray\u001B[38;5;241m.\u001B[39mfrom_arrays(offsets, values)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/pyarrow/array.pxi:4822\u001B[0m, in \u001B[0;36mpyarrow.lib.concat_arrays\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/pyarrow/error.pxi:155\u001B[0m, in \u001B[0;36mpyarrow.lib.pyarrow_internal_check_status\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/pyarrow/error.pxi:92\u001B[0m, in \u001B[0;36mpyarrow.lib.check_status\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mArrowInvalid\u001B[0m: arrays to be concatenated must be identically typed, but string and null were encountered."
     ]
    }
   ],
   "execution_count": 148
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(test_ds[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here you can see that the new dataset returned a single numpy array containing all sentence embeddings in our dataset. This is a lot more efficient than returning a list of arrays (which is the default behaviour). Below we check the type and the dimensionality.\n",
    "\n",
    "We will be using `text` subset from our dataset to not use too much RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sent_embedding = test_ds['sentence_embedding']\n",
    "compr_embedding = test_ds['compressed_embedding']\n",
    "print(type(sent_embedding))\n",
    "print(sent_embedding.shape)\n",
    "print(type(compr_embedding))\n",
    "print(compr_embedding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next we try the condensed representatin based on a simple query. Feel free to try different queries with different words. What happens if we have OOV words in a query?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "query = 'fox and deer'\n",
    "print(query)\n",
    "\n",
    "query_embedding = embed_text(query, clean, tokenize, lambda x: embed_sentence_word_model(x, glove_model))\n",
    "print(query_embedding.shape)\n",
    "print(query_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a name='e13'></a>\n",
    "### Exercise 13: Analyze sentence embeddings\n",
    "- (5p) Calculate similarity between the word embeddings representations of the selected queries and the dataset sentences.\n",
    "- (5p) Analyze the search results. Does the search work as expected? Discuss the results.\n",
    "- (5p) Compare the results with the ones you got with the bag-of-words and TF-IDF representation. Discuss the differences and similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### YOUR CODE ENDS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZY2jouFmeHOg",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 6. Evaluating Retrieval\n",
    "\n",
    "In this last section we will try to evaluate how good our sentence retrieval system is. To keep the computational resources manageable, we will use the test set for that as its size is more manageable.\n",
    "\n",
    "Recall from the lecture in IR that there are several metrics to evaluate retrieval performance by taking into account the relevance of the retrieved results to the query. We will use Recall@K here (for more metrics and more details refer to the lecture slides and the textbooks).\n",
    "\n",
    "RRecall@K is a metric used to measure the effectiveness of a search system in retrieving relevant documents within the top $K$ retrieved documents. It calculates the proportion of relevant documents retrieved within the top-$K$ results, compared to the total number of relevant documents in the collection.\n",
    "\n",
    "$\n",
    "\\text{Recall@K} = \\frac{\\text{Number of relevant documents retrieved in the top }-K}{\\text{Total number of relevant documents}}\n",
    "$\n",
    "\n",
    "In our case, we have a sentence, and it's compressed version. To test our system, we will treat compressed sentences as the queries. Each query will have only a single relevant sentence - the corresponding uncompressed sentence.\n",
    "\n",
    "Therefore, for the calculation of Recall@K we will take into account whether the correct retrieved result is contained within the first $K$ retrieved results. For example, if for a query (i.e. a compressed sentence) we retrieve 10 results and within these we see the relevant one (i.e. the full sentence), then Recall@10 = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUKPtG-uem9f",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a name='e14'></a>\n",
    "### Exercise 14: Cosine similarity between two sets of vectors\n",
    "\n",
    "(3p) In this exercise you will revisit your implementation of the cosine similarity. Generalize it so that it can accept two arrays containing two sets of vectors (first one containing $M$ vectors and the second one $N$ vectors). Compute the cosine similarity between each pair of vectors coming from the two sets. The result should be an array of size $M x N$.\n",
    "\n",
    "Once again, try to write an efficient code. This means no loops. Remember the relation between matrix multiplication and dot product. (Depending on your implementation of the previous function calculating cosine similarity, this one can be almost the same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xKiHDrN9eld7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def cosine_similarity_m_to_n(vectors, other_vectors):\n",
    "    \"\"\"\n",
    "    Calculates the cosine similarity between a multiple vectors and other vectors.\n",
    "    Args:\n",
    "        vectors: a numpy array representing M number of vectors of D dimensions (of the size MxD)\n",
    "        other_vectors: a 2D numpy array representing other vectors (of the size NxD, where N is the number of vectors and D is their dimension)\n",
    "\n",
    "    Returns: a numpy array of cosine similarity between all the vectors and all the other vectors\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #### YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### YOUR CODE ENDS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQ-Yhl1Sgoka",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The following function will use your implementation to calculate Recall@K based on the similarity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z0sLS3uRCfdh",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_recall(queries, sentences, k, batch_size=1000):\n",
    "    \"\"\"\n",
    "    Calculates recall@k given the embeddings of the queries and sentences.\n",
    "    Assumes that only a single sentence with the same index as query is relevant.\n",
    "    Batching is implemented to avoid high memory usage.\n",
    "    Args:\n",
    "        queries: a numpy array with the embeddings of N queries\n",
    "        sentences: a numpy array with the embeddings of N sentences available for retrieval\n",
    "        k: number of top results to search for the relevant sentence\n",
    "        batch_size: number of queries to process at a time\n",
    "\n",
    "    Returns: calculated recall@k\n",
    "\n",
    "    \"\"\"\n",
    "    n_queries = queries.shape[0]\n",
    "    correct = np.zeros(n_queries, dtype=bool)\n",
    "\n",
    "    with tqdm.tqdm(total=n_queries) as pbar:\n",
    "        for batch_start in range(0, n_queries, batch_size):\n",
    "            batch_end = min(batch_start + batch_size, n_queries)\n",
    "            queries_batch = queries[batch_start:batch_end]\n",
    "            batch_similarity = cosine_similarity_m_to_n(queries_batch, sentences)\n",
    "\n",
    "            for i, similarity_row in enumerate(batch_similarity):\n",
    "                query_index = batch_start + i\n",
    "                top_k = top_k_indices(similarity_row, k=k, sorted=False)\n",
    "\n",
    "                if query_index in top_k:\n",
    "                    correct[query_index] = True\n",
    "\n",
    "                pbar.update(1)\n",
    "\n",
    "    recall = np.sum(correct) / n_queries\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3QgAgMiDgw8m",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You can use it like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yxpex7ZxHM7c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "recall_at_1 = calculate_recall(compr_embedding, sent_embedding, k=1, batch_size=1000)\n",
    "print(f'\\n{recall_at_1 * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zY5ZVq5ogzMI",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a name='e15'></a>\n",
    "### Exercise 15: Evaluating retrieval methods\n",
    "\n",
    "(10p) Calculate recall for different values of $K$ for all methods:\n",
    "- BOW,\n",
    "- TF-IDF,\n",
    "- Pre-trained embeddings.\n",
    "\n",
    "Discuss the results.\n",
    "Comment on how recall changes based on the value of $K$. Are the results expected or surprising?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#### YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "### YOUR CODE ENDS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a name='e16'></a>\n",
    "### Exercise 16: Improving retrieval\n",
    "\n",
    "(10p) Imagine that you work at a company and are tasked with delivering the best retrieval method. Select the most promising one and try to improve the scores (e.g. by changing the vocab size, loading different model, etc.).\n",
    "Discuss the results you achieve, even if you didn't manage to improve the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YA9bEm5ehMq8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#### YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "### YOUR CODE ENDS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "// your comments"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
